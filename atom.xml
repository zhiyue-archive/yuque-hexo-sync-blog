<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>å™«åæˆ</title>
  
  <subtitle>Just Do IT.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yixuxi.xyz/"/>
  <updated>2019-11-13T07:22:27.373Z</updated>
  <id>http://yixuxi.xyz/</id>
  
  <author>
    <name>zhiyue</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Regularization on GBDT</title>
    <link href="http://yixuxi.xyz/posts/hello-world_2/"/>
    <id>http://yixuxi.xyz/posts/hello-world_2/</id>
    <published>2019-11-13T07:22:27.373Z</published>
    <updated>2019-11-13T07:22:27.373Z</updated>
    
    <content type="html"><![CDATA[<script src="//gist.github.com/930f5f2f2b315ec967617d88600f16df.js"></script><p>ä¹‹å‰ä¸€ç¯‡æ–‡ç« ç®€å•åœ°è®²äº†XGBoostçš„å®ç°ä¸æ™®é€šGBDTå®ç°çš„ä¸åŒä¹‹å¤„ï¼Œæœ¬æ–‡å°è¯•æ€»ç»“ä¸€ä¸‹GBDTè¿ç”¨çš„æ­£åˆ™åŒ–æŠ€å·§ã€‚</p><script src="https://gist.github.com/zihengcat/1a80a31b671e5bb3db6eb7af5a4b30f7.js"></script><h3 id="Early-Stopping"><a href="#Early-Stopping" class="headerlink" title="Early Stopping"></a>Early Stopping</h3><p><a href="https://en.wikipedia.org/wiki/Early_stopping" target="_blank" rel="noopener">Early Stopping</a>æ˜¯æœºå™¨å­¦ä¹ è¿­ä»£å¼è®­ç»ƒæ¨¡å‹ä¸­å¾ˆå¸¸è§çš„é˜²æ­¢è¿‡æ‹ŸåˆæŠ€å·§ï¼Œç»´åŸºç™¾ç§‘é‡Œå¦‚ä¸‹æè¿°:</p><blockquote><p>In machine learning, early stopping is a form of <em>regularization</em> used to <em>avoid overfitting</em> when training a learner with an <em>iterative method</em>, such as gradient descent.</p></blockquote><p>å…·ä½“çš„åšæ³•æ˜¯é€‰æ‹©ä¸€éƒ¨åˆ†æ ·æœ¬ä½œä¸ºéªŒè¯é›†ï¼Œåœ¨è¿­ä»£æ‹Ÿåˆè®­ç»ƒé›†çš„è¿‡ç¨‹ä¸­ï¼Œå¦‚æœæ¨¡å‹åœ¨éªŒè¯é›†é‡Œé”™è¯¯ç‡ä¸å†ä¸‹é™ï¼Œå°±åœæ­¢è®­ç»ƒï¼Œä¹Ÿå°±æ˜¯è¯´æ§åˆ¶è¿­ä»£çš„è½®æ•°ï¼ˆæ ‘çš„ä¸ªæ•°ï¼‰ã€‚</p><p>XGBoost Pythonå…³äºearly stoppingçš„<a href="https://github.com/dmlc/xgboost/blob/master/doc/python/python_intro.md#early-stopping" target="_blank" rel="noopener">å‚æ•°è®¾ç½®æ–‡æ¡£</a>éå¸¸æ¸…æ™°ï¼ŒAPIå¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># code snippets from xgboost python-package training.py</span><br><span class="line">def train(..., evals=(), early_stopping_rounds=None)</span><br><span class="line">&quot;&quot;&quot;Train a booster with given parameters.</span><br><span class="line">Parameters</span><br><span class="line">    ----------</span><br><span class="line">early_stopping_rounds: int</span><br><span class="line">        Activates early stopping. Validation error needs to decrease at least</span><br><span class="line">        every &lt;early_stopping_rounds&gt; round(s) to continue training.</span><br><span class="line">&quot;&quot;&quot;</span><br></pre></td></tr></table></figure><p>Sklearnçš„GBDTå®ç°è™½ç„¶å¯ä»¥æ·»åŠ early stoppingï¼Œä½†æ˜¯æ¯”è¾ƒå¤æ‚ã€‚å®˜æ–¹æ²¡æœ‰ç›¸åº”çš„æ–‡æ¡£å’Œä»£ç æ ·ä¾‹ï¼Œå¿…é¡»çœ‹<a href="https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/ensemble/gradient_boosting.py#L931" target="_blank" rel="noopener">æºç </a>ã€‚å®ç°çš„æ—¶å€™éœ€è¦ç”¨æˆ·æä¾›monitorå›è°ƒå‡½æ•°ï¼Œä¸”è¦äº†è§£æºç å†…éƒ¨_fit_stageså‡½æ•°çš„localsï¼Œæ€»ä¹‹å¯¹æ–°æ‰‹å¾ˆä¸å‹å¥½ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#code snippets from sklearn.ensemble.gradient_boosting</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaseGradientBoosting</span><span class="params">(six.with_metaclass<span class="params">(ABCMeta, BaseEnsemble,</span></span></span></span><br><span class="line"><span class="class"><span class="params"><span class="params">   _LearntSelectorMixin)</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Abstract base class for Gradient Boosting. """</span></span><br><span class="line">...</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y, sample_weight=None, monitor=None)</span>:</span></span><br><span class="line"><span class="string">"""Fit the gradient boosting model.</span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">----------</span></span><br><span class="line"><span class="string">monitor : callable, optional</span></span><br><span class="line"><span class="string">            The monitor is called after each iteration with the current</span></span><br><span class="line"><span class="string">            iteration, a reference to the estimator and the local variables of</span></span><br><span class="line"><span class="string">            ``_fit_stages`` as keyword arguments ``callable(i, self,</span></span><br><span class="line"><span class="string">            locals())``. If the callable returns ``True`` the fitting procedure</span></span><br><span class="line"><span class="string">            is stopped. The monitor can be used for various things such as</span></span><br><span class="line"><span class="string">            computing held-out estimates, early stopping, model introspect, and</span></span><br><span class="line"><span class="string">            snapshoting.</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><p>å¯¹Sklearnæ„Ÿå…´è¶£çš„å¯ä»¥çœ‹è¿™ç¯‡æ–‡ç« <a href="*https://henri.io/posts/using-gradient-boosting-with-early-stopping.html">Using Gradient Boosting (with Early Stopping)</a>ï¼Œé‡Œé¢æœ‰å›è°ƒå‡½æ•°monitorçš„å‚è€ƒå®ç°ã€‚</p><h3 id="Shrinkage"><a href="#Shrinkage" class="headerlink" title="Shrinkage"></a>Shrinkage</h3><p>Shrinkageå°±æ˜¯å°†æ¯æ£µæ ‘çš„è¾“å‡ºç»“æœä¹˜ä¸€ä¸ªå› å­($0&lt;\nu&lt;1$)ï¼Œå…¶ä¸­$\Sigma_{j=1}^{J_m}\gamma_{jm}I(x\in R_{jm})$æ˜¯ç¬¬mæ£µçš„è¾“å‡ºï¼Œè€Œ$f(m)$æ˜¯å‰mæ£µæ ‘çš„ensemble: $$f_m(x) = f_{m-1}(x) + \nu\cdot\Sigma_{j=1}^{J_m}\gamma_{jm}I(x\in R_{jm})$$<br>ESLä¹¦ä¸­è¿™æ ·è®²ï¼š</p><blockquote><p>The parameter $\nu$ can be regarded as controlling the leanring rate of the boosting procedure</p></blockquote><p>$\nu$å’Œè¿­ä»£è½®æ•°M(æ ‘ä¸ªæ•°)æ˜¯ä¸€ä¸ªtradeoffï¼Œæ¨èçš„æ˜¯$\nu$å€¼è®¾ç½®å°ä¸€ç‚¹(å¦‚0.1)ï¼Œè€ŒMè®¾ç½®å¤§ä¸€äº›ã€‚è¿™æ ·ä¸€èˆ¬èƒ½æœ‰æ¯”è¾ƒå¥½çš„å‡†ç¡®ç‡ï¼Œä»£ä»·æ˜¯è®­ç»ƒæ—¶é—´å˜é•¿(ä¸Mæˆæ¯”ä¾‹)ã€‚</p><p>ä¸‹é¢æ˜¯Sklearnçš„å®ç°å…³äºè¯¥å‚æ•°è®¾ç½®çš„ç‰‡æ®µï¼ŒXGBoostç±»ä¼¼ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#code snippets from sklearn.ensemble.gradient_boosting</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GradientBoostingClassifier</span><span class="params">(BaseGradientBoosting, ClassifierMixin)</span>:</span></span><br><span class="line">    <span class="string">"""Gradient Boosting for classification."""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, ..., learning_rate=<span class="number">0.1</span>, n_estimators=<span class="number">100</span>, ...)</span>:</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">learning_rate : float, optional (default=0.1)</span></span><br><span class="line"><span class="string">        learning rate shrinks the contribution of each tree by `learning_rate`.</span></span><br><span class="line"><span class="string">        There is a trade-off between learning_rate and n_estimators.</span></span><br><span class="line"><span class="string">n_estimators : int (default=100)</span></span><br><span class="line"><span class="string">        The number of boosting stages to perform. Gradient boosting</span></span><br><span class="line"><span class="string">        is fairly robust to over-fitting so a large number usually</span></span><br><span class="line"><span class="string">        results in better performance</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><h3 id="Subsampling"><a href="#Subsampling" class="headerlink" title="Subsampling"></a>Subsampling</h3><p>Subsamplingå…¶å®æºäºbootstrap averaging(bagging)æ€æƒ³ï¼ŒGBDTé‡Œçš„åšæ³•æ˜¯åœ¨æ¯ä¸€è½®å»ºæ ‘æ—¶ï¼Œæ ·æœ¬æ˜¯ä»è®­ç»ƒé›†åˆä¸­æ— æ”¾å›éšæœºæŠ½æ ·çš„$\eta$éƒ¨åˆ†ï¼Œå…¸å‹çš„$\eta$å€¼æ˜¯0.5ã€‚è¿™æ ·åšæ—¢èƒ½å¯¹æ¨¡å‹èµ·æ­£åˆ™ä½œç”¨ï¼Œä¹Ÿèƒ½å‡å°‘è®¡ç®—æ—¶é—´ã€‚</p><p>äº‹å®ä¸Šï¼ŒXGBoostå’ŒSklearnçš„å®ç°å‡å€Ÿé‰´äº†éšæœºæ£®æ—ï¼Œé™¤äº†æœ‰æ ·æœ¬å±‚æ¬¡ä¸Šçš„é‡‡æ ·ï¼Œä¹Ÿæœ‰ç‰¹å¾é‡‡æ ·ã€‚ä¹Ÿå°±æ˜¯è¯´å»ºæ ‘çš„æ—¶å€™åªä»éšæœºé€‰å–çš„ä¸€äº›ç‰¹å¾åˆ—å¯»æ‰¾æœ€ä¼˜åˆ†è£‚ã€‚<br>ä¸‹é¢æ˜¯Sklearné‡Œçš„ç›¸å…³å‚æ•°è®¾ç½®çš„ç‰‡æ®µï¼Œ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#code snippets from sklearn.ensemble.gradient_boosting</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GradientBoostingClassifier</span><span class="params">(BaseGradientBoosting, ClassifierMixin)</span>:</span></span><br><span class="line">    <span class="string">"""Gradient Boosting for classification."""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, ..., subsample=<span class="number">1.0</span>, max_features=None,...)</span>:</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">subsample : float, optional (default=1.0)</span></span><br><span class="line"><span class="string">        The fraction of samples to be used for fitting the individual base</span></span><br><span class="line"><span class="string">        learners. If smaller than 1.0 this results in Stochastic Gradient</span></span><br><span class="line"><span class="string">        Boosting. `subsample` interacts with the parameter `n_estimators`.</span></span><br><span class="line"><span class="string">        Choosing `subsample &lt; 1.0` leads to a reduction of variance</span></span><br><span class="line"><span class="string">        and an increase in bias.</span></span><br><span class="line"><span class="string">    max_features : int, float, string or None, optional (default=None)</span></span><br><span class="line"><span class="string">        The number of features to consider when looking for the best split:</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><h3 id="Regularized-Learning-Objective"><a href="#Regularized-Learning-Objective" class="headerlink" title="Regularized Learning Objective"></a>Regularized Learning Objective</h3><p>å°†æ ‘æ¨¡å‹çš„å¤æ‚åº¦ä½œä¸ºæ­£åˆ™é¡¹æ˜¾å¼åœ°åŠ è¿›ä¼˜åŒ–ç›®æ ‡é‡Œï¼Œæ˜¯XGBoostå®ç°çš„ç‹¬åˆ°ä¹‹å¤„ã€‚<br>$$\mathcal{L}^{(t)} = \sum_{i=1}^n l(y_i, y_i^{*(t-1)} + f_t(\mathrm{x}_i)) + \Omega(f_t)$$<br>where<br>$$ \Omega(f)=\gamma T+ \frac{1}{2}\lambda||w||^2$$</p><p>å…¶ä¸­$y_i^{*(t)}$æ˜¯ç¬¬tè½®ç¬¬iä¸ªinstanceçš„é¢„æµ‹å€¼ï¼Œ$f_t$æ˜¯ç¬¬tè½®å»ºçš„æ ‘ï¼Œ$T$æ˜¯æ ‘å¶ç»“ç‚¹æ•°ç›®ï¼Œ$w$æ˜¯æ ‘å¶ç»“ç‚¹çš„è¾“å‡ºï¼Œ$\gamma, \lambda$æ˜¯æ­£åˆ™åŒ–å‚æ•°ã€‚æ·±å…¥äº†è§£åŠ äº†æ­£åˆ™åå¦‚ä½•æ¨å¯¼å‰ƒåº¦æ›´æ–°çš„å¯ä»¥çœ‹XGBoostçš„<a href="http://arxiv.org/abs/1603.02754" target="_blank" rel="noopener">è®ºæ–‡</a>ã€‚</p><p>æˆ‘ä¸ªäººçš„çœ‹æ³•æ˜¯å°†æ ‘æ¨¡å‹çš„å¤æ‚åº¦ä½œä¸ºæ­£åˆ™åŒ–é¡¹åŠ åœ¨ä¼˜åŒ–ç›®æ ‡ï¼Œç›¸æ¯”è‡ªå·±é€šè¿‡å‚æ•°æ§åˆ¶æ¯è½®æ ‘çš„å¤æ‚åº¦æ›´ç›´æ¥ï¼Œè¿™å¯èƒ½æ˜¯XGBoostç›¸æ¯”æ™®é€šGBDTå®ç°æ•ˆæœæ›´å¥½çš„ä¸€ä¸ªå¾ˆé‡è¦çš„åŸå› ã€‚å¾ˆé—æ†¾ï¼ŒSklearnæš‚æ—¶æ— ç›¸åº”çš„å®ç°ã€‚</p><h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><p>Dropoutæ˜¯deep learningé‡Œå¾ˆå¸¸ç”¨çš„æ­£åˆ™åŒ–æŠ€å·§ï¼Œå¾ˆè‡ªç„¶çš„æˆ‘ä»¬ä¼šæƒ³èƒ½ä¸èƒ½æŠŠDropoutç”¨åˆ°GBDTæ¨¡å‹ä¸Šå‘¢ï¼Ÿ<a href="http://www.jmlr.org/proceedings/papers/v38/" target="_blank" rel="noopener">AISTATS2015</a>æœ‰ç¯‡æ–‡ç« [DART: Dropouts meet Multiple Additive Regression Trees](DART: Dropouts meet Multiple Additive Regression Trees)è¿›è¡Œäº†ä¸€äº›å°è¯•ã€‚</p><p>æ–‡ä¸­æåˆ°GBDTé‡Œä¼šå‡ºç°<em>over-specialization</em>çš„é—®é¢˜ï¼š</p><blockquote><p>Trees added at later iterations tend to impact the prediction of only<br>a few instances, and they make negligible contribution<br>towards the prediction of all the remaining instances.<br>We call this issue of subsequent trees affecting the prediction of only<br>a small fraction of the training instances <em>over-specialization</em>.</p></blockquote><p>ä¹Ÿå°±æ˜¯è¯´å‰é¢è¿­ä»£çš„æ ‘å¯¹é¢„æµ‹å€¼çš„è´¡çŒ®æ¯”è¾ƒå¤§ï¼Œåé¢çš„æ ‘ä¼šé›†ä¸­é¢„æµ‹ä¸€å°éƒ¨åˆ†æ ·æœ¬çš„åå·®ã€‚Shrinkageå¯ä»¥å‡è½»<em>over-specialization</em>çš„é—®é¢˜ï¼Œä½†ä¸æ˜¯å¾ˆå¥½ã€‚ä½œè€…æƒ³é€šè¿‡Dropoutæ¥å¹³è¡¡æ‰€æœ‰æ ‘å¯¹é¢„æµ‹çš„è´¡çŒ®ï¼Œå¦‚ä¸‹å›¾çš„æ•ˆæœï¼š<br><img src="/assets/images/gbdt_dart.png" alt=""></p><p>å…·ä½“çš„åšæ³•å¦‚ä¸‹ï¼š</p><blockquote><p>DART divergesfrom MART at two places. First, when computing the<br>gradient that the next tree will fit, only a random subset<br>of the existing ensemble is considered.<br>The second place at which DART diverges from MART<br>is when adding the new tree to the ensemble where<br>DART performs a normalization step.</p></blockquote><p>ç®€å•è¯´å°±æ˜¯æ¯æ¬¡æ–°åŠ ä¸€æ£µæ ‘ï¼Œè¿™æ£µæ ‘è¦æ‹Ÿåˆçš„å¹¶ä¸æ˜¯ä¹‹å‰å…¨éƒ¨æ ‘ensembleåçš„æ®‹å·®ï¼Œè€Œæ˜¯éšæœºæŠ½å–çš„ä¸€äº›æ ‘ensembleï¼›åŒæ—¶æ–°åŠ çš„æ ‘ç»“æœè¦è§„èŒƒåŒ–ä¸€ä¸‹ã€‚</p><p>è¿™ç§æ–°åšæ³•å¯¹GBDTæ•ˆæœçš„æå‡æœ‰å¤šæ˜æ˜¾è¿˜æœ‰å¾…å¤§å®¶æ¢ç´¢å°è¯•ã€‚</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;//gist.github.com/930f5f2f2b315ec967617d88600f16df.js&quot;&gt;&lt;/script&gt;


&lt;p&gt;ä¹‹å‰ä¸€ç¯‡æ–‡ç« ç®€å•åœ°è®²äº†XGBoostçš„å®ç°ä¸æ™®é€šGBDTå®ç°çš„ä¸åŒä¹‹å¤„ï¼Œæœ¬æ–‡å°è¯•æ€»ç»“ä¸€ä¸‹GBDTè¿ç”¨çš„æ­£åˆ™åŒ–æŠ€å·§ã€‚
      
    
    </summary>
    
    
      <category term="æœºå™¨å­¦ä¹ " scheme="http://yixuxi.xyz/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>åšå®¢ç¬¬1æœŸ</title>
    <link href="http://yixuxi.xyz/posts/yuque/%E5%8D%9A%E5%AE%A2%E7%AC%AC1%E6%9C%9F/"/>
    <id>http://yixuxi.xyz/posts/yuque/åšå®¢ç¬¬1æœŸ/</id>
    <published>2019-11-12T22:23:04.000Z</published>
    <updated>2019-11-13T07:23:02.281Z</updated>
    
    <content type="html"><![CDATA[<p>è¯¥åšå®¢æ¨¡ç‰ˆæ¡ˆä¾‹æ¥è‡ª <a href="#">@èš‚èšé‡‘æœä½“éªŒæŠ€æœ¯éƒ¨</a><br><a name="Cpuzj"></a></p><h3 id=""><a href="#" class="headerlink" title=""></a></h3><p>æµ‹è¯•<br><a name="az6uF"></a></p><h3 id="æ’å…¥å¸¦é“¾æ¥çš„æ ‡é¢˜ï¼ˆctrl-Kï¼‰Best-Year-in-Music"><a href="#æ’å…¥å¸¦é“¾æ¥çš„æ ‡é¢˜ï¼ˆctrl-Kï¼‰Best-Year-in-Music" class="headerlink" title="æ’å…¥å¸¦é“¾æ¥çš„æ ‡é¢˜ï¼ˆctrl+Kï¼‰Best Year in Music"></a>æ’å…¥å¸¦é“¾æ¥çš„æ ‡é¢˜ï¼ˆctrl+Kï¼‰<a href="https://pudding.cool/projects/music-history/" target="_blank" rel="noopener">Best Year in Music</a></h3><p>è¿™å¹…å¯è§†åŒ–ä½œå“å±•ç¤ºäº† 1960 å¹´ä»¥æ¥ï¼ŒBillboard å†å¹´æ¦œå•çš„å‰äº”åéŸ³ä¹çš„å˜åŒ–æƒ…å†µï¼Œæ•ˆæœå‘ˆç°è®¾è®¡æ„Ÿåè¶³ï¼Œè¿˜å¯ä»¥åœ¨è†å¬éŸ³ä¹çš„åŒæ—¶å›é¡¾éŸ³ä¹çš„å˜è¿å²ã€‚<br /><img src="https://cdn.nlark.com/yuque/0/2019/png/85075/1569743511172-7dfff3da-684a-4902-babc-cd9117fe3b7a.png#align=left&display=inline&height=648&name=image.png&originHeight=1296&originWidth=2868&search=&size=965213&status=done&width=1434" alt="image.png"><br /><em>æ’å…¥å›¾ç‰‡ï¼Œç‚¹å‡»å›¾ç‰‡ï¼Œè®¾ç½®å›¾ç‰‡å¤§å°</em><br />å€¼å¾—ä¸€æçš„æ˜¯ï¼Œä½œè€…æ­£æ˜¯å¤§åé¼é¼çš„æ•°æ®æ–°é—»ç«™ç‚¹ <a href="https://pudding.cool/" target="_blank" rel="noopener">The Pudding</a>ã€‚ä½œä¸ºå¯è§†åŒ–æ–°é—»åª’ä½“ä¸­çš„å§£å§£è€…ï¼ŒThe Pudding æ“…é•¿å¯¹é‚£äº›å…¼å…·ä¿¡æ¯é‡å’Œå¨±ä¹åº¦çš„äº‰è®®æ€§è¯é¢˜è¿›è¡Œå¯è§†åŒ–å‘ˆç°ï¼Œæ¥ä½¿å¾—å¤æ‚çš„è§‚ç‚¹å˜å¾—æ›´å®¹æ˜“è¢«å…¬ä¼—ç†è§£ã€‚è¯¥å›¢é˜Ÿè™½ç„¶ä»…ç”±æ•°åå…¨èŒè®°è€…å’Œå·¥ç¨‹å¸ˆç»„æˆï¼Œä½†æˆ˜æ–—åŠ›å¼ºæ‚ï¼Œç›®å‰å·²æœ‰æ•°åä¸ªå¤§å‹çš„æ•°æ®å¯è§†åŒ–ä½œå“ã€‚<br />è¾“å…¥ä½œè€… <a href="/dengfuping">@è¯¸å²³(dengfuping)</a><br /><br><br /></p><p><a name="xyPrr"></a></p><h3 id="Road-Suffixes-in-the-USA"><a href="#Road-Suffixes-in-the-USA" class="headerlink" title="Road Suffixes in the USA"></a><a href="https://erdavis.com/2019/07/04/road-suffixes-in-the-usa-take-2/" target="_blank" rel="noopener">Road Suffixes in the USA</a></h3><p>ç¾å›½é“è·¯å‘½åå¤šç§å¤šæ ·ï¼Œä¾‹å¦‚è‘—åçš„çº½çº¦ç¬¬äº”å¤§é“ï¼ˆFifth Avenueï¼‰ï¼Œåˆæˆ–è€…å‡¤å‡°åŸï¼ˆPhoenixï¼‰çš„Washington Streetï¼ŒThomas Roadï¼ŒUnion Hill Driveç­‰ã€‚ä¸åŒçš„é“è·¯ï¼Œæœ‰ä¸åŒçš„å«æ³•ï¼ŒAvenue, Street, Road, Driveç­‰ç­‰ã€‚æƒ³äº†è§£æ›´å¤šå…³äºç¾å›½é“è·¯å‘½åå¯ä»¥å‚è€ƒ<a href="http://blog.sina.com.cn/s/blog_7010d1db0101he93.html" target="_blank" rel="noopener">è¿™ç¯‡æ–‡ç« </a>ã€‚<br />ä½œè€…ç”¨Rè¯­è¨€ç»Ÿè®¡äº†ç¾å›½æ¯ä¸ªå¿çš„æ¯ç§é“è·¯åç¼€ï¼ˆä¾‹å¦‚Avenueï¼‰çš„æ€»é‡Œç¨‹ï¼Œå¹¶æŠŠæ¯ä¸ªå¿æ€»é‡Œç¨‹æœ€å¤§çš„é“è·¯åç¼€é€šè¿‡é¢œè‰²æ˜ å°„åˆ°åœ°å›¾ä¸Šã€‚å¯ä»¥çœ‹å‡ºç¾å›½å¤§éƒ¨åˆ†å¿çš„é“è·¯éƒ½æ˜¯ä»¥Rd(Roadçš„ç¼©å†™)ç»“å°¾çš„ã€‚<br /><img src="https://cdn.nlark.com/yuque/0/2019/png/85075/1569743625739-f1c8b376-5632-4d08-8fcc-56142f0b0c1a.png#align=left&display=inline&height=603&name=road-suffix-map.png&originHeight=1767&originWidth=2048&search=&size=328604&status=done&width=699" alt="road-suffix-map.png"><br /><em>æ’å…¥å›¾ç‰‡ï¼Œç‚¹å‡»å›¾ç‰‡ï¼Œè®¾ç½®å›¾ç‰‡å¤§å°</em></p><p>å¦å¤–è¿˜ä»¥æŸ±çŠ¶å›¾çš„æ–¹å¼å±•ç¤ºäº†æ¯ç§é“è·¯åç¼€çš„æ€»é‡Œç¨‹ï¼ˆè‹±é‡Œï¼‰ï¼š<br /><img src="https://cdn.nlark.com/yuque/0/2019/png/85075/1569743625720-b8759449-4b6a-4b11-bbc0-896fe8dca73e.png#align=left&display=inline&height=737&name=road-suffix-bar.png&originHeight=737&originWidth=890&search=&size=23572&status=done&width=890" alt="road-suffix-bar.png"><br />by <a href="/changzhe">@é•¿å“²(changzhe)</a></p><p><a name="hduVH"></a></p><h1 id="ã€ŒåŠ é¤ã€Hello-World-å›¾å¯è§†åŒ–"><a href="#ã€ŒåŠ é¤ã€Hello-World-å›¾å¯è§†åŒ–" class="headerlink" title="ã€ŒåŠ é¤ã€Hello World å›¾å¯è§†åŒ–"></a><a href="https://zhuanlan.zhihu.com/p/83685690" target="_blank" rel="noopener">ã€Œ</a><a href="https://zhuanlan.zhihu.com/p/83685690" target="_blank" rel="noopener">åŠ é¤ã€</a><a href="https://zhuanlan.zhihu.com/p/83685690" target="_blank" rel="noopener">Hello World å›¾å¯è§†åŒ–</a></h1><p>å›¾å¯è§†åŒ–æ˜¯ä¿¡æ¯å¯è§†åŒ–çš„å­é¢†åŸŸï¼Œå®ƒé€šè¿‡å±•ç¤ºå…ƒç´ ã€å…³ç³»ï¼Œå¸®åŠ©ç”¨æˆ·è·å–æ•°æ®çš„æ´æ‚‰èƒ½åŠ›ã€‚å®ƒå·²è¢«å¹¿æ³›åœ°åº”ç”¨åœ¨æµç¨‹å›¾ã€ç¤¾äº¤ç½‘ç»œã€è‹±ç‰¹ç½‘ã€è›‹ç™½è´¨ç½‘ç»œç­‰å…³ç³»æ•°æ®çš„å‘ˆç°ã€‚<br /><a href="https://zhuanlan.zhihu.com/p/83685690" target="_blank" rel="noopener">æœ¬æ–‡</a>ç”± AntV å›¢é˜Ÿ <a href="/shiwu-5wap2">@åå¾(shiwu-5wap2)</a> ğŸ‘†æ’°å†™ï¼Œå‚è€ƒè‡ª[1][2]ä¸¤ç¯‡å›¾å¯è§†åŒ–å­¦æœ¯è®ºæ–‡ï¼Œç®€è¦ä»‹ç»å›¾å¯è§†åŒ–çš„å†å²ã€èƒŒæ™¯ã€æœºé‡ä¸æŒ‘æˆ˜ã€‚</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;è¯¥åšå®¢æ¨¡ç‰ˆæ¡ˆä¾‹æ¥è‡ª &lt;a href=&quot;#&quot;&gt;@èš‚èšé‡‘æœä½“éªŒæŠ€æœ¯éƒ¨&lt;/a&gt;&lt;br&gt;&lt;a name=&quot;Cpuzj&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;&quot;&gt;&lt;a href=&quot;#&quot; class=&quot;headerlink&quot; title=&quot;&quot;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;æµ‹è¯•&lt;br&gt;&lt;a n
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>å¦‚ä½•å­¦ä¹ æ•°æ®ç§‘å­¦</title>
    <link href="http://yixuxi.xyz/posts/yuque/%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    <id>http://yixuxi.xyz/posts/yuque/å¦‚ä½•å­¦ä¹ æ•°æ®ç§‘å­¦/</id>
    <published>2019-07-22T08:08:11.000Z</published>
    <updated>2019-11-13T07:23:02.277Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>å¦‚ä½•å­¦ä¹  pandas</title>
    <link href="http://yixuxi.xyz/posts/yuque/%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0%20pandas/"/>
    <id>http://yixuxi.xyz/posts/yuque/å¦‚ä½•å­¦ä¹  pandas/</id>
    <published>2019-07-22T08:07:44.000Z</published>
    <updated>2019-11-13T07:23:02.277Z</updated>
    
    <content type="html"><![CDATA[<p><a name="eDcbx"></a></p><h2 id="ç›¸å…³å‚è€ƒèµ„æ–™"><a href="#ç›¸å…³å‚è€ƒèµ„æ–™" class="headerlink" title="ç›¸å…³å‚è€ƒèµ„æ–™"></a>ç›¸å…³å‚è€ƒèµ„æ–™</h2><p>hello pandas <a href="https://www.kaggle.com/colinmorris/hello-python" target="_blank" rel="noopener">https://www.kaggle.com/colinmorris/hello-python</a><br />pandas cards <a href="https://assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf" target="_blank" rel="noopener">https://assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf</a><br /><a href="https://www.kaggle.com/residentmario/creating-reading-and-writing" target="_blank" rel="noopener">https://www.kaggle.com/residentmario/creating-reading-and-writing</a><br /><a href="https://www.kaggle.com/jabari/exercise-explore-your-data/edit" target="_blank" rel="noopener">https://www.kaggle.com/jabari/exercise-explore-your-data/edit</a><br /><a href="https://www.kaggle.com/dansbecker/basic-data-exploration" target="_blank" rel="noopener">https://www.kaggle.com/dansbecker/basic-data-exploration</a><br /><a href="https://wiki.python.org/moin/BeginnersGuide/NonProgrammers" target="_blank" rel="noopener">https://wiki.python.org/moin/BeginnersGuide/NonProgrammers</a><br><a name="770Sw"></a></p><h2 id="ç›¸å…³ç»ƒä¹ "><a href="#ç›¸å…³ç»ƒä¹ " class="headerlink" title="ç›¸å…³ç»ƒä¹ "></a>ç›¸å…³ç»ƒä¹ </h2><pre><code>titanic [https://www.kaggle.com/c/titanic](https://www.kaggle.com/c/titanic)</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a name=&quot;eDcbx&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;ç›¸å…³å‚è€ƒèµ„æ–™&quot;&gt;&lt;a href=&quot;#ç›¸å…³å‚è€ƒèµ„æ–™&quot; class=&quot;headerlink&quot; title=&quot;ç›¸å…³å‚è€ƒèµ„æ–™&quot;&gt;&lt;/a&gt;ç›¸å…³å‚è€ƒèµ„æ–™&lt;/h2&gt;&lt;p&gt;hello pandas &lt;a href=&quot;http
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>ã€Šæœºå™¨å­¦ä¹ ã€‹è¥¿ç“œä¹¦é˜…è¯»ç¬”è®° | SF-Zhou&amp;#39;s Blog</title>
    <link href="http://yixuxi.xyz/posts/yuque/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%A5%BF%E7%93%9C%E4%B9%A6%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%20%7C%20SF-Zhou&#39;s%20Blog/"/>
    <id>http://yixuxi.xyz/posts/yuque/ã€Šæœºå™¨å­¦ä¹ ã€‹è¥¿ç“œä¹¦é˜…è¯»ç¬”è®° | SF-Zhou&#39;s Blog/</id>
    <published>2019-04-03T02:31:13.000Z</published>
    <updated>2019-11-13T07:23:02.269Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ç¬¬-1-ç« -ç»ªè®º"><a href="#ç¬¬-1-ç« -ç»ªè®º" class="headerlink" title="ç¬¬ 1 ç«  ç»ªè®º"></a>ç¬¬ 1 ç«  ç»ªè®º</h2><h3 id="åŸºæœ¬æœ¯è¯­"><a href="#åŸºæœ¬æœ¯è¯­" class="headerlink" title="åŸºæœ¬æœ¯è¯­"></a>åŸºæœ¬æœ¯è¯­</h3><p><code>æœºå™¨å­¦ä¹ </code>ï¼šåœ¨è®¡ç®—æœºä¸Šä»<code>æ•°æ®</code>ï¼ˆdataï¼‰ä¸­äº§ç”Ÿ<code>æ¨¡å‹</code>ï¼ˆmodelï¼‰çš„ç®—æ³•ï¼Œå³<code>å­¦ä¹ ç®—æ³•</code>ï¼ˆlearning algorithmï¼‰ã€‚</p><p>A computer program is said to learn from experience EEE with respect to some class of tasks TTT and performance measure PPP, if its performance at tasks in TTT, as measured by PPP, improves with experience EEE.</p><p>ä¸€èˆ¬åœ°ï¼Œä»¤ D={xâƒ—1,xâƒ—2,â‹¯,xâƒ—m}D = \left \{ \vec {x}_1, \vec {x}_2, \cdots, \vec {x}_m \right \}D={x1â€‹,x2â€‹,â‹¯,xmâ€‹} è¡¨ç¤ºåŒ…å« mmm ä¸ª<code>æ ·æœ¬</code>ï¼ˆsampleï¼‰çš„æ•°æ®é›†ï¼Œæ¯ä¸ªç¤ºä¾‹ç”± ddd ä¸ª<code>å±æ€§</code>ï¼ˆattributeï¼‰æè¿°ï¼Œåˆ™æ¯ä¸ªæ ·æœ¬ xâƒ—i={xi1;xi2;â‹¯;xid}\vec x_i = \left \{x_{i1}; x_{i2}; \cdots; x_{id} \right \}xiâ€‹={xi1â€‹;xi2â€‹;â‹¯;xidâ€‹} æ˜¯ ddd ç»´æ ·æœ¬ç©ºé—´ X\mathcal{X}X ä¸­çš„ä¸€ä¸ªå‘é‡ï¼Œxâƒ—iâˆˆX\vec x_i \in \mathcal{X}xiâ€‹âˆˆXï¼Œå…¶ä¸­ xijx_{ij}xijâ€‹ æ˜¯ xâƒ—i\vec x_ixiâ€‹ åœ¨ç¬¬ jjj ä¸ªå±æ€§ä¸Šçš„å–å€¼ï¼Œddd ç§°ä¸ºæ ·æœ¬ xâƒ—i\vec x_ixiâ€‹ çš„<code>ç»´æ•°</code>ï¼ˆdimensionalityï¼‰ã€‚</p><p>å±æ€§å¼ æˆçš„ç©ºé—´ç§°ä¸º<code>æ ·æœ¬ç©ºé—´</code>ï¼ˆsample spaceï¼‰ï¼Œæ¯ä¸ªæ ·æœ¬éƒ½å¯åœ¨è¿™ä¸ªç©ºé—´ä¸­æ‰¾åˆ°å”¯ä¸€çš„åæ ‡ä½ç½®ï¼Œå› æ­¤ä¹ŸæŠŠä¸€ä¸ªæ ·æœ¬ç§°ä¸ºä¸€ä¸ª<code>ç‰¹å¾å‘é‡</code>ï¼ˆfeature vectorï¼‰ã€‚</p><p>ä»æ•°æ®ä¸­å­¦å¾—æ¨¡å‹çš„è¿‡ç¨‹ç§°ä¹‹ä¸º<code>å­¦ä¹ </code>ï¼ˆlearningï¼‰æˆ–<code>è®­ç»ƒ</code>ï¼ˆtrainingï¼‰ï¼Œå­¦å¾—æ¨¡å‹é€‚ç”¨äºæ–°æ ·æœ¬çš„èƒ½åŠ›ç§°ä¸º<code>æ³›åŒ–</code>ï¼ˆgeneralizationï¼‰èƒ½åŠ›ã€‚</p><h3 id="å‡è®¾ç©ºé—´"><a href="#å‡è®¾ç©ºé—´" class="headerlink" title="å‡è®¾ç©ºé—´"></a>å‡è®¾ç©ºé—´</h3><p><code>å½’çº³</code>ï¼ˆinductionï¼‰ä¸<code>æ¼”ç»</code>ï¼ˆdeductionï¼‰æ˜¯ç§‘å­¦æ¨ç†çš„ä¸¤å¤§åŸºæœ¬æ‰‹æ®µã€‚å‰è€…æ˜¯ä»ç‰¹æ®Šåˆ°ä¸€èˆ¬çš„æ³›åŒ–ï¼ˆgeneralizationï¼‰è¿‡ç¨‹ï¼Œåè€…æ˜¯ä»ä¸€èˆ¬åˆ°ç‰¹æ®Šçš„ç‰¹åŒ–ï¼ˆspecializationï¼‰è¿‡ç¨‹ã€‚ä»æ ·ä¾‹ä¸­å­¦ä¹ æ˜¯ä¸€ä¸ªå½’çº³çš„è¿‡ç¨‹ï¼Œäº¦ç§°<code>å½’çº³å­¦ä¹ </code>ï¼ˆinductive learningï¼‰ã€‚</p><p>ç‹­ä¹‰çš„å½’çº³å­¦ä¹ æ˜¯ä»æ•°æ®ä¸­å­¦å¾—<code>æ¦‚å¿µ</code>ï¼ˆconceptï¼‰ï¼Œæœ€åŸºæœ¬çš„æ¦‚å¿µå­¦ä¹ æ˜¯å¸ƒå°”æ¦‚å¿µå­¦ä¹ ã€‚å¯ä»¥æŠŠå­¦ä¹ çš„è¿‡ç¨‹çœ‹ä½œä¸€ä¸ªåœ¨æ‰€æœ‰<code>å‡è®¾</code>ï¼ˆhypothesisï¼‰ç»„æˆçš„ç©ºé—´ä¸­è¿›è¡Œæœç´¢çš„è¿‡ç¨‹ï¼Œæœç´¢ç›®æ ‡æ˜¯æ‰¾åˆ°ä¸è®­ç»ƒé›†<code>åŒ¹é…</code>ï¼ˆfitï¼‰çš„å‡è®¾ã€‚</p><p>å‡è®¾çš„è¡¨ç¤ºä¸€æ—¦ç¡®å®šï¼Œ<code>å‡è®¾ç©ºé—´</code>ï¼ˆhypothesis spaceï¼‰åŠå…¶è§„æ¨¡å¤§å°å°±ç¡®å®šäº†ã€‚ç°å®é—®é¢˜ä¸­é€šå¸¸é¢ä¸´å¾ˆå¤§çš„å‡è®¾ç©ºé—´ï¼Œä½†æ ·æœ¬è®­ç»ƒé›†æ˜¯æœ‰é™çš„ï¼Œå› æ­¤å¯èƒ½æœ‰å¤šä¸ªå‡è®¾ä¸è®­ç»ƒé›†ä¸€è‡´ï¼Œå³å­˜åœ¨ä¸€ä¸ªä¸è®­ç»ƒé›†ä¸€è‡´çš„å‡è®¾é›†åˆï¼Œç§°ä¹‹ä¸º<code>ç‰ˆæœ¬ç©ºé—´</code>ï¼ˆversion spaceï¼‰ã€‚</p><h3 id="å½’çº³åå¥½"><a href="#å½’çº³åå¥½" class="headerlink" title="å½’çº³åå¥½"></a>å½’çº³åå¥½</h3><p>æœºå™¨å­¦ä¹ ç®—æ³•åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å¯¹æŸç§ç±»å‹å‡è®¾çš„åå¥½ï¼Œç§°ä¸º<code>å½’çº³åå¥½</code>ï¼ˆinductive biasï¼‰ã€‚å½’çº³åå¥½å¯çœ‹ä½œæ˜¯å­¦ä¹ ç®—æ³•åœ¨åºå¤§çš„å‡è®¾ç©ºé—´ä¸­å¯¹å‡è®¾è¿›è¡Œé€‰æ‹©çš„ä»·å€¼è§‚ã€‚</p><p><code>å¥¥å¡å§†å‰ƒåˆ€</code>ï¼ˆOccamâ€™s Razorï¼‰æ˜¯è‡ªç„¶ç§‘å­¦ç ”ç©¶ä¸­å¸¸ç”¨çš„åŸåˆ™ï¼Œå³è‹¥å­˜åœ¨å¤šä¸ªå‡è®¾ä¸è§‚å¯Ÿä¸€è‡´ï¼Œåˆ™é€‰æœ€ç®€å•çš„é‚£ä¸ªã€‚å¦‚æ— å¿…è¦ï¼Œå‹¿å¢å®ä½“ã€‚</p><p>ä½†å¥¥å¡å§†å‰ƒåˆ€åŸåˆ™å¹¶ä¸å¹³å‡¡ï¼Œâ€œç®€å•â€çš„è¯„ä»·æ ‡å‡†æ— æ³•é‡åŒ–ã€‚äº‹å®ä¸Šå½’çº³åå¥½å¯¹åº”äº†å­¦ä¹ ç®—æ³•æœ¬èº«æ‰€åšå‡ºçš„å…³äºâ€œä»€ä¹ˆæ ·çš„æ¨¡å‹æ›´å¥½â€çš„å‡è®¾ã€‚<code>æ²¡æœ‰å…è´¹çš„åˆé¤å®šç†</code>ï¼ˆNo Free Lunch Theoremï¼ŒNFLï¼‰è¯æ˜äº†åœ¨çœŸå®ç›®æ ‡å‡½æ•° fff å‡åŒ€åˆ†å¸ƒçš„æƒ…å†µä¸‹ï¼Œæ‰€æœ‰å­¦ä¹ ç®—æ³•å­¦å¾—çš„æ¨¡å‹æœŸæœ›æ€§èƒ½æ˜¯ä¸€è‡´çš„ã€‚</p><p>è„±ç¦»å®é™…é—®é¢˜ï¼Œç©ºè°ˆâ€œä»€ä¹ˆå­¦ä¹ ç®—æ³•æ›´å¥½â€æ¯«æ— æ„ä¹‰ã€‚</p><h2 id="ç¬¬-2-ç« -æ¨¡å‹è¯„ä¼°ä¸é€‰æ‹©"><a href="#ç¬¬-2-ç« -æ¨¡å‹è¯„ä¼°ä¸é€‰æ‹©" class="headerlink" title="ç¬¬ 2 ç«  æ¨¡å‹è¯„ä¼°ä¸é€‰æ‹©"></a>ç¬¬ 2 ç«  æ¨¡å‹è¯„ä¼°ä¸é€‰æ‹©</h2><h3 id="ç»éªŒè¯¯å·®ä¸è¿‡æ‹Ÿåˆ"><a href="#ç»éªŒè¯¯å·®ä¸è¿‡æ‹Ÿåˆ" class="headerlink" title="ç»éªŒè¯¯å·®ä¸è¿‡æ‹Ÿåˆ"></a>ç»éªŒè¯¯å·®ä¸è¿‡æ‹Ÿåˆ</h3><p>å­¦ä¹ å™¨çš„å®é™…è¾“å‡ºä¸æ ·æœ¬çš„çœŸå®è¾“å‡ºä¹‹é—´çš„å·®å¼‚ç§°ä¸º<code>è¯¯å·®</code>ï¼ˆerrorï¼‰ï¼Œè®­ç»ƒé›†ä¸Šçš„è¯¯å·®ç§°ä¸º<code>è®­ç»ƒè¯¯å·®</code>ï¼ˆtraining errorï¼‰ï¼Œæ–°æ ·æœ¬ä¸Šçš„è¯¯å·®ç§°ä¸º<code>æ³›åŒ–è¯¯å·®</code>ï¼ˆgeneralization errorï¼‰ã€‚</p><p>ä¸ºäº†ä½¿æ³›åŒ–è¯¯å·®æœ€å°åŒ–ï¼Œåº”è¯¥ä»è®­ç»ƒæ ·æœ¬ä¸­å°½å¯èƒ½å­¦å‡ºé€‚ç”¨äºæ‰€æœ‰æ½œåœ¨æ ·æœ¬çš„â€œæ™®éè§„å¾‹â€ã€‚è€Œå°†è®­ç»ƒæ ·æœ¬çš„ç‰¹ç‚¹å½“ä½œäº†æ‰€æœ‰æ½œåœ¨æ ·æœ¬çš„ä¸€èˆ¬æ€§è´¨ï¼Œå¯¼è‡´æ³›åŒ–æ€§èƒ½ä¸‹é™çš„ç°è±¡ï¼Œç§°ä¸º<code>è¿‡æ‹Ÿåˆ</code>ï¼ˆoverfittingï¼‰ï¼Œç›¸å¯¹åœ°æ²¡æœ‰å……åˆ†ä¹ å¾—è®­ç»ƒæ ·æœ¬çš„ä¸€èˆ¬æ€§è´¨çš„ç°è±¡ï¼Œç§°ä¸º<code>æ¬ æ‹Ÿåˆ</code>ï¼ˆunderfittingï¼‰ã€‚</p><p>ç°å®ä»»åŠ¡ä¸­ï¼Œå­˜åœ¨å¤šç§å­¦ä¹ ç®—æ³•ã€ä¸åŒå‚æ•°é…ç½®ï¼Œäº§ç”Ÿä¸åŒçš„æ¨¡å‹ï¼Œéœ€è¦é€‰æ‹©å…¶ä¸­åˆé€‚çš„æ¨¡å‹ï¼Œè¯¥é—®é¢˜ç§°ä¸º<code>æ¨¡å‹é€‰æ‹©</code>ï¼ˆmodel selectionï¼‰é—®é¢˜ã€‚ç†æƒ³çŠ¶æ€ä¸‹ä½¿ç”¨æ³›åŒ–è¯¯å·®ä½œä¸ºæ¨¡å‹é€‰æ‹©çš„è¯„ä»·æ ‡å‡†ï¼Œä½†æ³›åŒ–è¯¯å·®æ— æ³•ç›´æ¥è·å¾—ã€‚</p><h3 id="è¯„ä¼°æ–¹æ³•"><a href="#è¯„ä¼°æ–¹æ³•" class="headerlink" title="è¯„ä¼°æ–¹æ³•"></a>è¯„ä¼°æ–¹æ³•</h3><p>é€šå¸¸ä½¿ç”¨<code>æµ‹è¯•é›†</code>ï¼ˆtesting setï¼‰æ¥æµ‹è¯•å­¦ä¹ å™¨å¯¹æ–°æ ·æœ¬çš„åˆ¤åˆ«èƒ½åŠ›ï¼Œä»¥æµ‹è¯•é›†ä¸Šçš„<code>æµ‹è¯•è¯¯å·®</code>ï¼ˆtesting errorï¼‰ä½œä¸ºæ³›åŒ–è¯¯å·®çš„è¿‘ä¼¼ã€‚é€šå¸¸å‡è®¾æµ‹è¯•æ ·æœ¬æ˜¯ä»æ ·æœ¬çœŸå®åˆ†å¸ƒä¸­ç‹¬ç«‹åŒåˆ†å¸ƒé‡‡æ ·è€Œå¾—ã€‚</p><p>å¯¹äºåŒ…å« mmm ä¸ªæ ·æœ¬çš„æ•°æ®é›† D={(xâƒ—1,y1),(xâƒ—2,y2),â‹¯,(xâƒ—m,ym)}D = \left \{ (\vec x_1, y_1), (\vec x_2, y_2), \cdots, (\vec x_m, y_m) \right \}D={(x1â€‹,y1â€‹),(x2â€‹,y2â€‹),â‹¯,(xmâ€‹,ymâ€‹)}ï¼Œéœ€è¦å°†å…¶åˆ†è§£ä¸ºè®­ç»ƒé›† SSSã€éªŒè¯é›† VVV å’Œæµ‹è¯•é›† TTTï¼Œå¸¸ç”¨çš„æ–¹æ³•æœ‰ç•™å‡ºæ³•ã€äº¤å‰éªŒè¯æ³•å’Œ<code>è‡ªåŠ©æ³•</code>ï¼ˆbootstrappingï¼‰ã€‚</p><p>è‡ªåŠ©æ³•å³ä»æ•°æ®é›†ä¸­è¿›è¡Œ mmm æ¬¡å¯é‡å¤é‡‡æ ·ï¼Œå¯ä»¥é€‰å‡ºçº¦ 36.8% çš„æ ·æœ¬ä½œä¸ºæµ‹è¯•é›†ï¼Œåœ¨æ•°æ®é›†è¾ƒå°æ—¶è¾ƒä¸ºæœ‰æ•ˆã€‚</p><p>æœºå™¨å­¦ä¹ å¸¸æ¶‰åŠä¸¤ç±»å‚æ•°ï¼šä¸€æ˜¯ç®—æ³•çš„å‚æ•°ï¼Œç§°ä¸º<code>è¶…å‚æ•°</code>ï¼ˆhyper parameterï¼‰ï¼Œä¸€æ˜¯æ¨¡å‹çš„å‚æ•°ã€‚å¯¹è¶…å‚æ•°è¿›è¡Œè®¾å®šè°ƒä¼˜çš„è¿‡ç¨‹ç§°ä¸º<code>è°ƒå‚</code>ï¼ˆparameter tuningï¼‰ã€‚é€šå¸¸ä½¿ç”¨éªŒè¯é›†è¿›è¡Œæ¨¡å‹é€‰æ‹©å’Œè°ƒå‚ï¼Œä½¿ç”¨æµ‹è¯•é›†è¯„ä¼°æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</p><h3 id="æ€§èƒ½åº¦é‡"><a href="#æ€§èƒ½åº¦é‡" class="headerlink" title="æ€§èƒ½åº¦é‡"></a>æ€§èƒ½åº¦é‡</h3><p>æ€§èƒ½åº¦é‡ï¼ˆperformance measureï¼‰ï¼Œå³ä¸ºæ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„è¯„ä»·æ ‡å‡†ã€‚ç»™å®šæ•°æ®é›† D={(xâƒ—1,y1),(xâƒ—2,y2),â‹¯,(xâƒ—m,ym)}D = \left \{ (\vec x_1, y_1), (\vec x_2, y_2), \cdots, (\vec x_m, y_m) \right \}D={(x1â€‹,y1â€‹),(x2â€‹,y2â€‹),â‹¯,(xmâ€‹,ymâ€‹)}ï¼Œå…¶ä¸­ yiy_iyiâ€‹ æ˜¯æ ·æœ¬ xâƒ—i\vec x_ixiâ€‹ çš„çœŸå®æ ‡è®°ã€‚</p><p>å›å½’ä»»åŠ¡å¸¸ç”¨çš„æ€§èƒ½åº¦é‡æ˜¯<code>å‡æ–¹è¯¯å·®</code>ï¼ˆmean squared errorï¼‰ï¼š</p><p>E(f;D)=âˆ«xâƒ—âˆ¼D(f(xâƒ—)âˆ’y)2p(xâƒ—)dxâƒ— E(f; \mathcal{D}) = \int_{\vec x \sim \mathcal D} (f(\vec x) - y)^2 p(\vec {x}) d\vec x E(f;D)=âˆ«xâˆ¼Dâ€‹(f(x)âˆ’y)2p(x)dx</p><p>åˆ†ç±»ä»»åŠ¡å¸¸ç”¨çš„æ€§èƒ½åº¦é‡è¾ƒå¤šï¼Œå¸¸ç”¨çš„é”™è¯¯ç‡ï¼š</p><p>E(f;D)=âˆ«xâƒ—âˆ¼DI(f(xâƒ—)â‰ y)p(xâƒ—)dxâƒ— E(f; \mathcal{D}) = \int_{\vec x \sim \mathcal D} \mathbb I(f(\vec x) \neq y) p(\vec {x}) d\vec x E(f;D)=âˆ«xâˆ¼Dâ€‹I(f(x)Ì¸â€‹=y)p(x)dx</p><p><code>å‡†ç¡®ç‡</code>ï¼ˆpercisionï¼‰å’Œ<code>å¬å›ç‡</code>ï¼ˆrecallï¼‰ï¼š</p><p>P=TPTP+FPR=TPTP+FN \begin{aligned} P &amp;= \frac {TP} {TP + FP} \\ R &amp;= \frac {TP} {TP + FN} \end{aligned} PRâ€‹=TP+FPTPâ€‹=TP+FNTPâ€‹â€‹</p><p>é¢„æµ‹æ­£ä¾‹</p><p>é¢„æµ‹è´Ÿä¾‹</p><p>çœŸå®æ­£ä¾‹</p><p>TP</p><p>FN</p><p>çœŸå®è´Ÿä¾‹</p><p>FP</p><p>TN</p><p>å‡†ç¡®ç‡å’Œå¬å›ç‡ä¸å¯å¾—å…¼ã€‚ä»¥å‡†ç¡®ç‡ä½œä¸ºçºµè½´ã€å¬å›ç‡ä½œä¸ºæ¨ªè½´ï¼Œå¯ä»¥å¾—åˆ°<code>P-Ræ›²çº¿</code>ï¼Œæ›²çº¿ä¸­â€œå‡†ç¡®ç‡=å¬å›ç‡â€çš„ç‚¹æˆä¸º<code>å¹³è¡¡ç‚¹</code>ï¼ˆBreak-Even Pointï¼‰ã€‚</p><p>å‡†ç¡®ç‡å’Œå¬å›ç‡çš„<code>è°ƒå’Œå¹³å‡</code>ï¼ˆharmonic meanï¼‰ç§°ä¸º<code>F1</code>åº¦é‡ï¼š</p><p>1F1=12(1P+1R)F1=2PRP+R \begin{aligned} \frac {1} {F1} &amp;= \frac {1} {2} (\frac {1} {P} + \frac {1} {R}) \\ F1 &amp;= \frac {2PR} {P + R} \end{aligned} F11â€‹F1â€‹=21â€‹(P1â€‹+R1â€‹)=P+R2PRâ€‹â€‹</p><p>ç”±å¤šç»„æ··æ·†çŸ©é˜µè®¡ç®—å¤šç»„å‡†ç¡®ç‡å’Œå¬å›ç‡ï¼Œå†æ±‚å¹³å‡å€¼ï¼Œå¯å¾—<code>å®å‡†ç¡®ç‡</code>ï¼ˆmacro-Pï¼‰å’Œ<code>å®å¬å›ç‡</code>ï¼ˆmacro-Rï¼‰ï¼›å°†å¤šç»„æ··æ·†çŸ©é˜µæ±‚å¹³å‡å€¼ï¼Œå†æ±‚å‡†ç¡®ç‡å’Œå¬å›ç‡ï¼Œå¯å¾—<code>å¾®å‡†ç¡®ç‡</code>ï¼ˆmicro-Pï¼‰å’Œ<code>å¾®å¬å›ç‡</code>ï¼ˆmicro-Rï¼‰ã€‚</p><p><code>ROC</code> å…¨ç§°å—è¯•è€…å·¥ä½œç‰¹å¾ï¼ˆReceiver Operating Characteristicï¼‰ï¼Œè¯¥æ›²çº¿ä»¥<code>çœŸæ­£ä¾‹ç‡</code>ï¼ˆTrue Positive Rateï¼‰ä¸ºçºµè½´ï¼Œä»¥<code>å‡æ­£ä¾‹ç‡</code>ï¼ˆFalse Positive Rateï¼‰ä¸ºæ¨ªè½´ï¼š</p><p>TPR=TPTP+FNFPR=FPTN+FP \begin{aligned} TPR &amp;= \frac {TP} {TP + FN} \\ FPR &amp; = \frac {FP} {TN + FP} \end{aligned} TPRFPRâ€‹=TP+FNTPâ€‹=TN+FPFPâ€‹â€‹</p><p>ROC æ›²çº¿ä¸‹çš„é¢ç§¯ç§°ä¸º<code>AUC</code>ï¼ˆArea Under ROC Curveï¼‰ï¼Œé€šå¸¸ä½¿ç”¨ AUC ä½œä¸ºROC æ›²çº¿ä¼˜åŠ£çš„åˆ¤æ–­ä¾æ®ã€‚</p><p>ä¸åŒç±»å‹çš„é”™è¯¯æ‰€é€ æˆçš„åæœä¸åŒï¼Œä¸ºæƒè¡¡ä¸åŒç±»å‹é”™è¯¯æ‰€é€ æˆçš„ä¸åŒæŸå¤±ï¼Œå¯ä¸ºé”™è¯¯èµ‹äºˆ<code>éå‡ç­‰ä»£ä»·</code>ï¼ˆunequal costï¼‰ã€‚ä»¤ D+D^+D+ ä¸ Dâˆ’D^-Dâˆ’ ä»£è¡¨æ•°æ®é›† DDD ä¸­çš„æ­£ä¾‹å­é›†å’Œåä¾‹å­é›†ï¼Œåˆ™<code>ä»£ä»·æ•æ„Ÿ</code>ï¼ˆcost-sensitiveï¼‰é”™è¯¯ç‡ä¸ºï¼š</p><p>E(f;D;cost)=1m(âˆ‘xâƒ—iâˆˆD+I(f(xâƒ—i)â‰ yi)cost01+âˆ‘xâƒ—iâˆˆDâˆ’I(f(xâƒ—i)â‰ yi)cost10) E(f; D; cost) = \frac {1} {m} \left ( \sum_{\vec x_i \in D^+} \mathbb I (f(\vec x_i) \neq y_i) cost_{01} + \sum_{\vec x_i \in D^-} \mathbb I (f(\vec x_i) \neq y_i) cost_{10} \right ) E(f;D;cost)=m1â€‹ââ›â€‹xiâ€‹âˆˆD+âˆ‘â€‹I(f(xiâ€‹)Ì¸â€‹=yiâ€‹)cost01â€‹+xiâ€‹âˆˆDâˆ’âˆ‘â€‹I(f(xiâ€‹)Ì¸â€‹=yiâ€‹)cost10â€‹â ââ€‹</p><h3 id="åå·®ä¸æ–¹å·®"><a href="#åå·®ä¸æ–¹å·®" class="headerlink" title="åå·®ä¸æ–¹å·®"></a>åå·®ä¸æ–¹å·®</h3><p><code>åå·®-æ–¹å·®åˆ†è§£</code>ï¼ˆbias-veriance decompositionï¼‰æ˜¯è§£é‡Šå­¦ä¹ ç®—æ³•æ³›åŒ–æ€§èƒ½çš„ä¸€ç§é‡è¦å·¥å…·ã€‚å¯¹æµ‹è¯•æ ·æœ¬ xâƒ—\vec xxï¼Œä»¤ yDy_DyDâ€‹ ä¸º xâƒ—\vec xx åœ¨æ•°æ®é›†ä¸­çš„æ ‡è®°ï¼Œyyy ä¸º xâƒ—\vec xx çš„çœŸå®æ ‡è®°ï¼Œf(xâƒ—;D)f(\vec x; D)f(x;D) ä¸ºè®­ç»ƒé›† DDD ä¸Šå­¦çš„æ¨¡å‹ fff åœ¨ xâƒ—\vec xx ä¸Šçš„é¢„æµ‹è¾“å‡ºã€‚ä»¥å›å½’ä»»åŠ¡ä¸ºä¾‹ï¼Œå­¦ä¹ ç®—æ³•çš„æœŸæœ›é¢„æµ‹ä¸ºï¼š</p><p>fË‰(xâƒ—)=ED[f(xâƒ—;D)] \bar f(\vec x) = \mathbb E_D \left [ f(\vec x; D) \right ] fË‰â€‹(x)=EDâ€‹[f(x;D)]</p><p>æœŸæœ›è¾“å‡ºä¸çœŸå®æ ‡è®°çš„å·®åˆ«ç§°ä¸º<code>åå·®</code>ï¼ˆbiasï¼‰ï¼š</p><p>bias2(xâƒ—)=(fË‰(xâƒ—)âˆ’y)2 bias^2(\vec x) = \left ( \bar f(\vec x) - y \right )^2 bias2(x)=(fË‰â€‹(x)âˆ’y)2</p><p>ä½¿ç”¨æ ·æœ¬æ•°ç›¸åŒçš„ä¸åŒè®­ç»ƒé›†äº§ç”Ÿçš„<code>æ–¹å·®</code>ï¼ˆvarianceï¼‰ä¸ºï¼š</p><p>var(xâƒ—)=ED[(f(xâƒ—;D)âˆ’fË‰(xâƒ—))2] var(\vec x) = \mathbb E_D \left [ \left (f(\vec x; D) - \bar f(\vec x) \right )^2 \right ] var(x)=EDâ€‹[(f(x;D)âˆ’fË‰â€‹(x))2]</p><p>å™ªå£°ä¸ºï¼š</p><p>Îµ2=ED[(yDâˆ’y)2] \varepsilon ^2 = \mathbb E_D \left [ (y_D - y)^2 \right ] Îµ2=EDâ€‹[(yDâ€‹âˆ’y)2]</p><p>å‡å®šå™ªå£°çš„æœŸæœ›ä¸ºé›¶ï¼Œå¯å¾—ï¼š</p><p>E(f;D)=bias2(xâƒ—)+var(xâƒ—)+Îµ2 E(f; D) = bias^2(\vec x) + var(\vec x) + \varepsilon ^2 E(f;D)=bias2(x)+var(x)+Îµ2</p><p>å³æ³›åŒ–è¯¯å·®å¯ä»¥åˆ†è§£ä¸ºåå·®ã€æ–¹å·®å’Œå™ªå£°ä¹‹å’Œã€‚åå·®å’Œæ–¹å·®é—´å­˜åœ¨<code>åå·®-æ–¹å·®çª˜å¢ƒ</code>ï¼ˆbias-variance dilemmaï¼‰ï¼Œå½“å­¦ä¹ ç®—æ³•è®­ç»ƒä¸è¶³æ—¶ï¼Œå­¦ä¹ å™¨çš„æ‹Ÿåˆèƒ½åŠ›ä¸å¤Ÿå¼ºï¼Œåå·®ä¸»å¯¼äº†æ³›åŒ–é”™è¯¯ç‡ï¼›å½“è®­ç»ƒç¨‹åº¦åŠ æ·±åï¼Œå­¦ä¹ å™¨çš„æ‹Ÿåˆèƒ½åŠ›è¶³å¤Ÿï¼Œæ–¹å·®ä¸»å¯¼äº†æ³›åŒ–é”™è¯¯ç‡ã€‚</p><h2 id="ç¬¬-3-ç« -çº¿æ€§æ¨¡å‹"><a href="#ç¬¬-3-ç« -çº¿æ€§æ¨¡å‹" class="headerlink" title="ç¬¬ 3 ç«  çº¿æ€§æ¨¡å‹"></a>ç¬¬ 3 ç«  çº¿æ€§æ¨¡å‹</h2><h3 id="åŸºæœ¬å½¢å¼"><a href="#åŸºæœ¬å½¢å¼" class="headerlink" title="åŸºæœ¬å½¢å¼"></a>åŸºæœ¬å½¢å¼</h3><p>ç»™å®šç”± ddd ä¸ªå±æ€§æè¿°çš„ç¤ºä¾‹ x=(x1;x2;â‹¯;xd)\boldsymbol x = (x_1; x_2; \cdots; x_d)x=(x1â€‹;x2â€‹;â‹¯;xdâ€‹)ï¼Œå…¶ä¸­ xix_ixiâ€‹ æ˜¯ x\boldsymbol xx åœ¨ç¬¬ iii ä¸ªå±æ€§ä¸Šçš„å–å€¼ï¼Œ<code>çº¿æ€§æ¨¡å‹</code>ï¼ˆlinear modelï¼‰è¯•å›¾å­¦å¾—ä¸€ä¸ªé€šè¿‡å±æ€§çš„çº¿æ€§ç»„åˆæ¥è¿›è¡Œé¢„æµ‹çš„å‡½æ•°ï¼š</p><p>f(x)=wTx+b f(\boldsymbol x) = \boldsymbol w^T \boldsymbol x + b f(x)=wTx+b</p><p>å…¶ä¸­ w=(w1;w2;â‹¯;wd)\boldsymbol w = (w_1; w_2; \cdots; w_d)w=(w1â€‹;w2â€‹;â‹¯;wdâ€‹)ã€‚</p><p>çº¿æ€§æ¨¡å‹å½¢å¼ç®€å•ï¼Œæ˜“äºå»ºæ¨¡ï¼Œä¸” w\boldsymbol ww ç›´è§‚è¡¨è¾¾äº†å„å±æ€§åœ¨é¢„æµ‹ä¸­çš„é‡è¦æ€§ï¼Œå› æ­¤çº¿æ€§æ¨¡å‹æœ‰å¾ˆå¥½çš„ <code>å¯è§£é‡Šæ€§</code>ï¼ˆcomprehensibilityï¼‰ã€‚</p><p>åœ¨çº¿æ€§æ¨¡å‹çš„åŸºç¡€ä¸Šå¯é€šè¿‡å¼•å…¥å±‚çº§ç»“æ„æˆ–é«˜ç»´æ˜ å°„è€Œå¾—åˆ°æ›´ä¸ºå¼ºå¤§çš„<code>éçº¿æ€§æ¨¡å‹</code>ï¼ˆnonlinear modelï¼‰ã€‚</p><h3 id="çº¿æ€§å›å½’"><a href="#çº¿æ€§å›å½’" class="headerlink" title="çº¿æ€§å›å½’"></a>çº¿æ€§å›å½’</h3><p>ç»™å®šæ•°æ®é›† D={(x1,y1),(x2,y2),â‹¯,(xm,ym)}D = \{(\boldsymbol x_1, y_1), (\boldsymbol x_2, y_2), \cdots , (\boldsymbol x_m, y_m)\}D={(x1â€‹,y1â€‹),(x2â€‹,y2â€‹),â‹¯,(xmâ€‹,ymâ€‹)}ï¼Œå…¶ä¸­ xi=(xi1,xi2,â‹¯,xid)\boldsymbol x_i = (x_{i1}, x_{i2}, \cdots, x_{id})xiâ€‹=(xi1â€‹,xi2â€‹,â‹¯,xidâ€‹)ï¼ŒyâˆˆRy \in \mathbb RyâˆˆRï¼Œ<code>çº¿æ€§å›å½’</code>ï¼ˆlinear regressionï¼‰è¯•å›¾å­¦å¾—ä¸€ä¸ªçº¿æ€§æ¨¡å‹ä»¥å°½å¯èƒ½å‡†ç¡®åœ°é¢„æµ‹å®é™…è¾“å‡ºæ ‡è®°ã€‚</p><p>è€ƒè™‘æœ€ç®€å•çš„å•å±æ€§æƒ…å½¢ï¼ŒD={(xi,yi)}i=1mD = \left \{ (x_i, y_i) \right \}_{i=1}^mD={(xiâ€‹,yiâ€‹)}i=1mâ€‹ï¼Œçº¿æ€§å›å½’è¯•å›¾å­¦å¾—</p><p>f(xi)=wxi+b f(x_i) = wx_i+b f(xiâ€‹)=wxiâ€‹+b</p><p>ä»¥ä½¿å¾— f(xi)â‰ƒyif(x_i) \simeq y_if(xiâ€‹)â‰ƒyiâ€‹ã€‚ä½¿ç”¨å‡æ–¹è¯¯å·®ä½œä¸ºè¡¡é‡ f(x)f(x)f(x) ä¸ yyy ä¹‹é—´å·®åˆ«çš„æ€§èƒ½åº¦é‡ï¼š</p><p>E(w,b)=âˆ‘i=1m(f(xi)âˆ’yi)2 E_{(w, b)} = \sum_{i=1}^{m} {\left (f(x_i) - y_i \right )^2} E(w,b)â€‹=i=1âˆ‘mâ€‹(f(xiâ€‹)âˆ’yiâ€‹)2</p><p>åˆ™ï¼š</p><p>(wâˆ—,bâˆ—)=argâ¡minâ¡(w,b)E(w,b) (w^*, b^*) = \underset {(w, b)} {\arg \min} E_{(w, b)} (wâˆ—,bâˆ—)=(w,b)argminâ€‹E(w,b)â€‹</p><p>å‡æ–¹è¯¯å·®æœ‰éå¸¸å¥½çš„å‡ ä½•æ„ä¹‰ï¼Œå®ƒå¯¹åº”äº† <code>æ¬§æ°è·ç¦»</code>ï¼ˆEuclidean distanceï¼‰ã€‚åŸºäºå‡æ–¹è¯¯å·®æœ€å°åŒ–æ¥è¿›è¡Œæ¨¡å‹æ±‚è§£çš„æ–¹æ³•ç§°ä¸º <code>æœ€å°äºŒä¹˜æ³•</code>ï¼ˆleast square methodï¼‰ã€‚åœ¨çº¿æ€§å›å½’ä¸­ï¼Œæœ€å°äºŒä¹˜æ³•è¯•å›¾æ‰¾åˆ°ä¸€æ¡ç›´çº¿ï¼Œä½¿å¾—æ‰€æœ‰æ ·æœ¬åˆ°ç›´çº¿ä¸Šçš„æ¬§æ°è·ç¦»ä¹‹å’Œæœ€å°ã€‚</p><p>E(w,b)E_{(w, b)}E(w,b)â€‹ æ˜¯å…³äº www å’Œ bbb çš„å‡¸å‡½æ•°ã€‚å¯¹äºåŒºé—´ [a,b][a, b][a,b] ä¸Šå®šä¹‰çš„å‡½æ•° fffï¼Œè‹¥å®ƒåŒºé—´ä¸­ä»»æ„ä¸¤ç‚¹ x1x_1x1â€‹ å’Œ x2x_2x2â€‹ å‡æœ‰ f(x1+x22)â‰¤f(x1)+f(x2)2f(\frac {x_1 + x_2} {2}) \le \frac {f(x_1) + f(x_2)} {2}f(2x1â€‹+x2â€‹â€‹)â‰¤2f(x1â€‹)+f(x2â€‹)â€‹ï¼Œåˆ™ç§° fff ä¸ºåŒºé—´ [a,b][a, b][a,b] ä¸Šçš„å‡¸å‡½æ•°ã€‚å¯¹å®æ•°é›†ä¸Šçš„å‡½æ•°ï¼Œå¯ä»¥é€šè¿‡æ±‚äºŒé˜¶å¯¼æ•°çš„æ–¹å¼æ¥åˆ¤æ–­ï¼ŒäºŒé˜¶å¯¼æ•°åœ¨åŒºé—´ä¸Šéè´Ÿåˆ™ç§°ä¸ºå‡¸å‡½æ•°ã€‚</p><p>æ±‚è§£ www å’Œ bbb ä½¿å‡æ–¹è¯¯å·®æœ€å°åŒ–çš„è¿‡ç¨‹ï¼Œç§°ä¸ºçº¿æ€§å›å½’æ¨¡å‹çš„æœ€å°äºŒä¹˜ <code>å‚æ•°ä¼°è®¡</code>ï¼ˆparameter estimationï¼‰ã€‚å°† E(w,b)E_{(w, b)}E(w,b)â€‹ åˆ†åˆ«å¯¹ www å’Œ bbb æ±‚å¯¼ï¼Œå¾—åˆ°ï¼š</p><p>âˆ‚E(w,b)âˆ‚w=2(wâˆ‘i=1mxi2âˆ’âˆ‘i=1m(yiâˆ’b)xi)âˆ‚E(w,b)âˆ‚b=2(mbâˆ’âˆ‘i=1m(yiâˆ’wxi)) \begin {aligned} \frac {\partial E_{(w, b)}} {\partial w} &amp;= 2 \left ( w \sum_{i=1}^{m} x_i^2 - \sum_{i=1}^{m} (y_i - b)x_i \right ) \\ \frac {\partial E_{(w, b)}} {\partial b} &amp;= 2 \left ( mb - \sum_{i=1}^{m} (y_i - wx_i) \right ) \end {aligned} âˆ‚wâˆ‚E(w,b)â€‹â€‹âˆ‚bâˆ‚E(w,b)â€‹â€‹â€‹=2(wi=1âˆ‘mâ€‹xi2â€‹âˆ’i=1âˆ‘mâ€‹(yiâ€‹âˆ’b)xiâ€‹)=2(mbâˆ’i=1âˆ‘mâ€‹(yiâ€‹âˆ’wxiâ€‹))â€‹</p><p>å¯¹ www å’Œ bbb çš„åå¯¼ç½®é›¶å¯å¾—åˆ° www å’Œ bbb æœ€ä¼˜è§£çš„ <code>é—­å¼è§£</code>ï¼ˆclosed-form solutionï¼‰ï¼š</p><p>w=âˆ‘i=1mxiyiâˆ’mxË‰yË‰âˆ‘i=1mxi2âˆ’mxË‰2b=yË‰âˆ’wxË‰ \begin {aligned} w &amp;= \frac {\sum_{i=1}^{m}x_i y_i - m \bar x \bar y} {\sum_{i=1}^{m} {x_i^2} - m \bar x^2} \\ b &amp;= \bar y - w \bar x \end {aligned} wbâ€‹=âˆ‘i=1mâ€‹xi2â€‹âˆ’mxË‰2âˆ‘i=1mâ€‹xiâ€‹yiâ€‹âˆ’mxË‰yË‰â€‹â€‹=yË‰â€‹âˆ’wxË‰â€‹</p><p>æ›´ä¸€èˆ¬çš„æƒ…å½¢ï¼Œç»™å®šæ•°æ®é›† D={(xi,yi)}i=1mD = \left \{ (\boldsymbol x_i, y_i) \right \}_{i=1}^mD={(xiâ€‹,yiâ€‹)}i=1mâ€‹ï¼Œå…¶ä¸­ xi=(xi1,xi2,â‹¯,xid)\boldsymbol x_i = (x_{i1}, x_{i2}, \cdots, x_{id})xiâ€‹=(xi1â€‹,xi2â€‹,â‹¯,xidâ€‹)ï¼ŒyâˆˆRy \in \mathbb RyâˆˆRï¼Œçº¿æ€§å›å½’è¯•å›¾å­¦å¾—ï¼š</p><p>f(xi)=wTxi+b f(\boldsymbol x_i) = \boldsymbol w^T \boldsymbol x_i+b f(xiâ€‹)=wTxiâ€‹+b</p><p>ä½¿å¾— f(xi)â‰ƒyif(\boldsymbol x_i) \simeq y_if(xiâ€‹)â‰ƒyiâ€‹ã€‚è¿™ç§°ä¸º <code>å¤šå˜é‡çº¿æ€§å›å½’</code>ï¼ˆmultivariate linear regressionï¼‰ã€‚</p><p>[æœªå®Œå¾…ç»­]</p><h3 id="å‚è€ƒæ–‡çŒ®"><a href="#å‚è€ƒæ–‡çŒ®" class="headerlink" title="å‚è€ƒæ–‡çŒ®"></a>å‚è€ƒæ–‡çŒ®</h3><ol><li>å‘¨å¿—å. â€œæœºå™¨å­¦ä¹ .â€ æ¸…åå¤§å­¦å‡ºç‰ˆç¤¾ï¼ŒåŒ—äº¬.</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;ç¬¬-1-ç« -ç»ªè®º&quot;&gt;&lt;a href=&quot;#ç¬¬-1-ç« -ç»ªè®º&quot; class=&quot;headerlink&quot; title=&quot;ç¬¬ 1 ç«  ç»ªè®º&quot;&gt;&lt;/a&gt;ç¬¬ 1 ç«  ç»ªè®º&lt;/h2&gt;&lt;h3 id=&quot;åŸºæœ¬æœ¯è¯­&quot;&gt;&lt;a href=&quot;#åŸºæœ¬æœ¯è¯­&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>å¤§å­¦è¯¾ç¨‹</title>
    <link href="http://yixuxi.xyz/posts/yuque/%E5%A4%A7%E5%AD%A6%E8%AF%BE%E7%A8%8B/"/>
    <id>http://yixuxi.xyz/posts/yuque/å¤§å­¦è¯¾ç¨‹/</id>
    <published>2019-03-26T02:54:36.000Z</published>
    <updated>2019-11-13T07:23:02.277Z</updated>
    
    <content type="html"><![CDATA[<p><a name="5563b44c"></a></p><h2 id="åŒ—äº¬å¤§å­¦"><a href="#åŒ—äº¬å¤§å­¦" class="headerlink" title="åŒ—äº¬å¤§å­¦"></a>åŒ—äº¬å¤§å­¦</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a name=&quot;5563b44c&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;åŒ—äº¬å¤§å­¦&quot;&gt;&lt;a href=&quot;#åŒ—äº¬å¤§å­¦&quot; class=&quot;headerlink&quot; title=&quot;åŒ—äº¬å¤§å­¦&quot;&gt;&lt;/a&gt;åŒ—äº¬å¤§å­¦&lt;/h2&gt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>äº‹å®ä¸Š</title>
    <link href="http://yixuxi.xyz/posts/yuque/%E4%BA%8B%E5%AE%9E%E4%B8%8A/"/>
    <id>http://yixuxi.xyz/posts/yuque/äº‹å®ä¸Š/</id>
    <published>2019-03-07T00:08:49.000Z</published>
    <updated>2019-11-13T07:23:02.269Z</updated>
    
    <content type="html"><![CDATA[<p>äº‹å®ä¸Šæœç´¢æœç´¢</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;äº‹å®ä¸Šæœç´¢æœç´¢&lt;/p&gt;

      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>å¦‚ä½•ç§‘å­¦å‡è‚¥</title>
    <link href="http://yixuxi.xyz/posts/yuque/%E5%A6%82%E4%BD%95%E7%A7%91%E5%AD%A6%E5%87%8F%E8%82%A5/"/>
    <id>http://yixuxi.xyz/posts/yuque/å¦‚ä½•ç§‘å­¦å‡è‚¥/</id>
    <published>2019-01-31T01:50:22.000Z</published>
    <updated>2019-11-13T07:23:02.281Z</updated>
    
    <content type="html"><![CDATA[<p><a name="9699a50e"></a></p><h3 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h3><ul><li><p>ä¹¦å•</p></li><li><p>app</p></li><li><p>è¥å…»å­¦</p></li><li><p>ä½ç¢³é¥®é£Ÿ</p></li><li><p>ç”Ÿé…®é¥®é£Ÿ</p></li><li><p>paper</p></li><li><p>é˜¿ç‰¹é‡‘æ–¯å‡è‚¥æ³•</p></li><li><p>è®¡åˆ’</p></li><li><p>è¡¨æ ¼</p></li><li><p>ä½“è„‚ç§°</p></li><li><p>æ‰‹ç¯<br><a name="d41d8cd9"></a></p><h3 id=""><a href="#" class="headerlink" title=""></a></h3><p><a name="b59c9e0f"></a></p><h3 id="æ¦‚å¿µ"><a href="#æ¦‚å¿µ" class="headerlink" title="æ¦‚å¿µ"></a>æ¦‚å¿µ</h3></li><li><p>åŸºç¡€ä»£è°¢</p></li><li><p>ä½ç¢³æ°´é¥®é£Ÿ</p></li><li><p>ç‡ƒè„‚å¿ƒç‡</p></li><li><p>BMI æŒ‡æ•°</p></li><li><p>ç”Ÿé…®é¥®é£Ÿ(keto)</p></li><li><p>HIIT</p><ul><li>Tabata<blockquote><p>Tabata æ˜¯ HIIT é«˜å¼ºåº¦é—´æ­‡æ€§çš„ä¸€ç§ï¼Œå®ƒçš„è®­ç»ƒæ–¹å¼å’Œ HIIT æœ‰äº›åŒºåˆ«ï¼Œä½†å‡è„‚åŸç†ä»¥åŠä¼˜ç‚¹å’Œ HIIT éƒ½æ˜¯ç±»ä¼¼çš„ã€‚</p></blockquote></li></ul></li></ul><p><a name="fef9d212"></a></p><h2 id="è‚¥èƒ–çš„å±å®³"><a href="#è‚¥èƒ–çš„å±å®³" class="headerlink" title="è‚¥èƒ–çš„å±å®³"></a>è‚¥èƒ–çš„å±å®³</h2><p><img src="https://cdn.nlark.com/yuque/0/2019/jpeg/223800/1549541591417-d6dd7785-cdbb-4f09-b3ae-58d4f5b1bf0c.jpeg#align=left&display=inline&height=386&originHeight=328&originWidth=550&size=0&width=648" alt=""><br><a name="e9d1af34"></a></p><h2 id="å‡è‚¥æ–¹æ³•"><a href="#å‡è‚¥æ–¹æ³•" class="headerlink" title="å‡è‚¥æ–¹æ³•"></a>å‡è‚¥æ–¹æ³•</h2><p><a name="44ebfb82"></a></p><h3 id="é¥®é£Ÿ"><a href="#é¥®é£Ÿ" class="headerlink" title="é¥®é£Ÿ"></a>é¥®é£Ÿ</h3><p><a name="445ddd1a"></a></p><h4 id="ç”Ÿé…®é¥®é£Ÿ"><a href="#ç”Ÿé…®é¥®é£Ÿ" class="headerlink" title="ç”Ÿé…®é¥®é£Ÿ"></a>ç”Ÿé…®é¥®é£Ÿ</h4><ul><li><a href="http://songshuhui.net/archives/101982" target="_blank" rel="noopener">æ²»ç–—ç™«ç—«ç—…çš„ç”Ÿé…®é¥®é£Ÿï¼Œä½ æƒ³ç”¨æ¥å‡è‚¥ï¼Ÿ</a><blockquote><p>ç”Ÿé…®é¥®é£Ÿæ˜¯é™åˆ¶ç¢³æ°´åŒ–åˆç‰©ã€å¤§é‡æ‘„å…¥è„‚è‚ªçš„é£Ÿè°±ï¼Œå…¸å‹çš„ç”Ÿé…®é£Ÿè°±ä¸­è„‚è‚ªä¾›èƒ½æ¯”é«˜è¾¾70%-80%ï¼Œè›‹ç™½è´¨çº¦ä¸º10%-20%ï¼Œè€Œç¢³æ°´åŒ–åˆç‰©åªå 5%-10%<br>äººä½“çš„ç”Ÿç†æ´»åŠ¨éœ€è¦çƒ­é‡ï¼Œæ­£å¸¸æƒ…å†µä¸‹ç”±ç¢³æ°´åŒ–åˆç‰©æ¥æä¾›ã€‚å…‰æ˜¯å¤§è„‘æ´»åŠ¨æ‰€éœ€è¦çš„çƒ­é‡ï¼Œæ¯å¤©å°±éœ€è¦120å…‹è‘¡è„ç³–ã€‚å½“äººä½“å¤„äºé¥¥é¥¿æˆ–è€…ç¢³æ°´åŒ–åˆç‰©ç¼ºä¹çš„çŠ¶æ€ï¼Œå°±ä¼šæ¶ˆè€—è‚ç³–å…ƒä»¥åŠæš‚æ—¶åˆ†è§£è‚Œè‚‰æ¥ä¾›èƒ½ã€‚è¿™æ ·çš„çŠ¶æ€æŒç»­ä¸‰å››å¤©ï¼Œç³–å…ƒæ¶ˆå¤±æ®†å°½ï¼Œè¡€æ¶²ä¸­çš„èƒ°å²›ç´ æ°´å¹³å¤§å¤§é™ä½ï¼Œè‚è„å°±ä¼šå¼€å§‹æŠŠè„‚è‚ªåˆ†è§£ä¸ºé…®ä½“æ¥ä¾›èƒ½ã€‚<br>èº«ä½“æœ¬æ¥æ˜¯æŒ‰ç…§è‘¡è„ç³–ä¾›èƒ½æ¥è¿è¡Œçš„ï¼Œåœ¨ç”Ÿé…®é¥®é£Ÿä¸‹æ”¹ç”¨é…®ä½“æ¥ä¾›èƒ½ã€‚å°±åƒä¸€å°æ±½æ²¹å‘åŠ¨æœºï¼Œå˜æˆäº†ç”¨é…’ç²¾åšç‡ƒæ–™ã€‚è¿™ç§æ”¹å˜ï¼Œä¼šæ”¹å˜èº«ä½“çš„æ•´ä¸ªä»£è°¢çŠ¶æ€ã€‚</p></blockquote></li></ul><p><strong>ä¼˜ç‚¹</strong>ï¼š</p><ul><li>çŸ­æœŸçš„ç”Ÿé…®é¥®é£Ÿå¯¹äºå‡è½»ä½“é‡ä»¥åŠæ”¹å–„æŸäº›ç”Ÿç†æŒ‡æ ‡æœ‰ä¸€å®šå¸®åŠ©<ul><li>ä½“é‡çš„é™ä½</li><li>ä½“è„‚ç‡ã€èƒ°å²›ç´ æ°´å¹³ã€è¡€å‹ã€è…°è‡€æ¯”ç­‰æŒ‡æ ‡ä¹Ÿæœ‰æ‰€æ”¹å–„ </li></ul></li></ul><p><strong>ç¼ºç‚¹ï¼š</strong></p><blockquote><p>å½“è¡€æ¶²ä¸­çš„é…®ä½“å«é‡è¿‡é«˜ï¼Œäººä½“ä¼šå‡ºäºé…®è¡€ç—‡çš„çŠ¶æ€ã€‚åœ¨è¿™ç§çŠ¶æ€ä¸‹ï¼Œè‚¾ä¼šæ’å‡ºé…®ä½“å’Œä½“æ¶²ï¼Œä»è€Œå¯¼è‡´äººä½“å¤±æ°´ï¼Œä½“é‡è¿…é€Ÿå‡è½»ã€‚æˆ–è®¸ï¼Œè¿™å°±æ˜¯æœ‰çš„äººé‡‡ç”¨ç”Ÿé…®é¥®é£Ÿèƒ½è¿…é€Ÿå‡é‡çš„åŸå› ã€‚</p></blockquote><ul><li><p>å…¶ä»–å¥åº·çš„å‡è‚¥æ–¹å¼ç›¸æ¯”ï¼Œç”Ÿé…®é¥®é£Ÿå°±æ²¡æœ‰ä»€ä¹ˆä¼˜åŠ¿</p></li><li><p>ç”Ÿé…®é¥®é£Ÿçš„è¥å…»ç»„æˆç›¸å½“ä¸åˆç†ã€‚</p><blockquote><p>è®¸å¤šç»´ç”Ÿç´ ã€çŸ¿ç‰©è´¨ä»¥åŠè†³é£Ÿçº¤ç»´ç­‰è¥å…»æˆåˆ†éƒ½ä¼´éšç€ç¢³æ°´åŒ–åˆç‰©è€Œæ¥ã€‚é•¿æœŸåšæŒç”Ÿé…®é¥®é£Ÿï¼Œè¥å…»çš„å¤±è¡¡å¯¹å¥åº·ä¼šæœ‰ä»€ä¹ˆæ ·çš„å½±å“ï¼Œä¹Ÿè¿˜æ²¡æœ‰å……åˆ†çš„ç ”ç©¶</p></blockquote></li><li><p>äººä½“å¯èƒ½ä¼šå‡ºç°è®¸å¤šä¸é€‚ï¼Œæ¯”å¦‚é¥¥é¥¿ã€ç–²åŠ³ã€æƒ…ç»ªä½è½ã€ä¾¿ç§˜ã€å¤´ç—›ç­‰ç­‰</p></li><li><p>è¾ƒé•¿æ—¶é—´çš„ç”Ÿé…®é¥®é£Ÿä¼šå¤§å¤§å¢åŠ è‚¾ç»“çŸ³ã€éª¨è´¨ç–æ¾å’Œé«˜å°¿é…¸çš„é£é™©</p></li></ul><p>æ€»ç»“:</p><blockquote><p>ä»å®éªŒç»“æœæ¥çœ‹ï¼ŒçŸ­æœŸçš„ç”Ÿé…®é¥®é£Ÿå¯¹äºå‡è½»ä½“é‡ä»¥åŠæ”¹å–„æŸäº›ç”Ÿç†æŒ‡æ ‡æœ‰ä¸€å®šå¸®åŠ©ã€‚ä¸è¿‡ï¼Œå¦‚æœè·Ÿå…¶ä»–å¥åº·çš„å‡è‚¥æ–¹å¼ç›¸æ¯”ï¼Œç”Ÿé…®é¥®é£Ÿå°±æ²¡æœ‰ä»€ä¹ˆä¼˜åŠ¿ã€‚è€Œç”Ÿé…®é¥®é£Ÿæ—©å·²æ˜ç¡®çš„å‰¯ä½œç”¨ï¼Œå°±å·²ç»ä¸å¯å¿½è§†ã€‚æ­¤å¤–ï¼Œç”Ÿé…®é¥®é£Ÿçš„è¥å…»ç»„æˆç›¸å½“ä¸åˆç†ã€‚è®¸å¤šç»´ç”Ÿç´ ã€çŸ¿ç‰©è´¨ä»¥åŠè†³é£Ÿçº¤ç»´ç­‰è¥å…»æˆåˆ†éƒ½ä¼´éšç€ç¢³æ°´åŒ–åˆç‰©è€Œæ¥ã€‚é•¿æœŸåšæŒç”Ÿé…®é¥®é£Ÿï¼Œè¥å…»çš„å¤±è¡¡å¯¹å¥åº·ä¼šæœ‰ä»€ä¹ˆæ ·çš„å½±å“ï¼Œä¹Ÿè¿˜æ²¡æœ‰å……åˆ†çš„ç ”ç©¶ã€‚<br>å½“ç„¶ï¼Œå¦‚æœä½œä¸ºä¸€ç§åŒ»ç–—æ‰‹æ®µï¼Œç”Ÿé…®é¥®é£Ÿè¿˜æ˜¯å€¼å¾—ç ”ç©¶å’Œå…³æ³¨çš„ã€‚åœ¨æŸäº›ç–¾ç—…çš„æ²»ç–—ä¸­ï¼Œç»è¿‡åŒ»ç”Ÿçš„è¯„ä¼°ï¼Œå¹¶ä¸”åœ¨åŒ»é™¢çš„å¯†åˆ‡ç›‘æŠ¤ä¸‹è¿›è¡Œç”Ÿé…®é¥®é£Ÿï¼Œä¹Ÿæ˜¯å¯ä»¥é‡‡å–çš„æ–¹æ¡ˆã€‚è‡³äºæ—¥å¸¸ç”Ÿæ´»ä¸­ç”¨å®ƒæ¥å‡è‚¥ï¼Œè¿˜æ˜¯ç®—äº†å§ã€‚</p></blockquote><p>ç®€å•æ¥è¯´<strong>ç”Ÿé…®é¥®é£Ÿ</strong>æœ€åˆå°±æ˜¯ä½œä¸ºä¸€ç§åŒ»ç–—æ‰‹æ®µï¼Œä¾‹å¦‚ç³–å°¿ç—…ã€ç™«ç—«ï¼Œç”Ÿé…®é¥®é£Ÿè¿˜è¢«ç”¨äºè®¸å¤šè·Ÿç¥ç»æœ‰å…³çš„ç–¾ç—…ä¸Šï¼Œæ¯”å¦‚é˜¿èŒ¨æµ·é»˜ç—‡ã€è‡ªé—­ç—‡ã€è„‘ç™Œã€å¸•é‡‘æ£®æ°ç—…ç­‰ç­‰ï¼Œæœ‰ä¸€å®šçš„æ•ˆæœï¼Œä¸è¿‡ç»¼åˆæƒè¡¡æ•ˆæœä¸è¯æ®å¼ºåº¦ï¼Œå¹¶æ²¡æœ‰è¾¾åˆ°ä¸´åºŠæ¨èçš„å±‚æ¬¡ã€‚è€Œä¸”å‰¯ä½œç”¨æ˜æ˜¾ï¼Œä¾¿ç§˜å’Œè‚¾ç»“çŸ³<br><a name="d41d8cd9"></a></p><h4 id="-1"><a href="#-1" class="headerlink" title=""></a></h4><p><a name="0d74ba8c"></a></p><h4 id="é˜¿ç‰¹é‡‘æ–¯å‡è‚¥æ³•"><a href="#é˜¿ç‰¹é‡‘æ–¯å‡è‚¥æ³•" class="headerlink" title="é˜¿ç‰¹é‡‘æ–¯å‡è‚¥æ³•"></a>é˜¿ç‰¹é‡‘æ–¯å‡è‚¥æ³•</h4><p><a name="6b17f352"></a></p><h4 id="ä½ç¢³æ°´é¥®é£Ÿ"><a href="#ä½ç¢³æ°´é¥®é£Ÿ" class="headerlink" title="ä½ç¢³æ°´é¥®é£Ÿ"></a>ä½ç¢³æ°´é¥®é£Ÿ</h4><p><a name="37b6debe"></a></p><h3 id="è¿åŠ¨"><a href="#è¿åŠ¨" class="headerlink" title="è¿åŠ¨"></a>è¿åŠ¨</h3><p><a name="8558e728"></a></p><h4 id="é•¿æ—¶é—´æŒç»­æ€§æœ‰æ°§"><a href="#é•¿æ—¶é—´æŒç»­æ€§æœ‰æ°§" class="headerlink" title="é•¿æ—¶é—´æŒç»­æ€§æœ‰æ°§"></a>é•¿æ—¶é—´æŒç»­æ€§æœ‰æ°§</h4><blockquote><p>è¿åŠ¨å¼ºåº¦è¶…è¿‡30åˆ†é’Ÿçš„ä¸­ä½å¼ºåº¦æœ‰æ°§ï¼Œå¦‚æ…¢è·‘ï¼Œæ¸¸æ³³ï¼Œé•¿é€”éª‘è¡Œç­‰ã€‚æ˜¯ä¸€ç›´ä»¥æ¥æ²¡æ¯›ç—…çš„ä¼ ç»Ÿå‹æœ‰æ°§ã€‚</p></blockquote><p>ä¸ä½äº30åˆ†é’Ÿä¸é«˜äº70åˆ†é’Ÿä¸ºæœ€ä½³ã€‚</p><ul><li>æ…¢è·‘</li><li>æ¸¸æ³³</li><li>é•¿é€”éª‘è¡Œ</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2019/png/223800/1549541856051-0fd9ec25-c919-4b06-bd75-e991e3564695.png#align=left&display=inline&height=707&name=image.png&originHeight=508&originWidth=440&size=300058&width=612" alt="image.png"><br />å¡æ°å…¬å¼:<br />        ç‡ƒè„‚å¿ƒç‡ =ï¼ˆ220-å¹´é¾„-é™æ€å¿ƒç‡ï¼‰x 30%-45%+é™æ€å¿ƒç‡</p><p><br /><a name="95a7e4d0"></a></p><h4 id="é—´æ­‡æ€§æœ‰æ°§è¿åŠ¨ï¼ˆHIITï¼‰"><a href="#é—´æ­‡æ€§æœ‰æ°§è¿åŠ¨ï¼ˆHIITï¼‰" class="headerlink" title="é—´æ­‡æ€§æœ‰æ°§è¿åŠ¨ï¼ˆHIITï¼‰"></a>é—´æ­‡æ€§æœ‰æ°§è¿åŠ¨ï¼ˆHIITï¼‰</h4><blockquote><p>HIITï¼Œç®€å•è®²å°±æ˜¯ä¸€ç§é«˜å¼ºåº¦ä¸ä½å¼ºåº¦äº¤æ›¿é—´æ­‡çš„è®­ç»ƒæ–¹å¼ã€‚åªè¦åœ¨è¿åŠ¨ä¸­æ˜¯å¼ºåº¦é«˜ä½äº¤æ›¿çš„ï¼Œéƒ½å¯ä»¥è§†ä½œå¹¿ä¹‰çš„HIITï¼Œæ¯”å¦‚å¿«æ…¢äº¤æ›¿è·‘ï¼Œå¿«æ…¢äº¤æ›¿éª‘è½¦ç­‰ç­‰ã€‚</p></blockquote><p>ä¼˜ç‚¹ï¼š</p><ul><li>å³è¿åŠ¨åä»ç„¶èƒ½ä¿æŒé«˜çƒ­é‡ã€é«˜è„‚è‚ªçš„æ¶ˆè€—æ•ˆç‡ã€‚å…¶è®­ç»ƒåå‡è„‚æ•ˆæœå¯ä»¥æŒç»­72å°æ—¶å·¦å³ã€‚å¹¶ä¸”å…¶é«˜å¼ºåº¦çš„åŠ¨ä½œè¿˜å¯ä»¥èµ·åˆ°ä¿æŠ¤è‚Œè‚‰ç»´æŒä»£è°¢çš„ä½œç”¨</li></ul><p>ç¼ºç‚¹ï¼š</p><ul><li><p>å¼ºåº¦é«˜<br><a name="d41d8cd9"></a></p><h3 id="-2"><a href="#-2" class="headerlink" title=""></a></h3><p><a name="0debf521"></a></p><h3 id="è®¡åˆ’"><a href="#è®¡åˆ’" class="headerlink" title="è®¡åˆ’"></a>è®¡åˆ’</h3></li><li><p>é£Ÿè°±</p></li><li><p>è¿åŠ¨</p><ul><li>æ…¢è·‘<blockquote><p>è·‘å®Œæ­¥è®°å¾—è¡¥å……æ°´ä»½ï¼Œç‰›å¥¶æ¯”çŸ¿æ³‰æ°´æ›´è¡¥æ°´ï¼Œè¿˜èƒ½è¡¥å……è›‹ç™½è´¨å’Œç”µè§£è´¨ä¿®å¤ä½ çš„èº«ä½“æŸè€—ã€‚<br>åƒä¸€æ ¹å¯Œå«é’¾çš„é¦™è•‰ä¹Ÿä¸é”™ã€‚</p></blockquote></li></ul></li></ul><p><a name="1c7fa641"></a></p><h4 id="æ³¨æ„äº‹é¡¹ï¼š"><a href="#æ³¨æ„äº‹é¡¹ï¼š" class="headerlink" title="æ³¨æ„äº‹é¡¹ï¼š"></a>æ³¨æ„äº‹é¡¹ï¼š</h4><ul><li><p>å‡è‚¥ä¹Ÿä¸èƒ½åƒå¾—ä½äºè‡ªå·±çš„åŸºç¡€ä»£è°¢<br><a name="5b208a57"></a></p><h2 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ:"></a>å‚è€ƒ:</h2></li><li><p>çŸ¥ä¹</p><ul><li><a href="https://www.zhihu.com/question/20234124/answer/352356794" target="_blank" rel="noopener">ç¦é£Ÿã€Œç¢³æ°´åŒ–åˆç‰©ã€æ­£ç¡®å—ï¼Ÿã€Œé˜¿ç‰¹é‡‘æ–¯å‡è‚¥æ³•ã€æœ‰æ•ˆå®‰å…¨å—ï¼Ÿ - ã€Šç§‘å­¦ä¸–ç•Œã€‹æ‚å¿—çš„å›ç­” - çŸ¥ä¹ </a></li><li><a href="https://www.zhihu.com/question/23586456/answer/151934876" target="_blank" rel="noopener">å“¥æœ¬å“ˆæ ¹é£Ÿè°±çœŸçš„æœ‰é‚£ä¹ˆç¥å¥‡å—ï¼Ÿ</a></li><li><a href="https://zhuanlan.zhihu.com/p/36154483" target="_blank" rel="noopener">å‡è‚¥è°£è¨€å¤§æ··æˆ˜|ä½ç¢³æ°´orä½è„‚è‚ªï¼Œè°åœ¨çè¯´|ç”Ÿé…®å‡è‚¥</a></li><li><a href="https://zhuanlan.zhihu.com/p/36020258" target="_blank" rel="noopener">è„‚è‚ªæ˜¯å¦‚ä½•è¢«æ¶ˆè€—çš„ï¼Ÿ</a></li><li><a href="https://www.zhihu.com/question/28248712" target="_blank" rel="noopener">tabata 4åˆ†é’ŸçœŸçš„æœ‰æ•ˆæœå—ï¼Ÿ</a></li></ul></li><li><p>ä¸é¦™å›­</p><ul><li><a href="http://endo.dxy.cn/article/560367" target="_blank" rel="noopener">(ä¸é¦™å›­)ç”Ÿé…®é¥®é£Ÿï¼šå‡é‡æ•ˆæœå¦‚ä½•ï¼Ÿåˆæœ‰ä»€ä¹ˆé£é™©ï¼Ÿ</a><a href="https://web.archive.org/web/20190207075150/http://endo.dxy.cn/article/560367" target="_blank" rel="noopener">å¤‡ç”¨é“¾æ¥</a> #ç”Ÿé…®é¥®é£Ÿ</li></ul></li><li><p>RubyChina</p><ul><li><a href="https://ruby-china.org/topics/38029" target="_blank" rel="noopener">æ¨èä¸€ä¸ªç®€å•æœ‰æ•ˆçš„å‡è‚¥æ–¹æ³•ï¼šç”Ÿé…®é¥®é£Ÿ</a> <a href="https://web.archive.org/web/20190207074707/https://ruby-china.org/topics/38029" target="_blank" rel="noopener">å¤‡ç”¨é“¾æ¥</a></li></ul></li><li><p>Reddit</p><ul><li><a href="https://www.reddit.com/r/keto/wiki/faq" target="_blank" rel="noopener">keto faq</a></li><li><a href="https://calculo.io/keto-calculator" target="_blank" rel="noopener">keto-calculator</a></li><li><a href="https://www.reddit.com/r/keto/wiki/keto_in_a_nutshell" target="_blank" rel="noopener">Keto For Beginners</a></li><li><a href="https://docs.google.com/spreadsheets/d/1g-tl1PqIUaHsLdL2Au1KKGe7z5EQS0_xT7f_lMllIB4/edit#gid=5" target="_blank" rel="noopener">Keto Progress Tracker</a></li></ul></li><li><p>V2EX</p><ul><li><a href="https://www.v2ex.com/t/469642" target="_blank" rel="noopener">ä¸€ä¸ªå¥³è‚¥å®…çš„å‡è‚¥&amp;å¥èº«å¿ƒå¾—ï¼Œå’Œå¤§å®¶åˆ†äº«~</a></li></ul></li><li><p>ç§‘å­¦æ¾é¼ ä¼š</p><ul><li><a href="http://songshuhui.net/archives/101982" target="_blank" rel="noopener">æ²»ç–—ç™«ç—«ç—…çš„ç”Ÿé…®é¥®é£Ÿï¼Œä½ æƒ³ç”¨æ¥å‡è‚¥ï¼Ÿ</a></li><li><a href="http://songshuhui.net/archives/100583" target="_blank" rel="noopener">ä½è„‚è‚ªå’Œä½ç¢³æ°´ï¼Œå“ªç§é£Ÿè°±å‡è‚¥æ•ˆæœå¥½ï¼Ÿ</a></li></ul></li><li><p>å…¶å®ƒ</p><ul><li><a href="http://josepharcita.blogspot.com/2011/03/guide-to-ketosis.html" target="_blank" rel="noopener">A Guide to Ketosis</a><br><a name="app"></a><h4 id="app"><a href="#app" class="headerlink" title="app"></a>app</h4></li></ul></li><li><p>keep</p></li></ul><p><a name="b6c5522e"></a></p><h4 id="ä¹¦å•"><a href="#ä¹¦å•" class="headerlink" title="ä¹¦å•"></a>ä¹¦å•</h4><p>source: <a href="https://www.douban.com/doulist/111781954/" target="_blank" rel="noopener">https://www.douban.com/doulist/111781954/</a></p><ul><li>ã€Šæˆ‘ä»¬ä¸ºä»€ä¹ˆä¼šå‘èƒ–ã€‹</li></ul><p><a href="https://book.douban.com/subject/26369484/" target="_blank" rel="noopener"><img src="https://cdn.nlark.com/yuque/0/2019/png/223800/1549531654316-1583207e-f17f-4b6c-af24-ebb7d5e1a4a9.png#align=left&display=inline&height=295&name=image.png&originHeight=602&originWidth=1480&size=247921&width=726" alt="image.png"></a></p><ul><li>ã€Šè¿åŠ¨é¥®é£Ÿ1:9ã€‹</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2019/png/223800/1549531774483-242f4e73-f064-4451-924d-40307caf186a.png#align=left&display=inline&height=308&name=image.png&originHeight=616&originWidth=1500&size=216699&width=750" alt="image.png"></p><ul><li>ã€Šæ–½ç“¦è¾›æ ¼å¥èº«å…¨ä¹¦ã€‹</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2019/png/223800/1549531883167-4ed718e6-8487-494d-b7ed-46a7809bbd9e.png#align=left&display=inline&height=267&name=image.png&originHeight=534&originWidth=1496&size=322007&width=748" alt="image.png"></p><ul><li>ã€Šå›šå¾’å¥èº«ã€‹</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2019/png/223800/1549532264981-490bb0e2-e58d-4f9e-b91b-445fc496b0a4.png#align=left&display=inline&height=307&name=image.png&originHeight=614&originWidth=1468&size=363357&width=734" alt="image.png"></p><ul><li>ã€Šæ ¸å¿ƒåŸºç¡€è¿åŠ¨ã€‹</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2019/png/223800/1549532305042-6752e6dd-d89b-4727-992d-856408a3ca2d.png#align=left&display=inline&height=331&name=image.png&originHeight=662&originWidth=1514&size=312834&width=757" alt="image.png"></p><ul><li>ã€Šå¾·æ‹‰å¨å°”æ‹‰ä¼¸è®­ç»ƒå›¾è§£ã€‹</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2019/png/223800/1549532339425-0c31d2a0-5da1-4e2a-81c5-1cb7a0312ac6.png#align=left&display=inline&height=304&name=image.png&originHeight=608&originWidth=1472&size=275937&width=736" alt="image.png"><br /></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a name=&quot;9699a50e&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;å…³é”®è¯&quot;&gt;&lt;a href=&quot;#å…³é”®è¯&quot; class=&quot;headerlink&quot; title=&quot;å…³é”®è¯&quot;&gt;&lt;/a&gt;å…³é”®è¯&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ä¹¦å•&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;app&lt;/p
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>æ— æ ‡é¢˜</title>
    <link href="http://yixuxi.xyz/posts/yuque/%E6%97%A0%E6%A0%87%E9%A2%98/"/>
    <id>http://yixuxi.xyz/posts/yuque/æ— æ ‡é¢˜/</id>
    <published>2019-01-04T00:04:35.000Z</published>
    <updated>2019-11-13T07:23:02.273Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Deep Learningé‡è¦å‘å±•è„‰ç»œ</title>
    <link href="http://yixuxi.xyz/posts/yuque/Deep%20Learning%E9%87%8D%E8%A6%81%E5%8F%91%E5%B1%95%E8%84%89%E7%BB%9C/"/>
    <id>http://yixuxi.xyz/posts/yuque/Deep Learningé‡è¦å‘å±•è„‰ç»œ/</id>
    <published>2018-12-26T06:32:12.000Z</published>
    <updated>2019-11-13T07:23:02.273Z</updated>
    
    <content type="html"><![CDATA[<p>Deep Learningï¼ˆæ·±åº¦å­¦ä¹ ï¼‰çš„æ¦‚å¿µæºäºäººå·¥ç¥ç»ç½‘ç»œçš„ç ”ç©¶ï¼Œå®ƒçš„æ¦‚å¿µç”±Hintonç­‰äººäº2006å¹´æå‡ºï¼Œä½†å®ƒçš„æ¨¡å‹ç»å†äº†æ€æ ·çš„å‘å±•å’Œæ¼”åŒ–ï¼Œæœ¬æ–‡å°†ä¸ºæ‚¨æ·±åº¦è§£è¯»Deep Learningçš„å‰ä¸–ä»Šç”Ÿã€‚<br /><img src="https://static.aminer.cn/rcd/article/expertpic/aminer.gif#align=left&display=inline&height=1205&originHeight=1205&originWidth=1694&search=&status=done&width=1694" alt=""><br /><br><a name="tfacwu"></a></p><h3 id="è„‰ç»œä¸€-cv-tensor"><a href="#è„‰ç»œä¸€-cv-tensor" class="headerlink" title="è„‰ç»œä¸€  cv/tensor"></a>è„‰ç»œä¸€  cv/tensor</h3><p>1943å¹´  å¿ƒç†å­¦å®¶éº¦å¡æ´›å¯ï¼ˆWÂ·McCullochï¼‰å’Œæ•°ç†é€»è¾‘å­¦å®¶çš®èŒ¨ï¼ˆWÂ·Pittsï¼‰å‚è€ƒäº†ç”Ÿç‰©ç¥ç»å…ƒçš„ç»“æ„ï¼Œå‘è¡¨äº†ã€Šç¥ç»æ´»åŠ¨ä¸­æ€æƒ³å†…åœ¨æ€§çš„é€»è¾‘è¿ç®—ã€‹ä¸€æ–‡ï¼Œæå‡ºäº†æŠ½è±¡çš„ç¥ç»å…ƒæ¨¡å‹MPï¼Œè¯¥æ¨¡å‹å¯ä»¥çœ‹åšæ·±åº¦å­¦ä¹ çš„é›å½¢ã€‚</p><p>1957å¹´  è®¤çŸ¥å¿ƒç†å­¦å¤§å¸ˆ Frank Rosenblatt å‘æ˜äº†æ„ŸçŸ¥æœºï¼ˆPerceptronï¼Œåˆç§°æ„ŸçŸ¥å™¨ï¼‰ï¼Œæ„ŸçŸ¥æœºæ˜¯å½“æ—¶é¦–ä¸ªå¯ä»¥å­¦ä¹ çš„äººå·¥ç¥ç»ç½‘ç»œï¼Œæ€èµ·äº†ä¸€è‚¡å­¦ä¹ çš„çƒ­æ½®ã€‚</p><p>1969å¹´  äººå·¥æ™ºèƒ½å¤§å¸ˆ Marvin Minksy å’Œ Seymour Papert åœ¨ã€ŠPerceptronã€‹ä¸€ä¹¦ä¸­ï¼Œç”¨è¯¦ç»†çš„æ•°å­¦è¯æ˜äº†æ„ŸçŸ¥æœºçš„å¼±ç‚¹ï¼Œæ²¡æœ‰éšå±‚çš„ç®€å•æ„ŸçŸ¥æœºåœ¨è®¸å¤šåƒXORé—®é¢˜çš„æƒ…å½¢ä¸‹æ˜¾å¾—æ— èƒ½ä¸ºåŠ›ï¼Œå¹¶è¯æ˜äº†ç®€å•æ„ŸçŸ¥æœºåªèƒ½è§£å†³çº¿æ€§åˆ†ç±»é—®é¢˜å’Œä¸€é˜¶è°“è¯ƒåŒé¢˜ã€‚ç¥ç»ç½‘ç»œç ”ç©¶è¿›å…¥å†°æ²³æœŸã€‚</p><p>1984å¹´  æ—¥æœ¬å­¦è€…ç¦å²›é‚¦å½¦ï¼ˆKunihiko Fukishimaï¼‰æå‡ºäº†å·ç§¯ç¥ç»ç½‘ç»œçš„åŸå§‹æ¨¡å‹ç¥ç»æ„ŸçŸ¥æœºï¼ˆNeocognitronï¼‰ï¼Œäº§ç”Ÿäº†å·ç§¯å’Œæ± åŒ–çš„æ€æƒ³ï¼ˆå½“æ—¶ä¸å«å·ç§¯å’Œæ± åŒ–ï¼‰ã€‚</p><p>1986å¹´  Hintonç­‰äººæ­£å¼æå‡ºä¸€èˆ¬ Delta æ³•åˆ™ï¼Œå³åå‘ä¼ æ’­ï¼ˆBPï¼‰ç®—æ³•ï¼Œå¹¶ç”¨åå‘ä¼ æ’­è®­ç»ƒMLPï¼ˆå¤šå±‚æ„ŸçŸ¥æœºï¼‰ã€‚ä½†å…¶å®åœ¨ä»–æå‡ºä¹‹å‰ï¼Œå·²ç»æœ‰äººå°†å…¶ä»˜è¯¸å®é™…ã€‚ï¼ˆ1985å¹´ Parter ä¹Ÿç‹¬ç«‹åœ°å¾—å‡ºè¿‡ç›¸ä¼¼çš„ç®—æ³•ï¼Œä»–ç§°ä¹‹ä¸ºå­¦ä¹ é€»è¾‘ã€‚æ­¤å¤–ï¼Œ1985å¹´ Lecun ä¹Ÿç ”ç©¶å‡ºå¤§è‡´ç›¸ä¼¼çš„å­¦ä¹ æ³•åˆ™ã€‚ï¼‰</p><p>1998å¹´  ä»¥ Yann LeCun ä¸ºé¦–çš„ç ”ç©¶äººå‘˜å®ç°äº†ä¸€ä¸ª5å±‚çš„å·ç§¯ç¥ç»ç½‘ç»œâ€”â€”LeNet-5ï¼Œä»¥è¯†åˆ«æ‰‹å†™æ•°å­—ã€‚LeNet-5 æ ‡å¿—ç€ CNNï¼ˆå·ç§¯ç¥ç»ç½‘ç»œï¼‰çš„çœŸæ­£é¢ä¸–ï¼ŒLeNet-5 çš„æå‡ºæŠŠ CNN æ¨ä¸Šäº†ä¸€ä¸ªå°é«˜æ½®ã€‚</p><p>ä¹‹åSVMï¼ˆæ”¯æŒå‘é‡æœºï¼‰å…´èµ·ï¼ŒSVMåœ¨è®¡ç®—åŠå‡†ç¡®åº¦ä¸Šéƒ½æœ‰è¾ƒå¤§çš„ä¼˜åŠ¿ï¼Œå¯¼è‡´å·ç§¯ç¥ç»ç½‘ç»œçš„æ–¹æ³•åœ¨åæ¥çš„ä¸€æ®µæ—¶é—´å¹¶æœªèƒ½ç«èµ·æ¥ã€‚</p><p>2012å¹´  Hintonç»„çš„ AlexNet åœ¨ ImageNet ä¸Šä»¥å·¨å¤§ä¼˜åŠ¿å¤ºå† ï¼Œæ€èµ·äº†æ·±åº¦å­¦ä¹ çš„çƒ­æ½®ã€‚AlexNet å¯ä»¥ç®—æ˜¯ LeNet çš„ä¸€ç§æ›´æ·±æ›´å®½çš„ç‰ˆæœ¬ï¼Œå¹¶åŠ ä¸Šäº† reluã€dropout ç­‰æŠ€å·§ã€‚</p><p>è¿™æ¡æ€è·¯è¢«åäººå‘å±•ï¼Œå‡ºç°äº† VGGï¼ŒGoogLeNet ç­‰ç½‘ç»œã€‚</p><p>2016å¹´  é’å¹´è®¡ç®—æœºè§†è§‰ç§‘å­¦å®¶ä½•æºæ˜åœ¨å±‚æ¬¡ä¹‹é—´åŠ å…¥äº†è·³è·ƒè¿æ¥ï¼ŒResnet æå¤§å¢åŠ äº†ç½‘ç»œæ·±åº¦ï¼Œæ•ˆæœæœ‰å¾ˆå¤§æå‡ã€‚å¦ä¸€ä¸ªå°†è¿™æ¡æ€è·¯ç»§ç»­å‘å±•ä¸‹å»çš„æ˜¯å»å¹´cvpr best paper densenetã€‚</p><p>é™¤æ­¤ä¹‹å¤–ï¼Œcvé¢†åŸŸçš„ç‰¹å®šä»»åŠ¡è¿˜å‡ºç°äº†å„ç§å„æ ·çš„æ¨¡å‹ï¼ˆMask-RCNNç­‰ï¼‰ï¼Œè¿™é‡Œä¸ä¸€ä¸€ä»‹ç»ã€‚</p><p>2017å¹´  Hintonè®¤ä¸ºåçœä¼ æ’­å’Œä¼ ç»Ÿç¥ç»ç½‘ç»œæœ‰ç¼ºé™·ï¼Œç»§è€Œæå‡ºäº† Capsule Netã€‚ä½†æ˜¯ç›®å‰åœ¨ cifar ç­‰æ•°æ®é›†ä¸Šæ•ˆæœä¸€èˆ¬ï¼Œè¿™ä¸ªæ€è·¯è¿˜éœ€è¦ç»§ç»­éªŒè¯å’Œå‘å±•ã€‚</p><p><a name="orhvmd"></a></p><h3 id="è„‰ç»œäºŒ-ç”Ÿæˆæ¨¡å‹"><a href="#è„‰ç»œäºŒ-ç”Ÿæˆæ¨¡å‹" class="headerlink" title="è„‰ç»œäºŒ  ç”Ÿæˆæ¨¡å‹"></a>è„‰ç»œäºŒ  ç”Ÿæˆæ¨¡å‹</h3><p>ä¼ ç»Ÿçš„ç”Ÿæˆæ¨¡å‹æ˜¯è¦é¢„æµ‹è”åˆæ¦‚ç‡åˆ†å¸ƒP(x,y)ã€‚</p><p>RBMï¼ˆå—é™ç»å°”å…¹æ›¼æœºï¼‰è¿™ä¸ªæ¨¡å‹å…¶å®æ˜¯ä¸€ä¸ªåŸºäºèƒ½é‡çš„æ¨¡å‹ï¼Œ1986å¹´çš„æ—¶å€™å°±æœ‰ï¼Œ2006å¹´å°†å…¶é‡æ–°æ‹¿å‡ºæ¥ä½œä¸ºä¸€ä¸ªç”Ÿæˆæ¨¡å‹ï¼Œå¹¶ä¸”å †å æˆä¸ºdeep belief networkï¼Œä½¿ç”¨é€å±‚è´ªå©ªæˆ–è€…wake-sleepçš„æ–¹æ³•è®­ç»ƒï¼Œä¸è¿‡è¿™ä¸ªæ¨¡å‹æ•ˆæœä¸€èˆ¬ï¼Œç°åœ¨å·²ç»æ²¡ä»€ä¹ˆäººæäº†ã€‚ä½†æ˜¯Hintonç­‰äººå´ä»æ­¤å¼€å§‹ä½¿ç”¨æ·±åº¦å­¦ä¹ é‡æ–°åŒ…è£…ç¥ç»ç½‘ç»œã€‚</p><p>Auto-Encoderæ˜¯ä¸Šä¸ªä¸–çºª80å¹´ä»£hintonæå‡ºçš„æ¨¡å‹ï¼Œå¦‚ä»Šç”±äºè®¡ç®—èƒ½åŠ›çš„è¿›æ­¥é‡æ–°ç™»ä¸Šèˆå°ã€‚2008å¹´ï¼ŒBengioç­‰äººåˆæäº†denoise Auto-Encoderã€‚</p><p>Max wellingç­‰äººä½¿ç”¨ç¥ç»ç½‘ç»œè®­ç»ƒä¸€ä¸ªæœ‰ä¸€å±‚éšå˜é‡çš„å›¾æ¨¡å‹ï¼Œç”±äºä½¿ç”¨äº†å˜åˆ†æ¨æ–­ï¼Œæœ€åé•¿å¾—è·Ÿauto-encoderæœ‰ç‚¹åƒï¼Œå› è€Œè¢«ç§°ä¸ºVariational auto-encoderã€‚æ­¤æ¨¡å‹å¯ä»¥é€šè¿‡éšå˜é‡çš„åˆ†å¸ƒé‡‡æ ·ï¼Œç»è¿‡åé¢çš„decoderç½‘ç»œç›´æ¥ç”Ÿæˆæ ·æœ¬ã€‚</p><p>GANï¼ˆç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼‰æ˜¯äº2014å¹´æå‡ºçš„æ¨¡å‹ï¼Œå¦‚ä»Šç‚™æ‰‹å¯çƒ­ã€‚å®ƒæ˜¯ä¸€ä¸ªç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡åˆ¤åˆ«å™¨Dï¼ˆDiscriminatorï¼‰å’Œç”Ÿæˆå™¨Gï¼ˆGeneratorï¼‰çš„å¯¹æŠ—è®­ç»ƒï¼Œç›´æ¥ä½¿ç”¨ç¥ç»ç½‘ç»œGéšå¼å»ºæ¨¡æ ·æœ¬æ•´ä½“çš„æ¦‚ç‡åˆ†å¸ƒã€‚æ¯æ¬¡è¿è¡Œä¾¿ç›¸å½“äºä»åˆ†å¸ƒä¸­é‡‡æ ·ã€‚</p><p>DCGANæ˜¯ä¸€ä¸ªç›¸å½“å¥½çš„å·ç§¯ç¥ç»ç½‘ç»œå®ç°ï¼Œè€ŒWGANåˆ™æ˜¯é€šè¿‡ç»´å°”æ–¯ç‰¹æ‹‰æ–¯è·ç¦»æ›¿æ¢åŸæ¥çš„JSæ•£åº¦æ¥åº¦é‡åˆ†å¸ƒä¹‹é—´çš„ç›¸ä¼¼æ€§çš„å·¥ä½œï¼Œä½¿å¾—è®­ç»ƒç¨³å®šã€‚PGGANåˆ™é€å±‚å¢å¤§ç½‘ç»œï¼Œç”Ÿæˆæœºå™¨é€¼çœŸçš„äººè„¸ã€‚</p><p><a name="rkublv"></a></p><h3 id="è„‰ç»œä¸‰-sequencelearning"><a href="#è„‰ç»œä¸‰-sequencelearning" class="headerlink" title="è„‰ç»œä¸‰ sequencelearning"></a>è„‰ç»œä¸‰ sequencelearning</h3><p>1982å¹´  å‡ºç°çš„hopfield networkæœ‰äº†é€’å½’ç½‘ç»œçš„æ€æƒ³ã€‚</p><p>1997å¹´  JÃ¼rgen Schmidhuberå‘æ˜LSTMï¼Œå¹¶åšäº†ä¸€ç³»åˆ—çš„å·¥ä½œã€‚ä½†æ˜¯æ›´æœ‰å½±å“åŠ›çš„è¿˜æ˜¯2013å¹´ç”±Hintonç»„ä½¿ç”¨RNNåšçš„è¯­éŸ³è¯†åˆ«å·¥ä½œï¼Œè¿™ç§æ–¹æ³•æ¯”ä¼ ç»Ÿæ–¹æ³•æ›´å¼ºã€‚</p><p>æ–‡æœ¬æ–¹é¢ï¼ŒBengioåœ¨svmæœ€ç«çš„æ—¶æœŸæå‡ºäº†ä¸€ç§åŸºäºç¥ç»ç½‘ç»œçš„è¯­è¨€æ¨¡å‹ï¼Œåæ¥Googleæå‡ºçš„word2vecä¹ŸåŒ…å«äº†ä¸€äº›åå‘ä¼ æ’­çš„æ€æƒ³ã€‚åœ¨æœºå™¨ç¿»è¯‘ç­‰ä»»åŠ¡ä¸Šï¼Œé€æ¸å‡ºç°äº†ä»¥RNNä¸ºåŸºç¡€çš„seq2seqæ¨¡å‹ï¼ˆåºåˆ—æ¨¡å‹ï¼‰ï¼Œæ¨¡å‹é€šè¿‡ä¸€ä¸ªencoderï¼ˆç¼–ç å™¨ï¼‰æŠŠä¸€å¥è¯çš„è¯­ä¹‰ä¿¡æ¯å‹æˆå‘é‡å†é€šè¿‡decoderï¼ˆè§£ç å™¨ï¼‰è¾“å‡ºï¼Œå½“ç„¶æ›´å¤šçš„è¿˜è¦å’ŒAttention Modelï¼ˆæ³¨æ„åŠ›æ¨¡å‹ï¼‰ç»“åˆã€‚</p><p>åæ¥ï¼Œå¤§å®¶å‘ç°ä½¿ç”¨ä»¥å­—ç¬¦ä¸ºå•ä½çš„CNNæ¨¡å‹åœ¨å¾ˆå¤šè¯­è¨€ä»»åŠ¡ä¹Ÿæœ‰ä¸ä¿—çš„è¡¨ç°ï¼Œè€Œä¸”æ—¶ç©ºæ¶ˆè€—æ›´å°‘ã€‚LSTM/RNN æ¨¡å‹ä¸­çš„Attentionæœºåˆ¶æ˜¯ç”¨äºå…‹æœä¼ ç»Ÿç¼–ç å™¨-è§£ç å™¨ç»“æ„å­˜åœ¨çš„é—®é¢˜çš„ã€‚å…¶ä¸­ï¼Œself-attentionï¼ˆè‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼‰å®é™…ä¸Šå°±æ˜¯é‡‡å–ä¸€ç§ç»“æ„å»åŒæ—¶è€ƒè™‘åŒä¸€åºåˆ—å±€éƒ¨å’Œå…¨å±€çš„ä¿¡æ¯ï¼ŒGoogleå°±æœ‰ä¸€ç¯‡è€¸äººå¬é—»çš„Attention Is All You Needçš„æ–‡ç« ã€‚</p><p><a name="65uhmf"></a></p><h3 id="è„‰ç»œå››-deepreinforcement-learning"><a href="#è„‰ç»œå››-deepreinforcement-learning" class="headerlink" title="è„‰ç»œå›› deepreinforcement learning"></a>è„‰ç»œå›› deepreinforcement learning</h3><p>è¯¥é¢†åŸŸæœ€å‡ºåçš„æ˜¯DeepMindï¼Œè¿™é‡Œåˆ—å‡ºçš„David Silveråˆ™æ˜¯ä¸€ç›´ç ”ç©¶rlï¼ˆå¼ºåŒ–å­¦ä¹ ï¼‰çš„é«˜ç®¡ã€‚</p><p>q-learningæ˜¯å¾ˆæœ‰åçš„ä¼ ç»Ÿrlç®—æ³•ï¼Œdeep q-learningåˆ™æ˜¯å°†åŸæ¥çš„qå€¼è¡¨ç”¨ç¥ç»ç½‘ç»œä»£æ›¿ã€‚åˆ©ç”¨deep q-learningåˆ¶ä½œçš„æ‰“ç –å—çš„æ¸¸æˆååˆ†æœ‰åã€‚åæ¥David Silverç­‰äººåˆåˆ©ç”¨å…¶æµ‹è¯•äº†è®¸å¤šæ¸¸æˆï¼Œå‘åœ¨äº†Natureä¸Šã€‚</p><p>å¢å¼ºå­¦ä¹ åœ¨double duelçš„è¿›å±•ï¼Œä¸»è¦æ˜¯Qlearningçš„æƒé‡æ›´æ–°æ—¶åºä¸Šã€‚</p><p>DeepMindçš„å…¶ä»–å·¥ä½œè¯¸å¦‚DDPGã€A3Cä¹Ÿéå¸¸æœ‰åï¼Œå®ƒä»¬æ˜¯åŸºäºpolicy gradientå’Œç¥ç»ç½‘ç»œç»“åˆçš„å˜ç§ã€‚</p><p>å¤§å®¶éƒ½çŸ¥é“çš„ä¸€ä¸ªåº”ç”¨æ˜¯AlphaGoï¼Œé‡Œé¢ä¸ä»…ä½¿ç”¨äº†rlçš„æ–¹æ³•ï¼Œä¹ŸåŒ…å«äº†ä¼ ç»Ÿçš„è’™ç‰¹å¡æ´›æœç´¢æŠ€å·§ã€‚Alpha Zero åˆ™æ˜¯ä»–ä»¬æäº†ä¸€ä¸ªç”¨Alphagoæ¡†æ¶æ¥æ‰“å…¶ä»–æ£‹ç±»æ¸¸æˆçš„æ¸¸æˆï¼Œè€Œä¸”è¿™ä¸ªâ€œæ‰“â€è¿˜æ˜¯åŠæ‰“çš„æ‰“ã€‚</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Deep Learningï¼ˆæ·±åº¦å­¦ä¹ ï¼‰çš„æ¦‚å¿µæºäºäººå·¥ç¥ç»ç½‘ç»œçš„ç ”ç©¶ï¼Œå®ƒçš„æ¦‚å¿µç”±Hintonç­‰äººäº2006å¹´æå‡ºï¼Œä½†å®ƒçš„æ¨¡å‹ç»å†äº†æ€æ ·çš„å‘å±•å’Œæ¼”åŒ–ï¼Œæœ¬æ–‡å°†ä¸ºæ‚¨æ·±åº¦è§£è¯»Deep Learningçš„å‰ä¸–ä»Šç”Ÿã€‚&lt;br /&gt;&lt;img src=&quot;https://static.amine
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Elasticsearch çŸ¥è¯†ç‚¹ç´¢å¼•</title>
    <link href="http://yixuxi.xyz/posts/yuque/Elasticsearch%20%E7%9F%A5%E8%AF%86%E7%82%B9%E7%B4%A2%E5%BC%95/"/>
    <id>http://yixuxi.xyz/posts/yuque/Elasticsearch çŸ¥è¯†ç‚¹ç´¢å¼•/</id>
    <published>2018-12-17T01:28:38.000Z</published>
    <updated>2019-11-13T07:23:02.273Z</updated>
    
    <content type="html"><![CDATA[<p><a name="9ykeeh"></a></p><h1 id="quick-start"><a href="#quick-start" class="headerlink" title="quick start"></a>quick start</h1><p><a name="qrpeom"></a></p><h2 id="install"><a href="#install" class="headerlink" title="install"></a>install</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a name=&quot;9ykeeh&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;quick-start&quot;&gt;&lt;a href=&quot;#quick-start&quot; class=&quot;headerlink&quot; title=&quot;quick start&quot;&gt;&lt;/a&gt;quick start&lt;/h1&gt;&lt;p&gt;&lt;a na
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>æµ‹è¯•å›¾ç‰‡</title>
    <link href="http://yixuxi.xyz/posts/yuque/%E6%B5%8B%E8%AF%95%E5%9B%BE%E7%89%87/"/>
    <id>http://yixuxi.xyz/posts/yuque/æµ‹è¯•å›¾ç‰‡/</id>
    <published>2018-12-12T22:22:01.000Z</published>
    <updated>2019-11-13T07:23:02.277Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://cdn.nlark.com/yuque/0/2019/png/223800/1572711795535-706c0409-f726-4627-9d0a-e3d799d7fd00.png#align=left&display=inline&height=225&name=images%20%283%29.png&originHeight=225&originWidth=225&search=&size=1636&status=done&width=225" alt="images (3).png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/223800/1572711795535-706c0409-f726-4627-9d0a-e3d799d7fd00.png#align=left&amp;display=inline&amp;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>æµ‹è¯•æ–‡æ¡£</title>
    <link href="http://yixuxi.xyz/posts/yuque/%E6%B5%8B%E8%AF%95%E6%96%87%E6%A1%A3/"/>
    <id>http://yixuxi.xyz/posts/yuque/æµ‹è¯•æ–‡æ¡£/</id>
    <published>2018-12-11T22:43:12.000Z</published>
    <updated>2019-11-13T07:23:02.277Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yixuxi.xyz/posts/hello-world/"/>
    <id>http://yixuxi.xyz/posts/hello-world/</id>
    <published>2016-04-05T06:16:00.000Z</published>
    <updated>2019-11-13T07:22:27.373Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
      <category term="math" scheme="http://yixuxi.xyz/categories/math/"/>
    
    
  </entry>
  
</feed>
