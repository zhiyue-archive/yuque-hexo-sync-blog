[
  {
    "id": 1470262,
    "slug": "66b45610-4514-4c48-98d5-2be4de113575",
    "title": "《机器学习》西瓜书阅读笔记 | SF-Zhou's Blog",
    "book_id": 188088,
    "book": {
      "id": 188088,
      "type": "Book",
      "slug": "wiki",
      "name": "spin",
      "user_id": 223800,
      "description": "个人知识库",
      "creator_id": 223800,
      "public": 1,
      "items_count": 8,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-11-02T16:00:03.816Z",
      "updated_at": "2019-11-02T16:00:03.000Z",
      "created_at": "2018-12-12T06:42:09.000Z",
      "namespace": "zhiyue/wiki",
      "user": {
        "id": 223800,
        "type": "User",
        "login": "zhiyue",
        "name": "zhiyue",
        "description": null,
        "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
        "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 8,
        "public_books_count": 1,
        "followers_count": 4,
        "following_count": 1,
        "created_at": "2018-12-12T06:39:44.000Z",
        "updated_at": "2019-08-27T06:25:28.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "markdown",
    "body": "第 1 章 绪论\n--------\n\n### 基本术语\n\n`机器学习`：在计算机上从`数据`（data）中产生`模型`（model）的算法，即`学习算法`（learning algorithm）。\n\nA computer program is said to learn from experience EEE with respect to some class of tasks TTT and performance measure PPP, if its performance at tasks in TTT, as measured by PPP, improves with experience EEE.\n\n一般地，令 D\\={x⃗1,x⃗2,⋯,x⃗m}D = \\\\left \\\\{ \\\\vec {x}\\_1, \\\\vec {x}\\_2, \\\\cdots, \\\\vec {x}\\_m \\\\right \\\\}D\\={x1​,x2​,⋯,xm​} 表示包含 mmm 个`样本`（sample）的数据集，每个示例由 ddd 个`属性`（attribute）描述，则每个样本 x⃗i\\={xi1;xi2;⋯;xid}\\\\vec x\\_i = \\\\left \\\\{x\\_{i1}; x\\_{i2}; \\\\cdots; x\\_{id} \\\\right \\\\}xi​\\={xi1​;xi2​;⋯;xid​} 是 ddd 维样本空间 X\\\\mathcal{X}X 中的一个向量，x⃗i∈X\\\\vec x\\_i \\\\in \\\\mathcal{X}xi​∈X，其中 xijx\\_{ij}xij​ 是 x⃗i\\\\vec x\\_ixi​ 在第 jjj 个属性上的取值，ddd 称为样本 x⃗i\\\\vec x\\_ixi​ 的`维数`（dimensionality）。\n\n属性张成的空间称为`样本空间`（sample space），每个样本都可在这个空间中找到唯一的坐标位置，因此也把一个样本称为一个`特征向量`（feature vector）。\n\n从数据中学得模型的过程称之为`学习`（learning）或`训练`（training），学得模型适用于新样本的能力称为`泛化`（generalization）能力。\n\n### 假设空间\n\n`归纳`（induction）与`演绎`（deduction）是科学推理的两大基本手段。前者是从特殊到一般的泛化（generalization）过程，后者是从一般到特殊的特化（specialization）过程。从样例中学习是一个归纳的过程，亦称`归纳学习`（inductive learning）。\n\n狭义的归纳学习是从数据中学得`概念`（concept），最基本的概念学习是布尔概念学习。可以把学习的过程看作一个在所有`假设`（hypothesis）组成的空间中进行搜索的过程，搜索目标是找到与训练集`匹配`（fit）的假设。\n\n假设的表示一旦确定，`假设空间`（hypothesis space）及其规模大小就确定了。现实问题中通常面临很大的假设空间，但样本训练集是有限的，因此可能有多个假设与训练集一致，即存在一个与训练集一致的假设集合，称之为`版本空间`（version space）。\n\n### 归纳偏好\n\n机器学习算法在学习过程中对某种类型假设的偏好，称为`归纳偏好`（inductive bias）。归纳偏好可看作是学习算法在庞大的假设空间中对假设进行选择的价值观。\n\n`奥卡姆剃刀`（Occam's Razor）是自然科学研究中常用的原则，即若存在多个假设与观察一致，则选最简单的那个。如无必要，勿增实体。\n\n但奥卡姆剃刀原则并不平凡，“简单”的评价标准无法量化。事实上归纳偏好对应了学习算法本身所做出的关于“什么样的模型更好”的假设。`没有免费的午餐定理`（No Free Lunch Theorem，NFL）证明了在真实目标函数 fff 均匀分布的情况下，所有学习算法学得的模型期望性能是一致的。\n\n脱离实际问题，空谈“什么学习算法更好”毫无意义。\n\n第 2 章 模型评估与选择\n-------------\n\n### 经验误差与过拟合\n\n学习器的实际输出与样本的真实输出之间的差异称为`误差`（error），训练集上的误差称为`训练误差`（training error），新样本上的误差称为`泛化误差`（generalization error）。\n\n为了使泛化误差最小化，应该从训练样本中尽可能学出适用于所有潜在样本的“普遍规律”。而将训练样本的特点当作了所有潜在样本的一般性质，导致泛化性能下降的现象，称为`过拟合`（overfitting），相对地没有充分习得训练样本的一般性质的现象，称为`欠拟合`（underfitting）。\n\n现实任务中，存在多种学习算法、不同参数配置，产生不同的模型，需要选择其中合适的模型，该问题称为`模型选择`（model selection）问题。理想状态下使用泛化误差作为模型选择的评价标准，但泛化误差无法直接获得。\n\n### 评估方法\n\n通常使用`测试集`（testing set）来测试学习器对新样本的判别能力，以测试集上的`测试误差`（testing error）作为泛化误差的近似。通常假设测试样本是从样本真实分布中独立同分布采样而得。\n\n对于包含 mmm 个样本的数据集 D\\={(x⃗1,y1),(x⃗2,y2),⋯,(x⃗m,ym)}D = \\\\left \\\\{ (\\\\vec x\\_1, y\\_1), (\\\\vec x\\_2, y\\_2), \\\\cdots, (\\\\vec x\\_m, y\\_m) \\\\right \\\\}D\\={(x1​,y1​),(x2​,y2​),⋯,(xm​,ym​)}，需要将其分解为训练集 SSS、验证集 VVV 和测试集 TTT，常用的方法有留出法、交叉验证法和`自助法`（bootstrapping）。\n\n自助法即从数据集中进行 mmm 次可重复采样，可以选出约 36.8% 的样本作为测试集，在数据集较小时较为有效。\n\n机器学习常涉及两类参数：一是算法的参数，称为`超参数`（hyper parameter），一是模型的参数。对超参数进行设定调优的过程称为`调参`（parameter tuning）。通常使用验证集进行模型选择和调参，使用测试集评估模型的泛化能力。\n\n### 性能度量\n\n性能度量（performance measure），即为模型泛化能力的评价标准。给定数据集 D\\={(x⃗1,y1),(x⃗2,y2),⋯,(x⃗m,ym)}D = \\\\left \\\\{ (\\\\vec x\\_1, y\\_1), (\\\\vec x\\_2, y\\_2), \\\\cdots, (\\\\vec x\\_m, y\\_m) \\\\right \\\\}D\\={(x1​,y1​),(x2​,y2​),⋯,(xm​,ym​)}，其中 yiy\\_iyi​ 是样本 x⃗i\\\\vec x\\_ixi​ 的真实标记。\n\n回归任务常用的性能度量是`均方误差`（mean squared error）：\n\nE(f;D)\\=∫x⃗∼D(f(x⃗)−y)2p(x⃗)dx⃗ E(f; \\\\mathcal{D}) = \\\\int\\_{\\\\vec x \\\\sim \\\\mathcal D} (f(\\\\vec x) - y)^2 p(\\\\vec {x}) d\\\\vec x E(f;D)\\=∫x∼D​(f(x)−y)2p(x)dx\n\n分类任务常用的性能度量较多，常用的错误率：\n\nE(f;D)\\=∫x⃗∼DI(f(x⃗)≠y)p(x⃗)dx⃗ E(f; \\\\mathcal{D}) = \\\\int\\_{\\\\vec x \\\\sim \\\\mathcal D} \\\\mathbb I(f(\\\\vec x) \\\\neq y) p(\\\\vec {x}) d\\\\vec x E(f;D)\\=∫x∼D​I(f(x)̸​\\=y)p(x)dx\n\n`准确率`（percision）和`召回率`（recall）：\n\nP\\=TPTP+FPR\\=TPTP+FN \\\\begin{aligned} P &= \\\\frac {TP} {TP + FP} \\\\\\\\ R &= \\\\frac {TP} {TP + FN} \\\\end{aligned} PR​\\=TP+FPTP​\\=TP+FNTP​​\n\n预测正例\n\n预测负例\n\n真实正例\n\nTP\n\nFN\n\n真实负例\n\nFP\n\nTN\n\n准确率和召回率不可得兼。以准确率作为纵轴、召回率作为横轴，可以得到`P-R曲线`，曲线中“准确率=召回率”的点成为`平衡点`（Break-Even Point）。\n\n准确率和召回率的`调和平均`（harmonic mean）称为`F1`度量：\n\n1F1\\=12(1P+1R)F1\\=2PRP+R \\\\begin{aligned} \\\\frac {1} {F1} &= \\\\frac {1} {2} (\\\\frac {1} {P} + \\\\frac {1} {R}) \\\\\\\\ F1 &= \\\\frac {2PR} {P + R} \\\\end{aligned} F11​F1​\\=21​(P1​+R1​)\\=P+R2PR​​\n\n由多组混淆矩阵计算多组准确率和召回率，再求平均值，可得`宏准确率`（macro-P）和`宏召回率`（macro-R）；将多组混淆矩阵求平均值，再求准确率和召回率，可得`微准确率`（micro-P）和`微召回率`（micro-R）。\n\n`ROC` 全称受试者工作特征（Receiver Operating Characteristic），该曲线以`真正例率`（True Positive Rate）为纵轴，以`假正例率`（False Positive Rate）为横轴：\n\nTPR\\=TPTP+FNFPR\\=FPTN+FP \\\\begin{aligned} TPR &= \\\\frac {TP} {TP + FN} \\\\\\\\ FPR & = \\\\frac {FP} {TN + FP} \\\\end{aligned} TPRFPR​\\=TP+FNTP​\\=TN+FPFP​​\n\nROC 曲线下的面积称为`AUC`（Area Under ROC Curve），通常使用 AUC 作为ROC 曲线优劣的判断依据。\n\n不同类型的错误所造成的后果不同，为权衡不同类型错误所造成的不同损失，可为错误赋予`非均等代价`（unequal cost）。令 D+D^+D+ 与 D−D^-D− 代表数据集 DDD 中的正例子集和反例子集，则`代价敏感`（cost-sensitive）错误率为：\n\nE(f;D;cost)\\=1m(∑x⃗i∈D+I(f(x⃗i)≠yi)cost01+∑x⃗i∈D−I(f(x⃗i)≠yi)cost10) E(f; D; cost) = \\\\frac {1} {m} \\\\left ( \\\\sum\\_{\\\\vec x\\_i \\\\in D^+} \\\\mathbb I (f(\\\\vec x\\_i) \\\\neq y\\_i) cost\\_{01} + \\\\sum\\_{\\\\vec x\\_i \\\\in D^-} \\\\mathbb I (f(\\\\vec x\\_i) \\\\neq y\\_i) cost\\_{10} \\\\right ) E(f;D;cost)\\=m1​⎝⎛​xi​∈D+∑​I(f(xi​)̸​\\=yi​)cost01​+xi​∈D−∑​I(f(xi​)̸​\\=yi​)cost10​⎠⎞​\n\n### 偏差与方差\n\n`偏差-方差分解`（bias-veriance decomposition）是解释学习算法泛化性能的一种重要工具。对测试样本 x⃗\\\\vec xx，令 yDy\\_DyD​ 为 x⃗\\\\vec xx 在数据集中的标记，yyy 为 x⃗\\\\vec xx 的真实标记，f(x⃗;D)f(\\\\vec x; D)f(x;D) 为训练集 DDD 上学的模型 fff 在 x⃗\\\\vec xx 上的预测输出。以回归任务为例，学习算法的期望预测为：\n\nfˉ(x⃗)\\=ED\\[f(x⃗;D)\\] \\\\bar f(\\\\vec x) = \\\\mathbb E\\_D \\\\left \\[ f(\\\\vec x; D) \\\\right \\] fˉ​(x)\\=ED​\\[f(x;D)\\]\n\n期望输出与真实标记的差别称为`偏差`（bias）：\n\nbias2(x⃗)\\=(fˉ(x⃗)−y)2 bias^2(\\\\vec x) = \\\\left ( \\\\bar f(\\\\vec x) - y \\\\right )^2 bias2(x)\\=(fˉ​(x)−y)2\n\n使用样本数相同的不同训练集产生的`方差`（variance）为：\n\nvar(x⃗)\\=ED\\[(f(x⃗;D)−fˉ(x⃗))2\\] var(\\\\vec x) = \\\\mathbb E\\_D \\\\left \\[ \\\\left (f(\\\\vec x; D) - \\\\bar f(\\\\vec x) \\\\right )^2 \\\\right \\] var(x)\\=ED​\\[(f(x;D)−fˉ​(x))2\\]\n\n噪声为：\n\nε2\\=ED\\[(yD−y)2\\] \\\\varepsilon ^2 = \\\\mathbb E\\_D \\\\left \\[ (y\\_D - y)^2 \\\\right \\] ε2\\=ED​\\[(yD​−y)2\\]\n\n假定噪声的期望为零，可得：\n\nE(f;D)\\=bias2(x⃗)+var(x⃗)+ε2 E(f; D) = bias^2(\\\\vec x) + var(\\\\vec x) + \\\\varepsilon ^2 E(f;D)\\=bias2(x)+var(x)+ε2\n\n即泛化误差可以分解为偏差、方差和噪声之和。偏差和方差间存在`偏差-方差窘境`（bias-variance dilemma），当学习算法训练不足时，学习器的拟合能力不够强，偏差主导了泛化错误率；当训练程度加深后，学习器的拟合能力足够，方差主导了泛化错误率。\n\n第 3 章 线性模型\n----------\n\n### 基本形式\n\n给定由 ddd 个属性描述的示例 x\\=(x1;x2;⋯;xd)\\\\boldsymbol x = (x\\_1; x\\_2; \\\\cdots; x\\_d)x\\=(x1​;x2​;⋯;xd​)，其中 xix\\_ixi​ 是 x\\\\boldsymbol xx 在第 iii 个属性上的取值，`线性模型`（linear model）试图学得一个通过属性的线性组合来进行预测的函数：\n\nf(x)\\=wTx+b f(\\\\boldsymbol x) = \\\\boldsymbol w^T \\\\boldsymbol x + b f(x)\\=wTx+b\n\n其中 w\\=(w1;w2;⋯;wd)\\\\boldsymbol w = (w\\_1; w\\_2; \\\\cdots; w\\_d)w\\=(w1​;w2​;⋯;wd​)。\n\n线性模型形式简单，易于建模，且 w\\\\boldsymbol ww 直观表达了各属性在预测中的重要性，因此线性模型有很好的 `可解释性`（comprehensibility）。\n\n在线性模型的基础上可通过引入层级结构或高维映射而得到更为强大的`非线性模型`（nonlinear model）。\n\n### 线性回归\n\n给定数据集 D\\={(x1,y1),(x2,y2),⋯,(xm,ym)}D = \\\\{(\\\\boldsymbol x\\_1, y\\_1), (\\\\boldsymbol x\\_2, y\\_2), \\\\cdots , (\\\\boldsymbol x\\_m, y\\_m)\\\\}D\\={(x1​,y1​),(x2​,y2​),⋯,(xm​,ym​)}，其中 xi\\=(xi1,xi2,⋯,xid)\\\\boldsymbol x\\_i = (x\\_{i1}, x\\_{i2}, \\\\cdots, x\\_{id})xi​\\=(xi1​,xi2​,⋯,xid​)，y∈Ry \\\\in \\\\mathbb Ry∈R，`线性回归`（linear regression）试图学得一个线性模型以尽可能准确地预测实际输出标记。\n\n考虑最简单的单属性情形，D\\={(xi,yi)}i\\=1mD = \\\\left \\\\{ (x\\_i, y\\_i) \\\\right \\\\}\\_{i=1}^mD\\={(xi​,yi​)}i\\=1m​，线性回归试图学得\n\nf(xi)\\=wxi+b f(x\\_i) = wx\\_i+b f(xi​)\\=wxi​+b\n\n以使得 f(xi)≃yif(x\\_i) \\\\simeq y\\_if(xi​)≃yi​。使用均方误差作为衡量 f(x)f(x)f(x) 与 yyy 之间差别的性能度量：\n\nE(w,b)\\=∑i\\=1m(f(xi)−yi)2 E\\_{(w, b)} = \\\\sum\\_{i=1}^{m} {\\\\left (f(x\\_i) - y\\_i \\\\right )^2} E(w,b)​\\=i\\=1∑m​(f(xi​)−yi​)2\n\n则：\n\n(w∗,b∗)\\=arg⁡min⁡(w,b)E(w,b) (w^\\*, b^\\*) = \\\\underset {(w, b)} {\\\\arg \\\\min} E\\_{(w, b)} (w∗,b∗)\\=(w,b)argmin​E(w,b)​\n\n均方误差有非常好的几何意义，它对应了 `欧氏距离`（Euclidean distance）。基于均方误差最小化来进行模型求解的方法称为 `最小二乘法`（least square method）。在线性回归中，最小二乘法试图找到一条直线，使得所有样本到直线上的欧氏距离之和最小。\n\nE(w,b)E\\_{(w, b)}E(w,b)​ 是关于 www 和 bbb 的凸函数。对于区间 \\[a,b\\]\\[a, b\\]\\[a,b\\] 上定义的函数 fff，若它区间中任意两点 x1x\\_1x1​ 和 x2x\\_2x2​ 均有 f(x1+x22)≤f(x1)+f(x2)2f(\\\\frac {x\\_1 + x\\_2} {2}) \\\\le \\\\frac {f(x\\_1) + f(x\\_2)} {2}f(2x1​+x2​​)≤2f(x1​)+f(x2​)​，则称 fff 为区间 \\[a,b\\]\\[a, b\\]\\[a,b\\] 上的凸函数。对实数集上的函数，可以通过求二阶导数的方式来判断，二阶导数在区间上非负则称为凸函数。\n\n求解 www 和 bbb 使均方误差最小化的过程，称为线性回归模型的最小二乘 `参数估计`（parameter estimation）。将 E(w,b)E\\_{(w, b)}E(w,b)​ 分别对 www 和 bbb 求导，得到：\n\n∂E(w,b)∂w\\=2(w∑i\\=1mxi2−∑i\\=1m(yi−b)xi)∂E(w,b)∂b\\=2(mb−∑i\\=1m(yi−wxi)) \\\\begin {aligned} \\\\frac {\\\\partial E\\_{(w, b)}} {\\\\partial w} &= 2 \\\\left ( w \\\\sum\\_{i=1}^{m} x\\_i^2 - \\\\sum\\_{i=1}^{m} (y\\_i - b)x\\_i \\\\right ) \\\\\\\\ \\\\frac {\\\\partial E\\_{(w, b)}} {\\\\partial b} &= 2 \\\\left ( mb - \\\\sum\\_{i=1}^{m} (y\\_i - wx\\_i) \\\\right ) \\\\end {aligned} ∂w∂E(w,b)​​∂b∂E(w,b)​​​\\=2(wi\\=1∑m​xi2​−i\\=1∑m​(yi​−b)xi​)\\=2(mb−i\\=1∑m​(yi​−wxi​))​\n\n对 www 和 bbb 的偏导置零可得到 www 和 bbb 最优解的 `闭式解`（closed-form solution）：\n\nw\\=∑i\\=1mxiyi−mxˉyˉ∑i\\=1mxi2−mxˉ2b\\=yˉ−wxˉ \\\\begin {aligned} w &= \\\\frac {\\\\sum\\_{i=1}^{m}x\\_i y\\_i - m \\\\bar x \\\\bar y} {\\\\sum\\_{i=1}^{m} {x\\_i^2} - m \\\\bar x^2} \\\\\\\\ b &= \\\\bar y - w \\\\bar x \\\\end {aligned} wb​\\=∑i\\=1m​xi2​−mxˉ2∑i\\=1m​xi​yi​−mxˉyˉ​​\\=yˉ​−wxˉ​\n\n更一般的情形，给定数据集 D\\={(xi,yi)}i\\=1mD = \\\\left \\\\{ (\\\\boldsymbol x\\_i, y\\_i) \\\\right \\\\}\\_{i=1}^mD\\={(xi​,yi​)}i\\=1m​，其中 xi\\=(xi1,xi2,⋯,xid)\\\\boldsymbol x\\_i = (x\\_{i1}, x\\_{i2}, \\\\cdots, x\\_{id})xi​\\=(xi1​,xi2​,⋯,xid​)，y∈Ry \\\\in \\\\mathbb Ry∈R，线性回归试图学得：\n\nf(xi)\\=wTxi+b f(\\\\boldsymbol x\\_i) = \\\\boldsymbol w^T \\\\boldsymbol x\\_i+b f(xi​)\\=wTxi​+b\n\n使得 f(xi)≃yif(\\\\boldsymbol x\\_i) \\\\simeq y\\_if(xi​)≃yi​。这称为 `多变量线性回归`（multivariate linear regression）。\n\n\\[未完待续\\]\n\n### 参考文献\n\n1.  周志华. \"机器学习.\" 清华大学出版社，北京.",
    "body_draft": "",
    "body_html": "<a name=\"第-1-章-绪论\"></a><h2 id=\"d2632f7c\">第 1 章 绪论</h2><p><br /></p><a name=\"基本术语\"></a><h3 id=\"60657fa7\">基本术语</h3><p><br /></p><p><code>机器学习</code>：在计算机上从<code>数据</code>（data）中产生<code>模型</code>（model）的算法，即<code>学习算法</code>（learning algorithm）。</p><p><br /></p><p>A computer program is said to learn from experience EEE with respect to some class of tasks TTT and performance measure PPP, if its performance at tasks in TTT, as measured by PPP, improves with experience EEE.</p><p><br /></p><p>一般地，令 D={x⃗1,x⃗2,⋯,x⃗m}D = \\left \\{ \\vec {x}_1, \\vec {x}_2, \\cdots, \\vec {x}_m \\right \\}D={x1​,x2​,⋯,xm​} 表示包含 mmm 个<code>样本</code>（sample）的数据集，每个示例由 ddd 个<code>属性</code>（attribute）描述，则每个样本 x⃗i={xi1;xi2;⋯;xid}\\vec x_i = \\left \\{x_{i1}; x_{i2}; \\cdots; x_{id} \\right \\}xi​={xi1​;xi2​;⋯;xid​} 是 ddd 维样本空间 X\\mathcal{X}X 中的一个向量，x⃗i∈X\\vec x_i \\in \\mathcal{X}xi​∈X，其中 xijx_{ij}xij​ 是 x⃗i\\vec x_ixi​ 在第 jjj 个属性上的取值，ddd 称为样本 x⃗i\\vec x_ixi​ 的<code>维数</code>（dimensionality）。</p><p><br /></p><p>属性张成的空间称为<code>样本空间</code>（sample space），每个样本都可在这个空间中找到唯一的坐标位置，因此也把一个样本称为一个<code>特征向量</code>（feature vector）。</p><p><br /></p><p>从数据中学得模型的过程称之为<code>学习</code>（learning）或<code>训练</code>（training），学得模型适用于新样本的能力称为<code>泛化</code>（generalization）能力。</p><p><br /></p><a name=\"假设空间\"></a><h3 id=\"d70ed78e\">假设空间</h3><p><br /></p><p><code>归纳</code>（induction）与<code>演绎</code>（deduction）是科学推理的两大基本手段。前者是从特殊到一般的泛化（generalization）过程，后者是从一般到特殊的特化（specialization）过程。从样例中学习是一个归纳的过程，亦称<code>归纳学习</code>（inductive learning）。</p><p><br /></p><p>狭义的归纳学习是从数据中学得<code>概念</code>（concept），最基本的概念学习是布尔概念学习。可以把学习的过程看作一个在所有<code>假设</code>（hypothesis）组成的空间中进行搜索的过程，搜索目标是找到与训练集<code>匹配</code>（fit）的假设。</p><p><br /></p><p>假设的表示一旦确定，<code>假设空间</code>（hypothesis space）及其规模大小就确定了。现实问题中通常面临很大的假设空间，但样本训练集是有限的，因此可能有多个假设与训练集一致，即存在一个与训练集一致的假设集合，称之为<code>版本空间</code>（version space）。</p><p><br /></p><a name=\"归纳偏好\"></a><h3 id=\"b5c5f209\">归纳偏好</h3><p><br /></p><p>机器学习算法在学习过程中对某种类型假设的偏好，称为<code>归纳偏好</code>（inductive bias）。归纳偏好可看作是学习算法在庞大的假设空间中对假设进行选择的价值观。</p><p><br /></p><p><code>奥卡姆剃刀</code>（Occam's Razor）是自然科学研究中常用的原则，即若存在多个假设与观察一致，则选最简单的那个。如无必要，勿增实体。</p><p><br /></p><p>但奥卡姆剃刀原则并不平凡，“简单”的评价标准无法量化。事实上归纳偏好对应了学习算法本身所做出的关于“什么样的模型更好”的假设。<code>没有免费的午餐定理</code>（No Free Lunch Theorem，NFL）证明了在真实目标函数 fff 均匀分布的情况下，所有学习算法学得的模型期望性能是一致的。</p><p><br /></p><p>脱离实际问题，空谈“什么学习算法更好”毫无意义。</p><p><br /></p><a name=\"第-2-章-模型评估与选择\"></a><h2 id=\"07bd81f2\">第 2 章 模型评估与选择</h2><p><br /></p><a name=\"经验误差与过拟合\"></a><h3 id=\"1ac7a372\">经验误差与过拟合</h3><p><br /></p><p>学习器的实际输出与样本的真实输出之间的差异称为<code>误差</code>（error），训练集上的误差称为<code>训练误差</code>（training error），新样本上的误差称为<code>泛化误差</code>（generalization error）。</p><p><br /></p><p>为了使泛化误差最小化，应该从训练样本中尽可能学出适用于所有潜在样本的“普遍规律”。而将训练样本的特点当作了所有潜在样本的一般性质，导致泛化性能下降的现象，称为<code>过拟合</code>（overfitting），相对地没有充分习得训练样本的一般性质的现象，称为<code>欠拟合</code>（underfitting）。</p><p><br /></p><p>现实任务中，存在多种学习算法、不同参数配置，产生不同的模型，需要选择其中合适的模型，该问题称为<code>模型选择</code>（model selection）问题。理想状态下使用泛化误差作为模型选择的评价标准，但泛化误差无法直接获得。</p><p><br /></p><a name=\"评估方法\"></a><h3 id=\"f3787b82\">评估方法</h3><p><br /></p><p>通常使用<code>测试集</code>（testing set）来测试学习器对新样本的判别能力，以测试集上的<code>测试误差</code>（testing error）作为泛化误差的近似。通常假设测试样本是从样本真实分布中独立同分布采样而得。</p><p><br /></p><p>对于包含 mmm 个样本的数据集 D={(x⃗1,y1),(x⃗2,y2),⋯,(x⃗m,ym)}D = \\left \\{ (\\vec x_1, y_1), (\\vec x_2, y_2), \\cdots, (\\vec x_m, y_m) \\right \\}D={(x1​,y1​),(x2​,y2​),⋯,(xm​,ym​)}，需要将其分解为训练集 SSS、验证集 VVV 和测试集 TTT，常用的方法有留出法、交叉验证法和<code>自助法</code>（bootstrapping）。</p><p><br /></p><p>自助法即从数据集中进行 mmm 次可重复采样，可以选出约 36.8% 的样本作为测试集，在数据集较小时较为有效。</p><p><br /></p><p>机器学习常涉及两类参数：一是算法的参数，称为<code>超参数</code>（hyper parameter），一是模型的参数。对超参数进行设定调优的过程称为<code>调参</code>（parameter tuning）。通常使用验证集进行模型选择和调参，使用测试集评估模型的泛化能力。</p><p><br /></p><a name=\"性能度量\"></a><h3 id=\"1a299e7e\">性能度量</h3><p><br /></p><p>性能度量（performance measure），即为模型泛化能力的评价标准。给定数据集 D={(x⃗1,y1),(x⃗2,y2),⋯,(x⃗m,ym)}D = \\left \\{ (\\vec x_1, y_1), (\\vec x_2, y_2), \\cdots, (\\vec x_m, y_m) \\right \\}D={(x1​,y1​),(x2​,y2​),⋯,(xm​,ym​)}，其中 yiy_iyi​ 是样本 x⃗i\\vec x_ixi​ 的真实标记。</p><p><br /></p><p>回归任务常用的性能度量是<code>均方误差</code>（mean squared error）：</p><p><br /></p><p>E(f;D)=∫x⃗∼D(f(x⃗)−y)2p(x⃗)dx⃗ E(f; \\mathcal{D}) = \\int_{\\vec x \\sim \\mathcal D} (f(\\vec x) - y)^2 p(\\vec {x}) d\\vec x E(f;D)=∫x∼D​(f(x)−y)2p(x)dx</p><p><br /></p><p>分类任务常用的性能度量较多，常用的错误率：</p><p><br /></p><p>E(f;D)=∫x⃗∼DI(f(x⃗)≠y)p(x⃗)dx⃗ E(f; \\mathcal{D}) = \\int_{\\vec x \\sim \\mathcal D} \\mathbb I(f(\\vec x) \\neq y) p(\\vec {x}) d\\vec x E(f;D)=∫x∼D​I(f(x)̸​=y)p(x)dx</p><p><br /></p><p><code>准确率</code>（percision）和<code>召回率</code>（recall）：</p><p><br /></p><p>P=TPTP+FPR=TPTP+FN \\begin{aligned} P &amp;= \\frac {TP} {TP + FP} \\\\ R &amp;= \\frac {TP} {TP + FN} \\end{aligned} PR​=TP+FPTP​=TP+FNTP​​</p><p><br /></p><p>预测正例</p><p><br /></p><p>预测负例</p><p><br /></p><p>真实正例</p><p><br /></p><p>TP</p><p><br /></p><p>FN</p><p><br /></p><p>真实负例</p><p><br /></p><p>FP</p><p><br /></p><p>TN</p><p><br /></p><p>准确率和召回率不可得兼。以准确率作为纵轴、召回率作为横轴，可以得到<code>P-R曲线</code>，曲线中“准确率=召回率”的点成为<code>平衡点</code>（Break-Even Point）。</p><p><br /></p><p>准确率和召回率的<code>调和平均</code>（harmonic mean）称为<code>F1</code>度量：</p><p><br /></p><p>1F1=12(1P+1R)F1=2PRP+R \\begin{aligned} \\frac {1} {F1} &amp;= \\frac {1} {2} (\\frac {1} {P} + \\frac {1} {R}) \\\\ F1 &amp;= \\frac {2PR} {P + R} \\end{aligned} F11​F1​=21​(P1​+R1​)=P+R2PR​​</p><p><br /></p><p>由多组混淆矩阵计算多组准确率和召回率，再求平均值，可得<code>宏准确率</code>（macro-P）和<code>宏召回率</code>（macro-R）；将多组混淆矩阵求平均值，再求准确率和召回率，可得<code>微准确率</code>（micro-P）和<code>微召回率</code>（micro-R）。</p><p><br /></p><p><code>ROC</code> 全称受试者工作特征（Receiver Operating Characteristic），该曲线以<code>真正例率</code>（True Positive Rate）为纵轴，以<code>假正例率</code>（False Positive Rate）为横轴：</p><p><br /></p><p>TPR=TPTP+FNFPR=FPTN+FP \\begin{aligned} TPR &amp;= \\frac {TP} {TP + FN} \\\\ FPR &amp; = \\frac {FP} {TN + FP} \\end{aligned} TPRFPR​=TP+FNTP​=TN+FPFP​​</p><p><br /></p><p>ROC 曲线下的面积称为<code>AUC</code>（Area Under ROC Curve），通常使用 AUC 作为ROC 曲线优劣的判断依据。</p><p><br /></p><p>不同类型的错误所造成的后果不同，为权衡不同类型错误所造成的不同损失，可为错误赋予<code>非均等代价</code>（unequal cost）。令 D+D^+D+ 与 D−D^-D− 代表数据集 DDD 中的正例子集和反例子集，则<code>代价敏感</code>（cost-sensitive）错误率为：</p><p><br /></p><p>E(f;D;cost)=1m(∑x⃗i∈D+I(f(x⃗i)≠yi)cost01+∑x⃗i∈D−I(f(x⃗i)≠yi)cost10) E(f; D; cost) = \\frac {1} {m} \\left ( \\sum_{\\vec x_i \\in D^+} \\mathbb I (f(\\vec x_i) \\neq y_i) cost_{01} + \\sum_{\\vec x_i \\in D^-} \\mathbb I (f(\\vec x_i) \\neq y_i) cost_{10} \\right ) E(f;D;cost)=m1​⎝⎛​xi​∈D+∑​I(f(xi​)̸​=yi​)cost01​+xi​∈D−∑​I(f(xi​)̸​=yi​)cost10​⎠⎞​</p><p><br /></p><a name=\"偏差与方差\"></a><h3 id=\"ba51c5c7\">偏差与方差</h3><p><br /></p><p><code>偏差-方差分解</code>（bias-veriance decomposition）是解释学习算法泛化性能的一种重要工具。对测试样本 x⃗\\vec xx，令 yDy_DyD​ 为 x⃗\\vec xx 在数据集中的标记，yyy 为 x⃗\\vec xx 的真实标记，f(x⃗;D)f(\\vec x; D)f(x;D) 为训练集 DDD 上学的模型 fff 在 x⃗\\vec xx 上的预测输出。以回归任务为例，学习算法的期望预测为：</p><p><br /></p><p>fˉ(x⃗)=ED[f(x⃗;D)] \\bar f(\\vec x) = \\mathbb E_D \\left [ f(\\vec x; D) \\right ] fˉ​(x)=ED​[f(x;D)]</p><p><br /></p><p>期望输出与真实标记的差别称为<code>偏差</code>（bias）：</p><p><br /></p><p>bias2(x⃗)=(fˉ(x⃗)−y)2 bias^2(\\vec x) = \\left ( \\bar f(\\vec x) - y \\right )^2 bias2(x)=(fˉ​(x)−y)2</p><p><br /></p><p>使用样本数相同的不同训练集产生的<code>方差</code>（variance）为：</p><p><br /></p><p>var(x⃗)=ED[(f(x⃗;D)−fˉ(x⃗))2] var(\\vec x) = \\mathbb E_D \\left [ \\left (f(\\vec x; D) - \\bar f(\\vec x) \\right )^2 \\right ] var(x)=ED​[(f(x;D)−fˉ​(x))2]</p><p><br /></p><p>噪声为：</p><p><br /></p><p>ε2=ED[(yD−y)2] \\varepsilon ^2 = \\mathbb E_D \\left [ (y_D - y)^2 \\right ] ε2=ED​[(yD​−y)2]</p><p><br /></p><p>假定噪声的期望为零，可得：</p><p><br /></p><p>E(f;D)=bias2(x⃗)+var(x⃗)+ε2 E(f; D) = bias^2(\\vec x) + var(\\vec x) + \\varepsilon ^2 E(f;D)=bias2(x)+var(x)+ε2</p><p><br /></p><p>即泛化误差可以分解为偏差、方差和噪声之和。偏差和方差间存在<code>偏差-方差窘境</code>（bias-variance dilemma），当学习算法训练不足时，学习器的拟合能力不够强，偏差主导了泛化错误率；当训练程度加深后，学习器的拟合能力足够，方差主导了泛化错误率。</p><p><br /></p><a name=\"第-3-章-线性模型\"></a><h2 id=\"761d37e2\">第 3 章 线性模型</h2><p><br /></p><a name=\"基本形式\"></a><h3 id=\"53fae5a5\">基本形式</h3><p><br /></p><p>给定由 ddd 个属性描述的示例 x=(x1;x2;⋯;xd)\\boldsymbol x = (x_1; x_2; \\cdots; x_d)x=(x1​;x2​;⋯;xd​)，其中 xix_ixi​ 是 x\\boldsymbol xx 在第 iii 个属性上的取值，<code>线性模型</code>（linear model）试图学得一个通过属性的线性组合来进行预测的函数：</p><p><br /></p><p>f(x)=wTx+b f(\\boldsymbol x) = \\boldsymbol w^T \\boldsymbol x + b f(x)=wTx+b</p><p><br /></p><p>其中 w=(w1;w2;⋯;wd)\\boldsymbol w = (w_1; w_2; \\cdots; w_d)w=(w1​;w2​;⋯;wd​)。</p><p><br /></p><p>线性模型形式简单，易于建模，且 w\\boldsymbol ww 直观表达了各属性在预测中的重要性，因此线性模型有很好的 <code>可解释性</code>（comprehensibility）。</p><p><br /></p><p>在线性模型的基础上可通过引入层级结构或高维映射而得到更为强大的<code>非线性模型</code>（nonlinear model）。</p><p><br /></p><a name=\"线性回归\"></a><h3 id=\"d8b87768\">线性回归</h3><p><br /></p><p>给定数据集 D={(x1,y1),(x2,y2),⋯,(xm,ym)}D = \\{(\\boldsymbol x_1, y_1), (\\boldsymbol x_2, y_2), \\cdots , (\\boldsymbol x_m, y_m)\\}D={(x1​,y1​),(x2​,y2​),⋯,(xm​,ym​)}，其中 xi=(xi1,xi2,⋯,xid)\\boldsymbol x_i = (x_{i1}, x_{i2}, \\cdots, x_{id})xi​=(xi1​,xi2​,⋯,xid​)，y∈Ry \\in \\mathbb Ry∈R，<code>线性回归</code>（linear regression）试图学得一个线性模型以尽可能准确地预测实际输出标记。</p><p><br /></p><p>考虑最简单的单属性情形，D={(xi,yi)}i=1mD = \\left \\{ (x_i, y_i) \\right \\}_{i=1}^mD={(xi​,yi​)}i=1m​，线性回归试图学得</p><p><br /></p><p>f(xi)=wxi+b f(x_i) = wx_i+b f(xi​)=wxi​+b</p><p><br /></p><p>以使得 f(xi)≃yif(x_i) \\simeq y_if(xi​)≃yi​。使用均方误差作为衡量 f(x)f(x)f(x) 与 yyy 之间差别的性能度量：</p><p><br /></p><p>E(w,b)=∑i=1m(f(xi)−yi)2 E_{(w, b)} = \\sum_{i=1}^{m} {\\left (f(x_i) - y_i \\right )^2} E(w,b)​=i=1∑m​(f(xi​)−yi​)2</p><p><br /></p><p>则：</p><p><br /></p><p>(w∗,b∗)=arg⁡min⁡(w,b)E(w,b) (w^*, b^*) = \\underset {(w, b)} {\\arg \\min} E_{(w, b)} (w∗,b∗)=(w,b)argmin​E(w,b)​</p><p><br /></p><p>均方误差有非常好的几何意义，它对应了 <code>欧氏距离</code>（Euclidean distance）。基于均方误差最小化来进行模型求解的方法称为 <code>最小二乘法</code>（least square method）。在线性回归中，最小二乘法试图找到一条直线，使得所有样本到直线上的欧氏距离之和最小。</p><p><br /></p><p>E(w,b)E_{(w, b)}E(w,b)​ 是关于 www 和 bbb 的凸函数。对于区间 [a,b][a, b][a,b] 上定义的函数 fff，若它区间中任意两点 x1x_1x1​ 和 x2x_2x2​ 均有 f(x1+x22)≤f(x1)+f(x2)2f(\\frac {x_1 + x_2} {2}) \\le \\frac {f(x_1) + f(x_2)} {2}f(2x1​+x2​​)≤2f(x1​)+f(x2​)​，则称 fff 为区间 [a,b][a, b][a,b] 上的凸函数。对实数集上的函数，可以通过求二阶导数的方式来判断，二阶导数在区间上非负则称为凸函数。</p><p><br /></p><p>求解 www 和 bbb 使均方误差最小化的过程，称为线性回归模型的最小二乘 <code>参数估计</code>（parameter estimation）。将 E(w,b)E_{(w, b)}E(w,b)​ 分别对 www 和 bbb 求导，得到：</p><p><br /></p><p>∂E(w,b)∂w=2(w∑i=1mxi2−∑i=1m(yi−b)xi)∂E(w,b)∂b=2(mb−∑i=1m(yi−wxi)) \\begin {aligned} \\frac {\\partial E_{(w, b)}} {\\partial w} &amp;= 2 \\left ( w \\sum_{i=1}^{m} x_i^2 - \\sum_{i=1}^{m} (y_i - b)x_i \\right ) \\\\ \\frac {\\partial E_{(w, b)}} {\\partial b} &amp;= 2 \\left ( mb - \\sum_{i=1}^{m} (y_i - wx_i) \\right ) \\end {aligned} ∂w∂E(w,b)​​∂b∂E(w,b)​​​=2(wi=1∑m​xi2​−i=1∑m​(yi​−b)xi​)=2(mb−i=1∑m​(yi​−wxi​))​</p><p><br /></p><p>对 www 和 bbb 的偏导置零可得到 www 和 bbb 最优解的 <code>闭式解</code>（closed-form solution）：</p><p><br /></p><p>w=∑i=1mxiyi−mxˉyˉ∑i=1mxi2−mxˉ2b=yˉ−wxˉ \\begin {aligned} w &amp;= \\frac {\\sum_{i=1}^{m}x_i y_i - m \\bar x \\bar y} {\\sum_{i=1}^{m} {x_i^2} - m \\bar x^2} \\\\ b &amp;= \\bar y - w \\bar x \\end {aligned} wb​=∑i=1m​xi2​−mxˉ2∑i=1m​xi​yi​−mxˉyˉ​​=yˉ​−wxˉ​</p><p><br /></p><p>更一般的情形，给定数据集 D={(xi,yi)}i=1mD = \\left \\{ (\\boldsymbol x_i, y_i) \\right \\}_{i=1}^mD={(xi​,yi​)}i=1m​，其中 xi=(xi1,xi2,⋯,xid)\\boldsymbol x_i = (x_{i1}, x_{i2}, \\cdots, x_{id})xi​=(xi1​,xi2​,⋯,xid​)，y∈Ry \\in \\mathbb Ry∈R，线性回归试图学得：</p><p><br /></p><p>f(xi)=wTxi+b f(\\boldsymbol x_i) = \\boldsymbol w^T \\boldsymbol x_i+b f(xi​)=wTxi​+b</p><p><br /></p><p>使得 f(xi)≃yif(\\boldsymbol x_i) \\simeq y_if(xi​)≃yi​。这称为 <code>多变量线性回归</code>（multivariate linear regression）。</p><p><br /></p><p>[未完待续]</p><p><br /></p><a name=\"参考文献\"></a><h3 id=\"fb507f2c\">参考文献</h3><p><br /></p><ol start=\"1\"><li>周志华. &quot;机器学习.&quot; 清华大学出版社，北京.</li></ol>",
    "body_lake": "<!doctype lake><a name=\"第-1-章-绪论\"></a><h2 id=\"d2632f7c\">第 1 章 绪论</h2><p><br /></p><a name=\"基本术语\"></a><h3 id=\"60657fa7\">基本术语</h3><p><br /></p><p><code>机器学习</code>：在计算机上从<code>数据</code>（data）中产生<code>模型</code>（model）的算法，即<code>学习算法</code>（learning algorithm）。</p><p><br /></p><p>A computer program is said to learn from experience EEE with respect to some class of tasks TTT and performance measure PPP, if its performance at tasks in TTT, as measured by PPP, improves with experience EEE.</p><p><br /></p><p>一般地，令 D={x⃗1,x⃗2,⋯,x⃗m}D = \\left \\{ \\vec {x}_1, \\vec {x}_2, \\cdots, \\vec {x}_m \\right \\}D={x1​,x2​,⋯,xm​} 表示包含 mmm 个<code>样本</code>（sample）的数据集，每个示例由 ddd 个<code>属性</code>（attribute）描述，则每个样本 x⃗i={xi1;xi2;⋯;xid}\\vec x_i = \\left \\{x_{i1}; x_{i2}; \\cdots; x_{id} \\right \\}xi​={xi1​;xi2​;⋯;xid​} 是 ddd 维样本空间 X\\mathcal{X}X 中的一个向量，x⃗i∈X\\vec x_i \\in \\mathcal{X}xi​∈X，其中 xijx_{ij}xij​ 是 x⃗i\\vec x_ixi​ 在第 jjj 个属性上的取值，ddd 称为样本 x⃗i\\vec x_ixi​ 的<code>维数</code>（dimensionality）。</p><p><br /></p><p>属性张成的空间称为<code>样本空间</code>（sample space），每个样本都可在这个空间中找到唯一的坐标位置，因此也把一个样本称为一个<code>特征向量</code>（feature vector）。</p><p><br /></p><p>从数据中学得模型的过程称之为<code>学习</code>（learning）或<code>训练</code>（training），学得模型适用于新样本的能力称为<code>泛化</code>（generalization）能力。</p><p><br /></p><a name=\"假设空间\"></a><h3 id=\"d70ed78e\">假设空间</h3><p><br /></p><p><code>归纳</code>（induction）与<code>演绎</code>（deduction）是科学推理的两大基本手段。前者是从特殊到一般的泛化（generalization）过程，后者是从一般到特殊的特化（specialization）过程。从样例中学习是一个归纳的过程，亦称<code>归纳学习</code>（inductive learning）。</p><p><br /></p><p>狭义的归纳学习是从数据中学得<code>概念</code>（concept），最基本的概念学习是布尔概念学习。可以把学习的过程看作一个在所有<code>假设</code>（hypothesis）组成的空间中进行搜索的过程，搜索目标是找到与训练集<code>匹配</code>（fit）的假设。</p><p><br /></p><p>假设的表示一旦确定，<code>假设空间</code>（hypothesis space）及其规模大小就确定了。现实问题中通常面临很大的假设空间，但样本训练集是有限的，因此可能有多个假设与训练集一致，即存在一个与训练集一致的假设集合，称之为<code>版本空间</code>（version space）。</p><p><br /></p><a name=\"归纳偏好\"></a><h3 id=\"b5c5f209\">归纳偏好</h3><p><br /></p><p>机器学习算法在学习过程中对某种类型假设的偏好，称为<code>归纳偏好</code>（inductive bias）。归纳偏好可看作是学习算法在庞大的假设空间中对假设进行选择的价值观。</p><p><br /></p><p><code>奥卡姆剃刀</code>（Occam's Razor）是自然科学研究中常用的原则，即若存在多个假设与观察一致，则选最简单的那个。如无必要，勿增实体。</p><p><br /></p><p>但奥卡姆剃刀原则并不平凡，“简单”的评价标准无法量化。事实上归纳偏好对应了学习算法本身所做出的关于“什么样的模型更好”的假设。<code>没有免费的午餐定理</code>（No Free Lunch Theorem，NFL）证明了在真实目标函数 fff 均匀分布的情况下，所有学习算法学得的模型期望性能是一致的。</p><p><br /></p><p>脱离实际问题，空谈“什么学习算法更好”毫无意义。</p><p><br /></p><a name=\"第-2-章-模型评估与选择\"></a><h2 id=\"07bd81f2\">第 2 章 模型评估与选择</h2><p><br /></p><a name=\"经验误差与过拟合\"></a><h3 id=\"1ac7a372\">经验误差与过拟合</h3><p><br /></p><p>学习器的实际输出与样本的真实输出之间的差异称为<code>误差</code>（error），训练集上的误差称为<code>训练误差</code>（training error），新样本上的误差称为<code>泛化误差</code>（generalization error）。</p><p><br /></p><p>为了使泛化误差最小化，应该从训练样本中尽可能学出适用于所有潜在样本的“普遍规律”。而将训练样本的特点当作了所有潜在样本的一般性质，导致泛化性能下降的现象，称为<code>过拟合</code>（overfitting），相对地没有充分习得训练样本的一般性质的现象，称为<code>欠拟合</code>（underfitting）。</p><p><br /></p><p>现实任务中，存在多种学习算法、不同参数配置，产生不同的模型，需要选择其中合适的模型，该问题称为<code>模型选择</code>（model selection）问题。理想状态下使用泛化误差作为模型选择的评价标准，但泛化误差无法直接获得。</p><p><br /></p><a name=\"评估方法\"></a><h3 id=\"f3787b82\">评估方法</h3><p><br /></p><p>通常使用<code>测试集</code>（testing set）来测试学习器对新样本的判别能力，以测试集上的<code>测试误差</code>（testing error）作为泛化误差的近似。通常假设测试样本是从样本真实分布中独立同分布采样而得。</p><p><br /></p><p>对于包含 mmm 个样本的数据集 D={(x⃗1,y1),(x⃗2,y2),⋯,(x⃗m,ym)}D = \\left \\{ (\\vec x_1, y_1), (\\vec x_2, y_2), \\cdots, (\\vec x_m, y_m) \\right \\}D={(x1​,y1​),(x2​,y2​),⋯,(xm​,ym​)}，需要将其分解为训练集 SSS、验证集 VVV 和测试集 TTT，常用的方法有留出法、交叉验证法和<code>自助法</code>（bootstrapping）。</p><p><br /></p><p>自助法即从数据集中进行 mmm 次可重复采样，可以选出约 36.8% 的样本作为测试集，在数据集较小时较为有效。</p><p><br /></p><p>机器学习常涉及两类参数：一是算法的参数，称为<code>超参数</code>（hyper parameter），一是模型的参数。对超参数进行设定调优的过程称为<code>调参</code>（parameter tuning）。通常使用验证集进行模型选择和调参，使用测试集评估模型的泛化能力。</p><p><br /></p><a name=\"性能度量\"></a><h3 id=\"1a299e7e\">性能度量</h3><p><br /></p><p>性能度量（performance measure），即为模型泛化能力的评价标准。给定数据集 D={(x⃗1,y1),(x⃗2,y2),⋯,(x⃗m,ym)}D = \\left \\{ (\\vec x_1, y_1), (\\vec x_2, y_2), \\cdots, (\\vec x_m, y_m) \\right \\}D={(x1​,y1​),(x2​,y2​),⋯,(xm​,ym​)}，其中 yiy_iyi​ 是样本 x⃗i\\vec x_ixi​ 的真实标记。</p><p><br /></p><p>回归任务常用的性能度量是<code>均方误差</code>（mean squared error）：</p><p><br /></p><p>E(f;D)=∫x⃗∼D(f(x⃗)−y)2p(x⃗)dx⃗ E(f; \\mathcal{D}) = \\int_{\\vec x \\sim \\mathcal D} (f(\\vec x) - y)^2 p(\\vec {x}) d\\vec x E(f;D)=∫x∼D​(f(x)−y)2p(x)dx</p><p><br /></p><p>分类任务常用的性能度量较多，常用的错误率：</p><p><br /></p><p>E(f;D)=∫x⃗∼DI(f(x⃗)≠y)p(x⃗)dx⃗ E(f; \\mathcal{D}) = \\int_{\\vec x \\sim \\mathcal D} \\mathbb I(f(\\vec x) \\neq y) p(\\vec {x}) d\\vec x E(f;D)=∫x∼D​I(f(x)̸​=y)p(x)dx</p><p><br /></p><p><code>准确率</code>（percision）和<code>召回率</code>（recall）：</p><p><br /></p><p>P=TPTP+FPR=TPTP+FN \\begin{aligned} P &amp;= \\frac {TP} {TP + FP} \\\\ R &amp;= \\frac {TP} {TP + FN} \\end{aligned} PR​=TP+FPTP​=TP+FNTP​​</p><p><br /></p><p>预测正例</p><p><br /></p><p>预测负例</p><p><br /></p><p>真实正例</p><p><br /></p><p>TP</p><p><br /></p><p>FN</p><p><br /></p><p>真实负例</p><p><br /></p><p>FP</p><p><br /></p><p>TN</p><p><br /></p><p>准确率和召回率不可得兼。以准确率作为纵轴、召回率作为横轴，可以得到<code>P-R曲线</code>，曲线中“准确率=召回率”的点成为<code>平衡点</code>（Break-Even Point）。</p><p><br /></p><p>准确率和召回率的<code>调和平均</code>（harmonic mean）称为<code>F1</code>度量：</p><p><br /></p><p>1F1=12(1P+1R)F1=2PRP+R \\begin{aligned} \\frac {1} {F1} &amp;= \\frac {1} {2} (\\frac {1} {P} + \\frac {1} {R}) \\\\ F1 &amp;= \\frac {2PR} {P + R} \\end{aligned} F11​F1​=21​(P1​+R1​)=P+R2PR​​</p><p><br /></p><p>由多组混淆矩阵计算多组准确率和召回率，再求平均值，可得<code>宏准确率</code>（macro-P）和<code>宏召回率</code>（macro-R）；将多组混淆矩阵求平均值，再求准确率和召回率，可得<code>微准确率</code>（micro-P）和<code>微召回率</code>（micro-R）。</p><p><br /></p><p><code>ROC</code> 全称受试者工作特征（Receiver Operating Characteristic），该曲线以<code>真正例率</code>（True Positive Rate）为纵轴，以<code>假正例率</code>（False Positive Rate）为横轴：</p><p><br /></p><p>TPR=TPTP+FNFPR=FPTN+FP \\begin{aligned} TPR &amp;= \\frac {TP} {TP + FN} \\\\ FPR &amp; = \\frac {FP} {TN + FP} \\end{aligned} TPRFPR​=TP+FNTP​=TN+FPFP​​</p><p><br /></p><p>ROC 曲线下的面积称为<code>AUC</code>（Area Under ROC Curve），通常使用 AUC 作为ROC 曲线优劣的判断依据。</p><p><br /></p><p>不同类型的错误所造成的后果不同，为权衡不同类型错误所造成的不同损失，可为错误赋予<code>非均等代价</code>（unequal cost）。令 D+D^+D+ 与 D−D^-D− 代表数据集 DDD 中的正例子集和反例子集，则<code>代价敏感</code>（cost-sensitive）错误率为：</p><p><br /></p><p>E(f;D;cost)=1m(∑x⃗i∈D+I(f(x⃗i)≠yi)cost01+∑x⃗i∈D−I(f(x⃗i)≠yi)cost10) E(f; D; cost) = \\frac {1} {m} \\left ( \\sum_{\\vec x_i \\in D^+} \\mathbb I (f(\\vec x_i) \\neq y_i) cost_{01} + \\sum_{\\vec x_i \\in D^-} \\mathbb I (f(\\vec x_i) \\neq y_i) cost_{10} \\right ) E(f;D;cost)=m1​⎝⎛​xi​∈D+∑​I(f(xi​)̸​=yi​)cost01​+xi​∈D−∑​I(f(xi​)̸​=yi​)cost10​⎠⎞​</p><p><br /></p><a name=\"偏差与方差\"></a><h3 id=\"ba51c5c7\">偏差与方差</h3><p><br /></p><p><code>偏差-方差分解</code>（bias-veriance decomposition）是解释学习算法泛化性能的一种重要工具。对测试样本 x⃗\\vec xx，令 yDy_DyD​ 为 x⃗\\vec xx 在数据集中的标记，yyy 为 x⃗\\vec xx 的真实标记，f(x⃗;D)f(\\vec x; D)f(x;D) 为训练集 DDD 上学的模型 fff 在 x⃗\\vec xx 上的预测输出。以回归任务为例，学习算法的期望预测为：</p><p><br /></p><p>fˉ(x⃗)=ED[f(x⃗;D)] \\bar f(\\vec x) = \\mathbb E_D \\left [ f(\\vec x; D) \\right ] fˉ​(x)=ED​[f(x;D)]</p><p><br /></p><p>期望输出与真实标记的差别称为<code>偏差</code>（bias）：</p><p><br /></p><p>bias2(x⃗)=(fˉ(x⃗)−y)2 bias^2(\\vec x) = \\left ( \\bar f(\\vec x) - y \\right )^2 bias2(x)=(fˉ​(x)−y)2</p><p><br /></p><p>使用样本数相同的不同训练集产生的<code>方差</code>（variance）为：</p><p><br /></p><p>var(x⃗)=ED[(f(x⃗;D)−fˉ(x⃗))2] var(\\vec x) = \\mathbb E_D \\left [ \\left (f(\\vec x; D) - \\bar f(\\vec x) \\right )^2 \\right ] var(x)=ED​[(f(x;D)−fˉ​(x))2]</p><p><br /></p><p>噪声为：</p><p><br /></p><p>ε2=ED[(yD−y)2] \\varepsilon ^2 = \\mathbb E_D \\left [ (y_D - y)^2 \\right ] ε2=ED​[(yD​−y)2]</p><p><br /></p><p>假定噪声的期望为零，可得：</p><p><br /></p><p>E(f;D)=bias2(x⃗)+var(x⃗)+ε2 E(f; D) = bias^2(\\vec x) + var(\\vec x) + \\varepsilon ^2 E(f;D)=bias2(x)+var(x)+ε2</p><p><br /></p><p>即泛化误差可以分解为偏差、方差和噪声之和。偏差和方差间存在<code>偏差-方差窘境</code>（bias-variance dilemma），当学习算法训练不足时，学习器的拟合能力不够强，偏差主导了泛化错误率；当训练程度加深后，学习器的拟合能力足够，方差主导了泛化错误率。</p><p><br /></p><a name=\"第-3-章-线性模型\"></a><h2 id=\"761d37e2\">第 3 章 线性模型</h2><p><br /></p><a name=\"基本形式\"></a><h3 id=\"53fae5a5\">基本形式</h3><p><br /></p><p>给定由 ddd 个属性描述的示例 x=(x1;x2;⋯;xd)\\boldsymbol x = (x_1; x_2; \\cdots; x_d)x=(x1​;x2​;⋯;xd​)，其中 xix_ixi​ 是 x\\boldsymbol xx 在第 iii 个属性上的取值，<code>线性模型</code>（linear model）试图学得一个通过属性的线性组合来进行预测的函数：</p><p><br /></p><p>f(x)=wTx+b f(\\boldsymbol x) = \\boldsymbol w^T \\boldsymbol x + b f(x)=wTx+b</p><p><br /></p><p>其中 w=(w1;w2;⋯;wd)\\boldsymbol w = (w_1; w_2; \\cdots; w_d)w=(w1​;w2​;⋯;wd​)。</p><p><br /></p><p>线性模型形式简单，易于建模，且 w\\boldsymbol ww 直观表达了各属性在预测中的重要性，因此线性模型有很好的 <code>可解释性</code>（comprehensibility）。</p><p><br /></p><p>在线性模型的基础上可通过引入层级结构或高维映射而得到更为强大的<code>非线性模型</code>（nonlinear model）。</p><p><br /></p><a name=\"线性回归\"></a><h3 id=\"d8b87768\">线性回归</h3><p><br /></p><p>给定数据集 D={(x1,y1),(x2,y2),⋯,(xm,ym)}D = \\{(\\boldsymbol x_1, y_1), (\\boldsymbol x_2, y_2), \\cdots , (\\boldsymbol x_m, y_m)\\}D={(x1​,y1​),(x2​,y2​),⋯,(xm​,ym​)}，其中 xi=(xi1,xi2,⋯,xid)\\boldsymbol x_i = (x_{i1}, x_{i2}, \\cdots, x_{id})xi​=(xi1​,xi2​,⋯,xid​)，y∈Ry \\in \\mathbb Ry∈R，<code>线性回归</code>（linear regression）试图学得一个线性模型以尽可能准确地预测实际输出标记。</p><p><br /></p><p>考虑最简单的单属性情形，D={(xi,yi)}i=1mD = \\left \\{ (x_i, y_i) \\right \\}_{i=1}^mD={(xi​,yi​)}i=1m​，线性回归试图学得</p><p><br /></p><p>f(xi)=wxi+b f(x_i) = wx_i+b f(xi​)=wxi​+b</p><p><br /></p><p>以使得 f(xi)≃yif(x_i) \\simeq y_if(xi​)≃yi​。使用均方误差作为衡量 f(x)f(x)f(x) 与 yyy 之间差别的性能度量：</p><p><br /></p><p>E(w,b)=∑i=1m(f(xi)−yi)2 E_{(w, b)} = \\sum_{i=1}^{m} {\\left (f(x_i) - y_i \\right )^2} E(w,b)​=i=1∑m​(f(xi​)−yi​)2</p><p><br /></p><p>则：</p><p><br /></p><p>(w∗,b∗)=arg⁡min⁡(w,b)E(w,b) (w^*, b^*) = \\underset {(w, b)} {\\arg \\min} E_{(w, b)} (w∗,b∗)=(w,b)argmin​E(w,b)​</p><p><br /></p><p>均方误差有非常好的几何意义，它对应了 <code>欧氏距离</code>（Euclidean distance）。基于均方误差最小化来进行模型求解的方法称为 <code>最小二乘法</code>（least square method）。在线性回归中，最小二乘法试图找到一条直线，使得所有样本到直线上的欧氏距离之和最小。</p><p><br /></p><p>E(w,b)E_{(w, b)}E(w,b)​ 是关于 www 和 bbb 的凸函数。对于区间 [a,b][a, b][a,b] 上定义的函数 fff，若它区间中任意两点 x1x_1x1​ 和 x2x_2x2​ 均有 f(x1+x22)≤f(x1)+f(x2)2f(\\frac {x_1 + x_2} {2}) \\le \\frac {f(x_1) + f(x_2)} {2}f(2x1​+x2​​)≤2f(x1​)+f(x2​)​，则称 fff 为区间 [a,b][a, b][a,b] 上的凸函数。对实数集上的函数，可以通过求二阶导数的方式来判断，二阶导数在区间上非负则称为凸函数。</p><p><br /></p><p>求解 www 和 bbb 使均方误差最小化的过程，称为线性回归模型的最小二乘 <code>参数估计</code>（parameter estimation）。将 E(w,b)E_{(w, b)}E(w,b)​ 分别对 www 和 bbb 求导，得到：</p><p><br /></p><p>∂E(w,b)∂w=2(w∑i=1mxi2−∑i=1m(yi−b)xi)∂E(w,b)∂b=2(mb−∑i=1m(yi−wxi)) \\begin {aligned} \\frac {\\partial E_{(w, b)}} {\\partial w} &amp;= 2 \\left ( w \\sum_{i=1}^{m} x_i^2 - \\sum_{i=1}^{m} (y_i - b)x_i \\right ) \\\\ \\frac {\\partial E_{(w, b)}} {\\partial b} &amp;= 2 \\left ( mb - \\sum_{i=1}^{m} (y_i - wx_i) \\right ) \\end {aligned} ∂w∂E(w,b)​​∂b∂E(w,b)​​​=2(wi=1∑m​xi2​−i=1∑m​(yi​−b)xi​)=2(mb−i=1∑m​(yi​−wxi​))​</p><p><br /></p><p>对 www 和 bbb 的偏导置零可得到 www 和 bbb 最优解的 <code>闭式解</code>（closed-form solution）：</p><p><br /></p><p>w=∑i=1mxiyi−mxˉyˉ∑i=1mxi2−mxˉ2b=yˉ−wxˉ \\begin {aligned} w &amp;= \\frac {\\sum_{i=1}^{m}x_i y_i - m \\bar x \\bar y} {\\sum_{i=1}^{m} {x_i^2} - m \\bar x^2} \\\\ b &amp;= \\bar y - w \\bar x \\end {aligned} wb​=∑i=1m​xi2​−mxˉ2∑i=1m​xi​yi​−mxˉyˉ​​=yˉ​−wxˉ​</p><p><br /></p><p>更一般的情形，给定数据集 D={(xi,yi)}i=1mD = \\left \\{ (\\boldsymbol x_i, y_i) \\right \\}_{i=1}^mD={(xi​,yi​)}i=1m​，其中 xi=(xi1,xi2,⋯,xid)\\boldsymbol x_i = (x_{i1}, x_{i2}, \\cdots, x_{id})xi​=(xi1​,xi2​,⋯,xid​)，y∈Ry \\in \\mathbb Ry∈R，线性回归试图学得：</p><p><br /></p><p>f(xi)=wTxi+b f(\\boldsymbol x_i) = \\boldsymbol w^T \\boldsymbol x_i+b f(xi​)=wTxi​+b</p><p><br /></p><p>使得 f(xi)≃yif(\\boldsymbol x_i) \\simeq y_if(xi​)≃yi​。这称为 <code>多变量线性回归</code>（multivariate linear regression）。</p><p><br /></p><p>[未完待续]</p><p><br /></p><a name=\"参考文献\"></a><h3 id=\"fb507f2c\">参考文献</h3><p><br /></p><ol start=\"1\"><li>周志华. &quot;机器学习.&quot; 清华大学出版社，北京.</li></ol>",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-04-03T10:31:13.000Z",
    "deleted_at": null,
    "created_at": "2019-04-03T10:31:13.000Z",
    "updated_at": "2019-04-03T10:31:13.000Z",
    "published_at": "2019-04-03T10:31:13.000Z",
    "first_published_at": null,
    "word_count": 3441,
    "cover": null,
    "description": "第 1 章 绪论  基本术语 机器学习：在计算机上从数据（data）中产生模型（model）的算法，即学习算法（learning algorithm）。 A computer program is said to learn from experience EEE with respect t...",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1338753,
    "slug": "iu8cna",
    "title": "事实上",
    "book_id": 188088,
    "book": {
      "id": 188088,
      "type": "Book",
      "slug": "wiki",
      "name": "spin",
      "user_id": 223800,
      "description": "个人知识库",
      "creator_id": 223800,
      "public": 1,
      "items_count": 8,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-11-02T16:00:03.816Z",
      "updated_at": "2019-11-02T16:00:03.000Z",
      "created_at": "2018-12-12T06:42:09.000Z",
      "namespace": "zhiyue/wiki",
      "user": {
        "id": 223800,
        "type": "User",
        "login": "zhiyue",
        "name": "zhiyue",
        "description": null,
        "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
        "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 8,
        "public_books_count": 1,
        "followers_count": 4,
        "following_count": 1,
        "created_at": "2018-12-12T06:39:44.000Z",
        "updated_at": "2019-08-27T06:25:28.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "事实上搜索搜索\n",
    "body_draft": "事实上搜索搜索\n",
    "body_html": "<p>事实上搜索搜索</p>",
    "body_lake": "<!doctype lake><p>事实上搜索搜索<cursor /></p>",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-03-07T08:09:15.000Z",
    "deleted_at": null,
    "created_at": "2019-03-07T08:08:49.000Z",
    "updated_at": "2019-05-28T03:27:09.000Z",
    "published_at": "2019-03-07T08:09:15.000Z",
    "first_published_at": "2019-03-07T08:09:15.000Z",
    "word_count": 7,
    "cover": null,
    "description": "事实上搜索搜索",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1112593,
    "slug": "diep91",
    "title": "无标题",
    "book_id": 188088,
    "book": {
      "id": 188088,
      "type": "Book",
      "slug": "wiki",
      "name": "spin",
      "user_id": 223800,
      "description": "个人知识库",
      "creator_id": 223800,
      "public": 1,
      "items_count": 8,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-11-02T16:15:25.239Z",
      "updated_at": "2019-11-02T16:15:25.000Z",
      "created_at": "2018-12-12T06:42:09.000Z",
      "namespace": "zhiyue/wiki",
      "user": {
        "id": 223800,
        "type": "User",
        "login": "zhiyue",
        "name": "zhiyue",
        "description": null,
        "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
        "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 8,
        "public_books_count": 1,
        "followers_count": 4,
        "following_count": 1,
        "created_at": "2018-12-12T06:39:44.000Z",
        "updated_at": "2019-08-27T06:25:28.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "\n",
    "body_draft": "\n",
    "body_html": "<!doctype html><div class=\"lake-content-editor-core lake-engine\" data-lake-element=\"root\" data-selection-223800=\"%7B%22path%22%3A%5B%5B0%2C1%5D%2C%5B0%2C1%5D%5D%2C%22uuid%22%3A%22223800%22%2C%22active%22%3Atrue%7D\"><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p></div>",
    "body_lake": "<!doctype lake><meta name=\"doc-version\" content=\"1\" /><p><br /></p>",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-11-02T16:15:25.000Z",
    "deleted_at": null,
    "created_at": "2019-01-04T08:04:35.000Z",
    "updated_at": "2019-11-02T16:15:25.000Z",
    "published_at": "2019-11-02T16:15:25.000Z",
    "first_published_at": "2019-01-04T08:08:45.000Z",
    "word_count": 0,
    "cover": null,
    "description": "",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1089606,
    "slug": "wgmy6r",
    "title": "Deep Learning重要发展脉络",
    "book_id": 188088,
    "book": {
      "id": 188088,
      "type": "Book",
      "slug": "wiki",
      "name": "spin",
      "user_id": 223800,
      "description": "个人知识库",
      "creator_id": 223800,
      "public": 1,
      "items_count": 8,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-11-02T16:00:03.816Z",
      "updated_at": "2019-11-02T16:00:03.000Z",
      "created_at": "2018-12-12T06:42:09.000Z",
      "namespace": "zhiyue/wiki",
      "user": {
        "id": 223800,
        "type": "User",
        "login": "zhiyue",
        "name": "zhiyue",
        "description": null,
        "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
        "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 8,
        "public_books_count": 1,
        "followers_count": 4,
        "following_count": 1,
        "created_at": "2018-12-12T06:39:44.000Z",
        "updated_at": "2019-08-27T06:25:28.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "Deep Learning（深度学习）的概念源于人工神经网络的研究，它的概念由Hinton等人于2006年提出，但它的模型经历了怎样的发展和演化，本文将为您深度解读Deep Learning的前世今生。<br />![](https://static.aminer.cn/rcd/article/expertpic/aminer.gif#align=left&display=inline&height=1205&originHeight=1205&originWidth=1694&search=&status=done&width=1694)<br />\n<a name=\"tfacwu\"></a>\n### 脉络一  cv/tensor\n\n1943年  心理学家麦卡洛可（W·McCulloch）和数理逻辑学家皮茨（W·Pitts）参考了生物神经元的结构，发表了《神经活动中思想内在性的逻辑运算》一文，提出了抽象的神经元模型MP，该模型可以看做深度学习的雏形。\n\n1957年  认知心理学大师 Frank Rosenblatt 发明了感知机（Perceptron，又称感知器），感知机是当时首个可以学习的人工神经网络，掀起了一股学习的热潮。\n\n1969年  人工智能大师 Marvin Minksy 和 Seymour Papert 在《Perceptron》一书中，用详细的数学证明了感知机的弱点，没有隐层的简单感知机在许多像XOR问题的情形下显得无能为力，并证明了简单感知机只能解决线性分类问题和一阶谓诃同题。神经网络研究进入冰河期。\n\n1984年  日本学者福岛邦彦（Kunihiko Fukishima）提出了卷积神经网络的原始模型神经感知机（Neocognitron），产生了卷积和池化的思想（当时不叫卷积和池化）。\n\n1986年  Hinton等人正式提出一般 Delta 法则，即反向传播（BP）算法，并用反向传播训练MLP（多层感知机）。但其实在他提出之前，已经有人将其付诸实际。（1985年 Parter 也独立地得出过相似的算法，他称之为学习逻辑。此外，1985年 Lecun 也研究出大致相似的学习法则。）\n\n1998年  以 Yann LeCun 为首的研究人员实现了一个5层的卷积神经网络——LeNet-5，以识别手写数字。LeNet-5 标志着 CNN（卷积神经网络）的真正面世，LeNet-5 的提出把 CNN 推上了一个小高潮。\n\n之后SVM（支持向量机）兴起，SVM在计算及准确度上都有较大的优势，导致卷积神经网络的方法在后来的一段时间并未能火起来。\n\n2012年  Hinton组的 AlexNet 在 ImageNet 上以巨大优势夺冠，掀起了深度学习的热潮。AlexNet 可以算是 LeNet 的一种更深更宽的版本，并加上了 relu、dropout 等技巧。\n\n这条思路被后人发展，出现了 VGG，GoogLeNet 等网络。\n\n2016年  青年计算机视觉科学家何恺明在层次之间加入了跳跃连接，Resnet 极大增加了网络深度，效果有很大提升。另一个将这条思路继续发展下去的是去年cvpr best paper densenet。\n\n除此之外，cv领域的特定任务还出现了各种各样的模型（Mask-RCNN等），这里不一一介绍。\n\n2017年  Hinton认为反省传播和传统神经网络有缺陷，继而提出了 Capsule Net。但是目前在 cifar 等数据集上效果一般，这个思路还需要继续验证和发展。\n\n<a name=\"orhvmd\"></a>\n### 脉络二  生成模型\n\n传统的生成模型是要预测联合概率分布P(x,y)。\n\nRBM（受限玻尔兹曼机）这个模型其实是一个基于能量的模型，1986年的时候就有，2006年将其重新拿出来作为一个生成模型，并且堆叠成为deep belief network，使用逐层贪婪或者wake-sleep的方法训练，不过这个模型效果一般，现在已经没什么人提了。但是Hinton等人却从此开始使用深度学习重新包装神经网络。\n\nAuto-Encoder是上个世纪80年代hinton提出的模型，如今由于计算能力的进步重新登上舞台。2008年，Bengio等人又搞了denoise Auto-Encoder。\n\nMax welling等人使用神经网络训练一个有一层隐变量的图模型，由于使用了变分推断，最后长得跟auto-encoder有点像，因而被称为Variational auto-encoder。此模型可以通过隐变量的分布采样，经过后面的decoder网络直接生成样本。\n\nGAN（生成对抗网络）是于2014年提出的模型，如今炙手可热。它是一个生成模型，通过判别器D（Discriminator）和生成器G（Generator）的对抗训练，直接使用神经网络G隐式建模样本整体的概率分布。每次运行便相当于从分布中采样。\n\nDCGAN是一个相当好的卷积神经网络实现，而WGAN则是通过维尔斯特拉斯距离替换原来的JS散度来度量分布之间的相似性的工作，使得训练稳定。PGGAN则逐层增大网络，生成机器逼真的人脸。\n\n<a name=\"rkublv\"></a>\n### 脉络三 sequencelearning\n\n1982年  出现的hopfield network有了递归网络的思想。\n\n1997年  Jürgen Schmidhuber发明LSTM，并做了一系列的工作。但是更有影响力的还是2013年由Hinton组使用RNN做的语音识别工作，这种方法比传统方法更强。\n\n文本方面，Bengio在svm最火的时期提出了一种基于神经网络的语言模型，后来Google提出的word2vec也包含了一些反向传播的思想。在机器翻译等任务上，逐渐出现了以RNN为基础的seq2seq模型（序列模型），模型通过一个encoder（编码器）把一句话的语义信息压成向量再通过decoder（解码器）输出，当然更多的还要和Attention Model（注意力模型）结合。\n\n后来，大家发现使用以字符为单位的CNN模型在很多语言任务也有不俗的表现，而且时空消耗更少。LSTM/RNN 模型中的Attention机制是用于克服传统编码器-解码器结构存在的问题的。其中，self-attention（自注意力机制）实际上就是采取一种结构去同时考虑同一序列局部和全局的信息，Google就有一篇耸人听闻的Attention Is All You Need的文章。\n\n<a name=\"65uhmf\"></a>\n### 脉络四 deepreinforcement learning\n\n该领域最出名的是DeepMind，这里列出的David Silver则是一直研究rl（强化学习）的高管。\n\nq-learning是很有名的传统rl算法，deep q-learning则是将原来的q值表用神经网络代替。利用deep q-learning制作的打砖块的游戏十分有名。后来David Silver等人又利用其测试了许多游戏，发在了Nature上。\n\n增强学习在double duel的进展，主要是Qlearning的权重更新时序上。\n\nDeepMind的其他工作诸如DDPG、A3C也非常有名，它们是基于policy gradient和神经网络结合的变种。\n\n大家都知道的一个应用是AlphaGo，里面不仅使用了rl的方法，也包含了传统的蒙特卡洛搜索技巧。Alpha Zero 则是他们搞了一个用Alphago框架来打其他棋类游戏的游戏，而且这个“打”还是吊打的打。\n\n\n",
    "body_draft": "Deep Learning（深度学习）的概念源于人工神经网络的研究，它的概念由Hinton等人于2006年提出，但它的模型经历了怎样的发展和演化，本文将为您深度解读Deep Learning的前世今生。<br />![](https://static.aminer.cn/rcd/article/expertpic/aminer.gif#align=left&display=inline&height=1205&originHeight=1205&originWidth=1694&search=&status=done&width=1694)<br />\n<a name=\"tfacwu\"></a>\n### 脉络一  cv/tensor\n\n1943年  心理学家麦卡洛可（W·McCulloch）和数理逻辑学家皮茨（W·Pitts）参考了生物神经元的结构，发表了《神经活动中思想内在性的逻辑运算》一文，提出了抽象的神经元模型MP，该模型可以看做深度学习的雏形。\n\n1957年  认知心理学大师 Frank Rosenblatt 发明了感知机（Perceptron，又称感知器），感知机是当时首个可以学习的人工神经网络，掀起了一股学习的热潮。\n\n1969年  人工智能大师 Marvin Minksy 和 Seymour Papert 在《Perceptron》一书中，用详细的数学证明了感知机的弱点，没有隐层的简单感知机在许多像XOR问题的情形下显得无能为力，并证明了简单感知机只能解决线性分类问题和一阶谓诃同题。神经网络研究进入冰河期。\n\n1984年  日本学者福岛邦彦（Kunihiko Fukishima）提出了卷积神经网络的原始模型神经感知机（Neocognitron），产生了卷积和池化的思想（当时不叫卷积和池化）。\n\n1986年  Hinton等人正式提出一般 Delta 法则，即反向传播（BP）算法，并用反向传播训练MLP（多层感知机）。但其实在他提出之前，已经有人将其付诸实际。（1985年 Parter 也独立地得出过相似的算法，他称之为学习逻辑。此外，1985年 Lecun 也研究出大致相似的学习法则。）\n\n1998年  以 Yann LeCun 为首的研究人员实现了一个5层的卷积神经网络——LeNet-5，以识别手写数字。LeNet-5 标志着 CNN（卷积神经网络）的真正面世，LeNet-5 的提出把 CNN 推上了一个小高潮。\n\n之后SVM（支持向量机）兴起，SVM在计算及准确度上都有较大的优势，导致卷积神经网络的方法在后来的一段时间并未能火起来。\n\n2012年  Hinton组的 AlexNet 在 ImageNet 上以巨大优势夺冠，掀起了深度学习的热潮。AlexNet 可以算是 LeNet 的一种更深更宽的版本，并加上了 relu、dropout 等技巧。\n\n这条思路被后人发展，出现了 VGG，GoogLeNet 等网络。\n\n2016年  青年计算机视觉科学家何恺明在层次之间加入了跳跃连接，Resnet 极大增加了网络深度，效果有很大提升。另一个将这条思路继续发展下去的是去年cvpr best paper densenet。\n\n除此之外，cv领域的特定任务还出现了各种各样的模型（Mask-RCNN等），这里不一一介绍。\n\n2017年  Hinton认为反省传播和传统神经网络有缺陷，继而提出了 Capsule Net。但是目前在 cifar 等数据集上效果一般，这个思路还需要继续验证和发展。\n\n<a name=\"orhvmd\"></a>\n### 脉络二  生成模型\n\n传统的生成模型是要预测联合概率分布P(x,y)。\n\nRBM（受限玻尔兹曼机）这个模型其实是一个基于能量的模型，1986年的时候就有，2006年将其重新拿出来作为一个生成模型，并且堆叠成为deep belief network，使用逐层贪婪或者wake-sleep的方法训练，不过这个模型效果一般，现在已经没什么人提了。但是Hinton等人却从此开始使用深度学习重新包装神经网络。\n\nAuto-Encoder是上个世纪80年代hinton提出的模型，如今由于计算能力的进步重新登上舞台。2008年，Bengio等人又搞了denoise Auto-Encoder。\n\nMax welling等人使用神经网络训练一个有一层隐变量的图模型，由于使用了变分推断，最后长得跟auto-encoder有点像，因而被称为Variational auto-encoder。此模型可以通过隐变量的分布采样，经过后面的decoder网络直接生成样本。\n\nGAN（生成对抗网络）是于2014年提出的模型，如今炙手可热。它是一个生成模型，通过判别器D（Discriminator）和生成器G（Generator）的对抗训练，直接使用神经网络G隐式建模样本整体的概率分布。每次运行便相当于从分布中采样。\n\nDCGAN是一个相当好的卷积神经网络实现，而WGAN则是通过维尔斯特拉斯距离替换原来的JS散度来度量分布之间的相似性的工作，使得训练稳定。PGGAN则逐层增大网络，生成机器逼真的人脸。\n\n<a name=\"rkublv\"></a>\n### 脉络三 sequencelearning\n\n1982年  出现的hopfield network有了递归网络的思想。\n\n1997年  Jürgen Schmidhuber发明LSTM，并做了一系列的工作。但是更有影响力的还是2013年由Hinton组使用RNN做的语音识别工作，这种方法比传统方法更强。\n\n文本方面，Bengio在svm最火的时期提出了一种基于神经网络的语言模型，后来Google提出的word2vec也包含了一些反向传播的思想。在机器翻译等任务上，逐渐出现了以RNN为基础的seq2seq模型（序列模型），模型通过一个encoder（编码器）把一句话的语义信息压成向量再通过decoder（解码器）输出，当然更多的还要和Attention Model（注意力模型）结合。\n\n后来，大家发现使用以字符为单位的CNN模型在很多语言任务也有不俗的表现，而且时空消耗更少。LSTM/RNN 模型中的Attention机制是用于克服传统编码器-解码器结构存在的问题的。其中，self-attention（自注意力机制）实际上就是采取一种结构去同时考虑同一序列局部和全局的信息，Google就有一篇耸人听闻的Attention Is All You Need的文章。\n\n<a name=\"65uhmf\"></a>\n### 脉络四 deepreinforcement learning\n\n该领域最出名的是DeepMind，这里列出的David Silver则是一直研究rl（强化学习）的高管。\n\nq-learning是很有名的传统rl算法，deep q-learning则是将原来的q值表用神经网络代替。利用deep q-learning制作的打砖块的游戏十分有名。后来David Silver等人又利用其测试了许多游戏，发在了Nature上。\n\n增强学习在double duel的进展，主要是Qlearning的权重更新时序上。\n\nDeepMind的其他工作诸如DDPG、A3C也非常有名，它们是基于policy gradient和神经网络结合的变种。\n\n大家都知道的一个应用是AlphaGo，里面不仅使用了rl的方法，也包含了传统的蒙特卡洛搜索技巧。Alpha Zero 则是他们搞了一个用Alphago框架来打其他棋类游戏的游戏，而且这个“打”还是吊打的打。\n\n\n",
    "body_html": "<!doctype html><div class=\"lake-content-editor-core lake-engine\" data-lake-element=\"root\"><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\">Deep Learning（深度学习）的概念源于人工神经网络的研究，它的概念由Hinton等人于2006年提出，但它的模型经历了怎样的发展和演化，本文将为您深度解读Deep Learning的前世今生。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><span data-card-type=\"inline\" data-lake-card=\"image\"><img data-role=\"image\" src=\"https://static.aminer.cn/rcd/article/expertpic/aminer.gif\" data-raw-src=\"https://static.aminer.cn/rcd/article/expertpic/aminer.gif\" class=\"image lake-drag-image\" style=\"visibility: visible; width: 746px; height: 531px;\"></span><br></p><h3 id=\"tfacwu\" style=\"padding: 7px 0px; margin: 0px; font-weight: 700; font-size: 20px; line-height: 28px;\">脉络一&nbsp;&nbsp;cv/tensor</h3><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><span style=\"color: #286C91;\">1943年</span>&nbsp;&nbsp;心理学家麦卡洛可（W·McCulloch）和数理逻辑学家皮茨（W·Pitts）参考了生物神经元的结构，发表了《神经活动中思想内在性的逻辑运算》一文，提出了抽象的神经元模型MP，该模型可以看做深度学习的雏形。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><span style=\"color: #286C91;\">1957年</span>&nbsp;&nbsp;认知心理学大师 Frank Rosenblatt 发明了感知机（Perceptron，又称感知器），感知机是当时首个可以学习的人工神经网络，掀起了一股学习的热潮。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><span style=\"color: #286C91;\">1969年</span>&nbsp;&nbsp;人工智能大师 Marvin Minksy 和 Seymour Papert 在《Perceptron》一书中，用详细的数学证明了感知机的弱点，没有隐层的简单感知机在许多像XOR问题的情形下显得无能为力，并证明了简单感知机只能解决线性分类问题和一阶谓诃同题。神经网络研究进入冰河期。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><span style=\"color: #286C91;\">1984年</span>&nbsp;&nbsp;日本学者福岛邦彦（Kunihiko Fukishima）提出了卷积神经网络的原始模型神经感知机（Neocognitron），产生了卷积和池化的思想（当时不叫卷积和池化）。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><span style=\"color: #286C91;\">1986年</span>&nbsp;&nbsp;Hinton等人正式提出一般 Delta 法则，即反向传播（BP）算法，并用反向传播训练MLP（多层感知机）。但其实在他提出之前，已经有人将其付诸实际。（1985年 Parter 也独立地得出过相似的算法，他称之为学习逻辑。此外，1985年 Lecun 也研究出大致相似的学习法则。）</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><span style=\"color: #286C91;\">1998年</span>&nbsp;&nbsp;以 Yann LeCun 为首的研究人员实现了一个5层的卷积神经网络——LeNet-5，以识别手写数字。LeNet-5 标志着 CNN（卷积神经网络）的真正面世，LeNet-5 的提出把 CNN 推上了一个小高潮。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\">之后SVM（支持向量机）兴起，SVM在计算及准确度上都有较大的优势，导致卷积神经网络的方法在后来的一段时间并未能火起来。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><span style=\"color: #286C91;\">2012年</span>&nbsp;&nbsp;Hinton组的 AlexNet 在 ImageNet 上以巨大优势夺冠，掀起了深度学习的热潮。AlexNet 可以算是 LeNet 的一种更深更宽的版本，并加上了 relu、dropout 等技巧。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\">这条思路被后人发展，出现了 VGG，GoogLeNet 等网络。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><span style=\"color: #286C91;\">2016年</span>&nbsp;&nbsp;青年计算机视觉科学家何恺明在层次之间加入了跳跃连接，Resnet 极大增加了网络深度，效果有很大提升。另一个将这条思路继续发展下去的是去年cvpr best paper densenet。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\">除此之外，cv领域的特定任务还出现了各种各样的模型（Mask-RCNN等），这里不一一介绍。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><span style=\"color: #286C91;\">2017年</span>&nbsp;&nbsp;Hinton认为反省传播和传统神经网络有缺陷，继而提出了 Capsule Net。但是目前在 cifar 等数据集上效果一般，这个思路还需要继续验证和发展。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><h3 id=\"orhvmd\" style=\"padding: 7px 0px; margin: 0px; font-weight: 700; font-size: 20px; line-height: 28px;\">脉络二&nbsp;&nbsp;生成模型</h3><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\">传统的生成模型是要预测联合概率分布P(x,y)。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\">RBM（受限玻尔兹曼机）这个模型其实是一个基于能量的模型，1986年的时候就有，2006年将其重新拿出来作为一个生成模型，并且堆叠成为deep belief network，使用逐层贪婪或者wake-sleep的方法训练，不过这个模型效果一般，现在已经没什么人提了。但是Hinton等人却从此开始使用深度学习重新包装神经网络。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\">Auto-Encoder是上个世纪80年代hinton提出的模型，如今由于计算能力的进步重新登上舞台。2008年，Bengio等人又搞了denoise Auto-Encoder。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\">Max welling等人使用神经网络训练一个有一层隐变量的图模型，由于使用了变分推断，最后长得跟auto-encoder有点像，因而被称为Variational auto-encoder。此模型可以通过隐变量的分布采样，经过后面的decoder网络直接生成样本。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\">GAN（生成对抗网络）是于2014年提出的模型，如今炙手可热。它是一个生成模型，通过判别器D（Discriminator）和生成器G（Generator）的对抗训练，直接使用神经网络G隐式建模样本整体的概率分布。每次运行便相当于从分布中采样。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\">DCGAN是一个相当好的卷积神经网络实现，而WGAN则是通过维尔斯特拉斯距离替换原来的JS散度来度量分布之间的相似性的工作，使得训练稳定。PGGAN则逐层增大网络，生成机器逼真的人脸。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><h3 id=\"rkublv\" style=\"padding: 7px 0px; margin: 0px; font-weight: 700; font-size: 20px; line-height: 28px;\">脉络三 sequencelearning</h3><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><span style=\"color: #286C91;\">1982年</span>&nbsp;&nbsp;出现的hopfield network有了递归网络的思想。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><span style=\"color: #286C91;\">1997年</span>&nbsp;&nbsp;Jürgen Schmidhuber发明LSTM，并做了一系列的工作。但是更有影响力的还是2013年由Hinton组使用RNN做的语音识别工作，这种方法比传统方法更强。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\">文本方面，Bengio在svm最火的时期提出了一种基于神经网络的语言模型，后来Google提出的word2vec也包含了一些反向传播的思想。在机器翻译等任务上，逐渐出现了以RNN为基础的seq2seq模型（序列模型），模型通过一个encoder（编码器）把一句话的语义信息压成向量再通过decoder（解码器）输出，当然更多的还要和Attention Model（注意力模型）结合。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\">后来，大家发现使用以字符为单位的CNN模型在很多语言任务也有不俗的表现，而且时空消耗更少。LSTM/RNN 模型中的Attention机制是用于克服传统编码器-解码器结构存在的问题的。其中，self-attention（自注意力机制）实际上就是采取一种结构去同时考虑同一序列局部和全局的信息，Google就有一篇耸人听闻的Attention Is All You Need的文章。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><h3 id=\"65uhmf\" style=\"padding: 7px 0px; margin: 0px; font-weight: 700; font-size: 20px; line-height: 28px;\">脉络四 deepreinforcement learning</h3><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\">该领域最出名的是DeepMind，这里列出的David Silver则是一直研究rl（强化学习）的高管。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\">q-learning是很有名的传统rl算法，deep q-learning则是将原来的q值表用神经网络代替。利用deep q-learning制作的打砖块的游戏十分有名。后来David Silver等人又利用其测试了许多游戏，发在了Nature上。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\">增强学习在double duel的进展，主要是Qlearning的权重更新时序上。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\">DeepMind的其他工作诸如DDPG、A3C也非常有名，它们是基于policy gradient和神经网络结合的变种。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\">大家都知道的一个应用是AlphaGo，里面不仅使用了rl的方法，也包含了传统的蒙特卡洛搜索技巧。Alpha Zero 则是他们搞了一个用Alphago框架来打其他棋类游戏的游戏，而且这个“打”还是吊打的打。</p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p></div>",
    "body_lake": "<!doctype lake><meta name=\"doc-version\" content=\"1\" /><p>Deep Learning（深度学习）的概念源于人工神经网络的研究，它的概念由Hinton等人于2006年提出，但它的模型经历了怎样的发展和演化，本文将为您深度解读Deep Learning的前世今生。</p><p><card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22https%3A%2F%2Fstatic.aminer.cn%2Frcd%2Farticle%2Fexpertpic%2Faminer.gif%22%2C%22originWidth%22%3A1694%2C%22originHeight%22%3A1205%2C%22display%22%3A%22inline%22%2C%22align%22%3A%22left%22%2C%22linkTarget%22%3A%22_blank%22%2C%22status%22%3A%22done%22%2C%22search%22%3A%22%22%2C%22width%22%3A1694%2C%22height%22%3A1205%7D\"></card><br /></p><h3 id=\"tfacwu\">脉络一  cv/tensor</h3><p><br /></p><p><span style=\"color: #286C91;\">1943年</span>  心理学家麦卡洛可（W·McCulloch）和数理逻辑学家皮茨（W·Pitts）参考了生物神经元的结构，发表了《神经活动中思想内在性的逻辑运算》一文，提出了抽象的神经元模型MP，该模型可以看做深度学习的雏形。</p><p><br /></p><p><span style=\"color: #286C91;\">1957年</span>  认知心理学大师 Frank Rosenblatt 发明了感知机（Perceptron，又称感知器），感知机是当时首个可以学习的人工神经网络，掀起了一股学习的热潮。</p><p><br /></p><p><span style=\"color: #286C91;\">1969年</span>  人工智能大师 Marvin Minksy 和 Seymour Papert 在《Perceptron》一书中，用详细的数学证明了感知机的弱点，没有隐层的简单感知机在许多像XOR问题的情形下显得无能为力，并证明了简单感知机只能解决线性分类问题和一阶谓诃同题。神经网络研究进入冰河期。</p><p><br /></p><p><span style=\"color: #286C91;\">1984年</span>  日本学者福岛邦彦（Kunihiko Fukishima）提出了卷积神经网络的原始模型神经感知机（Neocognitron），产生了卷积和池化的思想（当时不叫卷积和池化）。</p><p><br /></p><p><span style=\"color: #286C91;\">1986年</span>  Hinton等人正式提出一般 Delta 法则，即反向传播（BP）算法，并用反向传播训练MLP（多层感知机）。但其实在他提出之前，已经有人将其付诸实际。（1985年 Parter 也独立地得出过相似的算法，他称之为学习逻辑。此外，1985年 Lecun 也研究出大致相似的学习法则。）</p><p><br /></p><p><span style=\"color: #286C91;\">1998年</span>  以 Yann LeCun 为首的研究人员实现了一个5层的卷积神经网络——LeNet-5，以识别手写数字。LeNet-5 标志着 CNN（卷积神经网络）的真正面世，LeNet-5 的提出把 CNN 推上了一个小高潮。</p><p><br /></p><p>之后SVM（支持向量机）兴起，SVM在计算及准确度上都有较大的优势，导致卷积神经网络的方法在后来的一段时间并未能火起来。</p><p><br /></p><p><span style=\"color: #286C91;\">2012年</span>  Hinton组的 AlexNet 在 ImageNet 上以巨大优势夺冠，掀起了深度学习的热潮。AlexNet 可以算是 LeNet 的一种更深更宽的版本，并加上了 relu、dropout 等技巧。</p><p><br /></p><p>这条思路被后人发展，出现了 VGG，GoogLeNet 等网络。</p><p><br /></p><p><span style=\"color: #286C91;\">2016年</span>  青年计算机视觉科学家何恺明在层次之间加入了跳跃连接，Resnet 极大增加了网络深度，效果有很大提升。另一个将这条思路继续发展下去的是去年cvpr best paper densenet。</p><p><br /></p><p>除此之外，cv领域的特定任务还出现了各种各样的模型（Mask-RCNN等），这里不一一介绍。</p><p><br /></p><p><span style=\"color: #286C91;\">2017年</span>  Hinton认为反省传播和传统神经网络有缺陷，继而提出了 Capsule Net。但是目前在 cifar 等数据集上效果一般，这个思路还需要继续验证和发展。</p><p><br /></p><h3 id=\"orhvmd\">脉络二  生成模型</h3><p><br /></p><p>传统的生成模型是要预测联合概率分布P(x,y)。</p><p><br /></p><p>RBM（受限玻尔兹曼机）这个模型其实是一个基于能量的模型，1986年的时候就有，2006年将其重新拿出来作为一个生成模型，并且堆叠成为deep belief network，使用逐层贪婪或者wake-sleep的方法训练，不过这个模型效果一般，现在已经没什么人提了。但是Hinton等人却从此开始使用深度学习重新包装神经网络。</p><p><br /></p><p>Auto-Encoder是上个世纪80年代hinton提出的模型，如今由于计算能力的进步重新登上舞台。2008年，Bengio等人又搞了denoise Auto-Encoder。</p><p><br /></p><p>Max welling等人使用神经网络训练一个有一层隐变量的图模型，由于使用了变分推断，最后长得跟auto-encoder有点像，因而被称为Variational auto-encoder。此模型可以通过隐变量的分布采样，经过后面的decoder网络直接生成样本。</p><p><br /></p><p>GAN（生成对抗网络）是于2014年提出的模型，如今炙手可热。它是一个生成模型，通过判别器D（Discriminator）和生成器G（Generator）的对抗训练，直接使用神经网络G隐式建模样本整体的概率分布。每次运行便相当于从分布中采样。</p><p><br /></p><p>DCGAN是一个相当好的卷积神经网络实现，而WGAN则是通过维尔斯特拉斯距离替换原来的JS散度来度量分布之间的相似性的工作，使得训练稳定。PGGAN则逐层增大网络，生成机器逼真的人脸。</p><p><br /></p><h3 id=\"rkublv\">脉络三 sequencelearning</h3><p><br /></p><p><span style=\"color: #286C91;\">1982年</span>  出现的hopfield network有了递归网络的思想。</p><p><br /></p><p><span style=\"color: #286C91;\">1997年</span>  Jürgen Schmidhuber发明LSTM，并做了一系列的工作。但是更有影响力的还是2013年由Hinton组使用RNN做的语音识别工作，这种方法比传统方法更强。</p><p><br /></p><p>文本方面，Bengio在svm最火的时期提出了一种基于神经网络的语言模型，后来Google提出的word2vec也包含了一些反向传播的思想。在机器翻译等任务上，逐渐出现了以RNN为基础的seq2seq模型（序列模型），模型通过一个encoder（编码器）把一句话的语义信息压成向量再通过decoder（解码器）输出，当然更多的还要和Attention Model（注意力模型）结合。</p><p><br /></p><p>后来，大家发现使用以字符为单位的CNN模型在很多语言任务也有不俗的表现，而且时空消耗更少。LSTM/RNN 模型中的Attention机制是用于克服传统编码器-解码器结构存在的问题的。其中，self-attention（自注意力机制）实际上就是采取一种结构去同时考虑同一序列局部和全局的信息，Google就有一篇耸人听闻的Attention Is All You Need的文章。</p><p><br /></p><h3 id=\"65uhmf\">脉络四 deepreinforcement learning</h3><p><br /></p><p>该领域最出名的是DeepMind，这里列出的David Silver则是一直研究rl（强化学习）的高管。</p><p><br /></p><p>q-learning是很有名的传统rl算法，deep q-learning则是将原来的q值表用神经网络代替。利用deep q-learning制作的打砖块的游戏十分有名。后来David Silver等人又利用其测试了许多游戏，发在了Nature上。</p><p><br /></p><p>增强学习在double duel的进展，主要是Qlearning的权重更新时序上。</p><p><br /></p><p>DeepMind的其他工作诸如DDPG、A3C也非常有名，它们是基于policy gradient和神经网络结合的变种。</p><p><br /></p><p>大家都知道的一个应用是AlphaGo，里面不仅使用了rl的方法，也包含了传统的蒙特卡洛搜索技巧。Alpha Zero 则是他们搞了一个用Alphago框架来打其他棋类游戏的游戏，而且这个“打”还是吊打的打。</p><p><br /></p><p><br /></p>",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-11-02T16:00:03.000Z",
    "deleted_at": null,
    "created_at": "2018-12-26T14:32:12.000Z",
    "updated_at": "2019-11-02T16:00:03.000Z",
    "published_at": "2019-11-02T16:00:03.000Z",
    "first_published_at": "2018-12-26T14:32:42.000Z",
    "word_count": 1796,
    "cover": null,
    "description": "Deep Learning（深度学习）的概念源于人工神经网络的研究，它的概念由Hinton等人于2006年提出，但它的模型经历了怎样的发展和演化，本文将为您深度解读Deep Learning的前世今生。脉络一  cv/tensor1943年  心理学家麦卡洛可（W·McCulloch）和数理逻...",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1060887,
    "slug": "fr35nn",
    "title": "Elasticsearch 知识点索引",
    "book_id": 188088,
    "book": {
      "id": 188088,
      "type": "Book",
      "slug": "wiki",
      "name": "spin",
      "user_id": 223800,
      "description": "个人知识库",
      "creator_id": 223800,
      "public": 1,
      "items_count": 7,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-11-02T16:22:25.687Z",
      "updated_at": "2019-11-02T16:22:25.000Z",
      "created_at": "2018-12-12T06:42:09.000Z",
      "namespace": "zhiyue/wiki",
      "user": {
        "id": 223800,
        "type": "User",
        "login": "zhiyue",
        "name": "zhiyue",
        "description": null,
        "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
        "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 8,
        "public_books_count": 1,
        "followers_count": 4,
        "following_count": 1,
        "created_at": "2018-12-12T06:39:44.000Z",
        "updated_at": "2019-08-27T06:25:28.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "<a name=\"9ykeeh\"></a>\n# quick start\n\n<a name=\"qrpeom\"></a>\n## install\n\n\n\n",
    "body_draft": "<a name=\"9ykeeh\"></a>\n# quick start\n\n<a name=\"qrpeom\"></a>\n## install\n\n\n\n",
    "body_html": "<!doctype html><div class=\"lake-content-editor-core lake-engine\" data-lake-element=\"root\"><h1 id=\"9ykeeh\" style=\"padding: 7px 0px; margin: 0px; font-weight: 700; font-size: 28px; line-height: 36px;\">quick start</h1><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><h2 id=\"qrpeom\" style=\"padding: 7px 0px; margin: 0px; font-weight: 700; font-size: 24px; line-height: 32px;\">install</h2><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><br></p></div>",
    "body_lake": "<!doctype lake><meta name=\"doc-version\" content=\"1\" /><h1 id=\"9ykeeh\">quick start</h1><p><br /></p><h2 id=\"qrpeom\">install</h2><p><br /></p><p><br /></p><p><br /></p>",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-11-02T16:21:41.000Z",
    "deleted_at": null,
    "created_at": "2018-12-17T09:28:38.000Z",
    "updated_at": "2019-11-02T16:21:41.000Z",
    "published_at": "2019-11-02T16:21:41.000Z",
    "first_published_at": "2019-11-02T16:21:36.000Z",
    "word_count": 3,
    "cover": null,
    "description": "quick startinstall",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1050971,
    "slug": "qaam8p",
    "title": "测试图片",
    "book_id": 188088,
    "book": {
      "id": 188088,
      "type": "Book",
      "slug": "wiki",
      "name": "spin",
      "user_id": 223800,
      "description": "个人知识库",
      "creator_id": 223800,
      "public": 1,
      "items_count": 7,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-11-02T16:23:22.843Z",
      "updated_at": "2019-11-02T16:23:22.000Z",
      "created_at": "2018-12-12T06:42:09.000Z",
      "namespace": "zhiyue/wiki",
      "user": {
        "id": 223800,
        "type": "User",
        "login": "zhiyue",
        "name": "zhiyue",
        "description": null,
        "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
        "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 8,
        "public_books_count": 1,
        "followers_count": 4,
        "following_count": 1,
        "created_at": "2018-12-12T06:39:44.000Z",
        "updated_at": "2019-08-27T06:25:28.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "![images (3).png](https://cdn.nlark.com/yuque/0/2019/png/223800/1572711795535-706c0409-f726-4627-9d0a-e3d799d7fd00.png#align=left&display=inline&height=225&name=images%20%283%29.png&originHeight=225&originWidth=225&search=&size=1636&status=done&width=225)\n",
    "body_draft": "![images (3).png](https://cdn.nlark.com/yuque/0/2019/png/223800/1572711795535-706c0409-f726-4627-9d0a-e3d799d7fd00.png#align=left&display=inline&height=225&name=images%20%283%29.png&originHeight=225&originWidth=225&search=&size=1636&status=done&width=225)\n",
    "body_html": "<!doctype html><div class=\"lake-content-editor-core lake-engine\" data-lake-element=\"root\" data-selection-223800=\"%7B%22path%22%3A%5B%5D%2C%22uuid%22%3A%22223800%22%2C%22active%22%3Atrue%7D\"><p style=\"font-size: 14px; color: rgb(38, 38, 38); line-height: 24px; letter-spacing: 0.05em; outline-style: none; overflow-wrap: break-word; margin: 0px;\"><span data-card-type=\"inline\" data-lake-card=\"image\"><img data-role=\"image\" src=\"https://cdn.nlark.com/yuque/0/2019/png/223800/1572711795535-706c0409-f726-4627-9d0a-e3d799d7fd00.png\" data-raw-src=\"https://cdn.nlark.com/yuque/0/2019/png/223800/1572711795535-706c0409-f726-4627-9d0a-e3d799d7fd00.png\" class=\"image lake-drag-image\" alt=\"images (3).png\" title=\"images (3).png\" style=\"visibility: visible; width: 225px; height: 225px;\"></span></p></div>",
    "body_lake": "<!doctype lake><meta name=\"doc-version\" content=\"1\" /><p><card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22https%3A%2F%2Fcdn.nlark.com%2Fyuque%2F0%2F2019%2Fpng%2F223800%2F1572711795535-706c0409-f726-4627-9d0a-e3d799d7fd00.png%22%2C%22originWidth%22%3A225%2C%22originHeight%22%3A225%2C%22name%22%3A%22images%20(3).png%22%2C%22size%22%3A1636%2C%22display%22%3A%22inline%22%2C%22align%22%3A%22left%22%2C%22linkTarget%22%3A%22_blank%22%2C%22status%22%3A%22done%22%2C%22search%22%3A%22%22%2C%22width%22%3A225%2C%22height%22%3A225%7D\"></card></p>",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-11-02T16:23:22.000Z",
    "deleted_at": null,
    "created_at": "2018-12-13T06:22:01.000Z",
    "updated_at": "2019-11-02T16:23:22.000Z",
    "published_at": "2019-11-02T16:23:22.000Z",
    "first_published_at": "2019-11-02T16:22:25.000Z",
    "word_count": 0,
    "cover": null,
    "description": "",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1048167,
    "slug": "clk6ym",
    "title": "测试文档",
    "book_id": 188088,
    "book": {
      "id": 188088,
      "type": "Book",
      "slug": "wiki",
      "name": "spin",
      "user_id": 223800,
      "description": "个人知识库",
      "creator_id": 223800,
      "public": 1,
      "items_count": 8,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-11-02T16:00:03.816Z",
      "updated_at": "2019-11-02T16:00:03.000Z",
      "created_at": "2018-12-12T06:42:09.000Z",
      "namespace": "zhiyue/wiki",
      "user": {
        "id": 223800,
        "type": "User",
        "login": "zhiyue",
        "name": "zhiyue",
        "description": null,
        "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
        "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 8,
        "public_books_count": 1,
        "followers_count": 4,
        "following_count": 1,
        "created_at": "2018-12-12T06:39:44.000Z",
        "updated_at": "2019-08-27T06:25:28.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "\n",
    "body_draft": "\n",
    "body_html": "<p><br /></p>",
    "body_lake": "<!doctype lake><p><br /></p>",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2018-12-12T06:43:52.000Z",
    "deleted_at": null,
    "created_at": "2018-12-12T06:43:12.000Z",
    "updated_at": "2019-07-02T09:45:43.000Z",
    "published_at": "2018-12-12T06:43:52.000Z",
    "first_published_at": null,
    "word_count": 0,
    "cover": null,
    "description": "",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 2175933,
    "slug": "bm4t6d",
    "title": "如何学习数据科学",
    "book_id": 213751,
    "book": {
      "id": 213751,
      "type": "Book",
      "slug": "how_to_x",
      "name": "如何做 X",
      "user_id": 223868,
      "description": "如何去完成或学习 X",
      "creator_id": 223800,
      "public": 0,
      "items_count": 14,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-07-22T16:15:06.546Z",
      "updated_at": "2019-07-22T16:15:06.000Z",
      "created_at": "2019-01-31T09:48:04.000Z",
      "namespace": "p_z/how_to_x",
      "user": {
        "id": 223868,
        "type": "Group",
        "login": "p_z",
        "name": "知曰",
        "description": "知曰",
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png",
        "large_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 13,
        "public_books_count": 1,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2018-12-12T07:39:16.000Z",
        "updated_at": "2019-08-27T06:23:10.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 228368,
    "creator": {
      "id": 228368,
      "type": "User",
      "login": "pennzys",
      "name": "pennzys",
      "description": null,
      "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
      "large_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 3,
      "public_books_count": 0,
      "followers_count": 0,
      "following_count": 0,
      "created_at": "2018-12-20T11:27:55.000Z",
      "updated_at": "2019-09-03T13:55:42.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "\n",
    "body_draft": "\n",
    "body_html": "<p><br /></p>",
    "body_lake": "<!doctype lake><p><br /><cursor /></p>",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-07-22T16:08:35.000Z",
    "deleted_at": null,
    "created_at": "2019-07-22T16:08:11.000Z",
    "updated_at": "2019-07-22T16:08:35.000Z",
    "published_at": "2019-07-22T16:08:35.000Z",
    "first_published_at": "2019-07-22T16:08:35.000Z",
    "word_count": 0,
    "cover": null,
    "description": "",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 2175930,
    "slug": "wpfkbg",
    "title": "如何学习 pandas",
    "book_id": 213751,
    "book": {
      "id": 213751,
      "type": "Book",
      "slug": "how_to_x",
      "name": "如何做 X",
      "user_id": 223868,
      "description": "如何去完成或学习 X",
      "creator_id": 223800,
      "public": 0,
      "items_count": 14,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-07-22T16:15:06.546Z",
      "updated_at": "2019-07-22T16:15:06.000Z",
      "created_at": "2019-01-31T09:48:04.000Z",
      "namespace": "p_z/how_to_x",
      "user": {
        "id": 223868,
        "type": "Group",
        "login": "p_z",
        "name": "知曰",
        "description": "知曰",
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png",
        "large_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 13,
        "public_books_count": 1,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2018-12-12T07:39:16.000Z",
        "updated_at": "2019-08-27T06:23:10.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 228368,
    "creator": {
      "id": 228368,
      "type": "User",
      "login": "pennzys",
      "name": "pennzys",
      "description": null,
      "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png",
      "large_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/wYnHWSXDmBhiEmuwXsym.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 3,
      "public_books_count": 0,
      "followers_count": 0,
      "following_count": 0,
      "created_at": "2018-12-20T11:27:55.000Z",
      "updated_at": "2019-09-03T13:55:42.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "<a name=\"eDcbx\"></a>\n## 相关参考资料\nhello pandas [https://www.kaggle.com/colinmorris/hello-python](https://www.kaggle.com/colinmorris/hello-python)<br />pandas cards [https://assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf](https://assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf)<br />[https://www.kaggle.com/residentmario/creating-reading-and-writing](https://www.kaggle.com/residentmario/creating-reading-and-writing)<br />[https://www.kaggle.com/jabari/exercise-explore-your-data/edit](https://www.kaggle.com/jabari/exercise-explore-your-data/edit)<br />[https://www.kaggle.com/dansbecker/basic-data-exploration](https://www.kaggle.com/dansbecker/basic-data-exploration)<br />[https://wiki.python.org/moin/BeginnersGuide/NonProgrammers](https://wiki.python.org/moin/BeginnersGuide/NonProgrammers)\n<a name=\"770Sw\"></a>\n## 相关练习\n    titanic [https://www.kaggle.com/c/titanic](https://www.kaggle.com/c/titanic)\n",
    "body_draft": "<a name=\"eDcbx\"></a>\n## 相关参考资料\nhello pandas [https://www.kaggle.com/colinmorris/hello-python](https://www.kaggle.com/colinmorris/hello-python)<br />pandas cards [https://assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf](https://assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf)<br />[https://www.kaggle.com/residentmario/creating-reading-and-writing](https://www.kaggle.com/residentmario/creating-reading-and-writing)<br />[https://www.kaggle.com/jabari/exercise-explore-your-data/edit](https://www.kaggle.com/jabari/exercise-explore-your-data/edit)<br />[https://www.kaggle.com/dansbecker/basic-data-exploration](https://www.kaggle.com/dansbecker/basic-data-exploration)<br />[https://wiki.python.org/moin/BeginnersGuide/NonProgrammers](https://wiki.python.org/moin/BeginnersGuide/NonProgrammers)\n<a name=\"770Sw\"></a>\n## 相关练习\n    titanic [https://www.kaggle.com/c/titanic](https://www.kaggle.com/c/titanic)\n",
    "body_html": "<h2 id=\"eDcbx\">相关参考资料</h2><p style=\"text-indent: 2em;\">hello pandas <a href=\"https://www.kaggle.com/colinmorris/hello-python\" target=\"_blank\">https://www.kaggle.com/colinmorris/hello-python</a></p><p style=\"text-indent: 2em;\">pandas cards <a href=\"https://assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf\" target=\"_blank\">https://assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf</a></p><p style=\"text-indent: 2em;\"><a href=\"https://www.kaggle.com/residentmario/creating-reading-and-writing\" target=\"_blank\">https://www.kaggle.com/residentmario/creating-reading-and-writing</a></p><p style=\"text-indent: 2em;\"><a href=\"https://www.kaggle.com/jabari/exercise-explore-your-data/edit\" target=\"_blank\">https://www.kaggle.com/jabari/exercise-explore-your-data/edit</a></p><p style=\"text-indent: 2em;\"><a href=\"https://www.kaggle.com/dansbecker/basic-data-exploration\" target=\"_blank\">https://www.kaggle.com/dansbecker/basic-data-exploration</a></p><p style=\"text-indent: 2em;\"><a href=\"https://wiki.python.org/moin/BeginnersGuide/NonProgrammers\" target=\"_blank\">https://wiki.python.org/moin/BeginnersGuide/NonProgrammers</a></p><h2 id=\"770Sw\">相关练习</h2><p>    titanic <a href=\"https://www.kaggle.com/c/titanic\" target=\"_blank\">https://www.kaggle.com/c/titanic</a></p>",
    "body_lake": "<!doctype lake><h2 id=\"eDcbx\">相关参考资料</h2><p style=\"text-indent: 2em;\">hello pandas <a href=\"https://www.kaggle.com/colinmorris/hello-python\" target=\"_blank\">https://www.kaggle.com/colinmorris/hello-python</a></p><p style=\"text-indent: 2em;\">pandas cards <a href=\"https://assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf\" target=\"_blank\">https://assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf</a></p><p style=\"text-indent: 2em;\"><a href=\"https://www.kaggle.com/residentmario/creating-reading-and-writing\" target=\"_blank\">https://www.kaggle.com/residentmario/creating-reading-and-writing</a></p><p style=\"text-indent: 2em;\"><a href=\"https://www.kaggle.com/jabari/exercise-explore-your-data/edit\" target=\"_blank\">https://www.kaggle.com/jabari/exercise-explore-your-data/edit</a></p><p style=\"text-indent: 2em;\"><a href=\"https://www.kaggle.com/dansbecker/basic-data-exploration\" target=\"_blank\">https://www.kaggle.com/dansbecker/basic-data-exploration</a></p><p style=\"text-indent: 2em;\"><a href=\"https://wiki.python.org/moin/BeginnersGuide/NonProgrammers\" target=\"_blank\">https://wiki.python.org/moin/BeginnersGuide/NonProgrammers</a></p><h2 id=\"770Sw\">相关练习</h2><p>    titanic <a href=\"https://www.kaggle.com/c/titanic\" target=\"_blank\">https://www.kaggle.com/c/titanic<cursor /></a></p>",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-07-22T16:15:06.000Z",
    "deleted_at": null,
    "created_at": "2019-07-22T16:07:44.000Z",
    "updated_at": "2019-07-22T16:15:06.000Z",
    "published_at": "2019-07-22T16:15:06.000Z",
    "first_published_at": "2019-07-22T16:08:04.000Z",
    "word_count": 70,
    "cover": null,
    "description": "相关参考资料hello pandas https://www.kaggle.com/colinmorris/hello-pythonpandas cards https://assets.datacamp.com/blog_assets/PandasPythonForDataScience.p...",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1430341,
    "slug": "rqrman",
    "title": "大学课程",
    "book_id": 213751,
    "book": {
      "id": 213751,
      "type": "Book",
      "slug": "how_to_x",
      "name": "如何做 X",
      "user_id": 223868,
      "description": "如何去完成或学习 X",
      "creator_id": 223800,
      "public": 0,
      "items_count": 14,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-07-22T16:15:06.546Z",
      "updated_at": "2019-07-22T16:15:06.000Z",
      "created_at": "2019-01-31T09:48:04.000Z",
      "namespace": "p_z/how_to_x",
      "user": {
        "id": 223868,
        "type": "Group",
        "login": "p_z",
        "name": "知曰",
        "description": "知曰",
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png",
        "large_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 13,
        "public_books_count": 1,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2018-12-12T07:39:16.000Z",
        "updated_at": "2019-08-27T06:23:10.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "<a name=\"5563b44c\"></a>\n## 北京大学\n\n\n",
    "body_draft": "<a name=\"5563b44c\"></a>\n## 北京大学\n\n\n",
    "body_html": "<h2 id=\"5563b44c\">北京大学</h2><p></p><p><br /></p>",
    "body_lake": "<!doctype lake><h2 id=\"5563b44c\">北京大学</h2><p><card type=\"inline\" name=\"file\" value=\"data:%7B%22src%22%3A%22%22%2C%22name%22%3A%22libpku-master.zip%22%2C%22size%22%3A576742740%2C%22type%22%3A%22application%2Fzip%22%2C%22progress%22%3A%7B%22percent%22%3A0%7D%2C%22status%22%3A%22error%22%2C%22percent%22%3A0%2C%22message%22%3A%22%E6%96%87%E4%BB%B6%E8%BF%87%E5%A4%A7%EF%BC%8C%E8%A6%81%E6%B1%82%E4%B8%8D%E8%83%BD%E8%B6%85%E8%BF%87%20500M%22%7D\"></card></p><p><cursor /><br /></p>",
    "public": 1,
    "status": 0,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-03-26T10:59:28.000Z",
    "deleted_at": null,
    "created_at": "2019-03-26T10:54:36.000Z",
    "updated_at": "2019-05-31T06:29:25.000Z",
    "published_at": "2019-03-26T10:58:12.000Z",
    "first_published_at": "2019-03-26T10:58:12.000Z",
    "word_count": 4,
    "cover": null,
    "description": "北京大学",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1216208,
    "slug": "krghbm",
    "title": "如何运营微信公众号",
    "book_id": 213751,
    "book": {
      "id": 213751,
      "type": "Book",
      "slug": "how_to_x",
      "name": "如何做 X",
      "user_id": 223868,
      "description": "如何去完成或学习 X",
      "creator_id": 223800,
      "public": 0,
      "items_count": 14,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-07-22T16:15:06.546Z",
      "updated_at": "2019-07-22T16:15:06.000Z",
      "created_at": "2019-01-31T09:48:04.000Z",
      "namespace": "p_z/how_to_x",
      "user": {
        "id": 223868,
        "type": "Group",
        "login": "p_z",
        "name": "知曰",
        "description": "知曰",
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png",
        "large_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 13,
        "public_books_count": 1,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2018-12-12T07:39:16.000Z",
        "updated_at": "2019-08-27T06:23:10.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "",
    "body_draft": "",
    "body_html": null,
    "body_lake": "",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-01-31T10:17:48.000Z",
    "deleted_at": null,
    "created_at": "2019-01-31T10:17:48.000Z",
    "updated_at": "2019-05-31T06:29:25.000Z",
    "published_at": "2019-01-31T10:18:10.000Z",
    "first_published_at": "2019-01-31T10:18:10.000Z",
    "word_count": 0,
    "cover": null,
    "description": "",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1216204,
    "slug": "nm86pl",
    "title": "如何养一只动物",
    "book_id": 213751,
    "book": {
      "id": 213751,
      "type": "Book",
      "slug": "how_to_x",
      "name": "如何做 X",
      "user_id": 223868,
      "description": "如何去完成或学习 X",
      "creator_id": 223800,
      "public": 0,
      "items_count": 14,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-07-22T16:15:06.546Z",
      "updated_at": "2019-07-22T16:15:06.000Z",
      "created_at": "2019-01-31T09:48:04.000Z",
      "namespace": "p_z/how_to_x",
      "user": {
        "id": 223868,
        "type": "Group",
        "login": "p_z",
        "name": "知曰",
        "description": "知曰",
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png",
        "large_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 13,
        "public_books_count": 1,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2018-12-12T07:39:16.000Z",
        "updated_at": "2019-08-27T06:23:10.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "",
    "body_draft": "",
    "body_html": null,
    "body_lake": "",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-01-31T10:17:17.000Z",
    "deleted_at": null,
    "created_at": "2019-01-31T10:17:17.000Z",
    "updated_at": "2019-05-31T06:29:48.000Z",
    "published_at": "2019-01-31T10:17:38.000Z",
    "first_published_at": "2019-01-31T10:17:38.000Z",
    "word_count": 0,
    "cover": null,
    "description": "",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1216191,
    "slug": "gbvygo",
    "title": "如何理财和投资",
    "book_id": 213751,
    "book": {
      "id": 213751,
      "type": "Book",
      "slug": "how_to_x",
      "name": "如何做 X",
      "user_id": 223868,
      "description": "如何去完成或学习 X",
      "creator_id": 223800,
      "public": 0,
      "items_count": 14,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-07-22T16:15:06.546Z",
      "updated_at": "2019-07-22T16:15:06.000Z",
      "created_at": "2019-01-31T09:48:04.000Z",
      "namespace": "p_z/how_to_x",
      "user": {
        "id": 223868,
        "type": "Group",
        "login": "p_z",
        "name": "知曰",
        "description": "知曰",
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png",
        "large_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 13,
        "public_books_count": 1,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2018-12-12T07:39:16.000Z",
        "updated_at": "2019-08-27T06:23:10.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "",
    "body_draft": "",
    "body_html": null,
    "body_lake": "",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-01-31T10:15:54.000Z",
    "deleted_at": null,
    "created_at": "2019-01-31T10:15:54.000Z",
    "updated_at": "2019-05-31T06:29:25.000Z",
    "published_at": "2019-01-31T10:16:16.000Z",
    "first_published_at": "2019-01-31T10:16:16.000Z",
    "word_count": 0,
    "cover": null,
    "description": "",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1216187,
    "slug": "gku0f9",
    "title": "如何学一门外语",
    "book_id": 213751,
    "book": {
      "id": 213751,
      "type": "Book",
      "slug": "how_to_x",
      "name": "如何做 X",
      "user_id": 223868,
      "description": "如何去完成或学习 X",
      "creator_id": 223800,
      "public": 0,
      "items_count": 14,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-07-22T16:15:06.546Z",
      "updated_at": "2019-07-22T16:15:06.000Z",
      "created_at": "2019-01-31T09:48:04.000Z",
      "namespace": "p_z/how_to_x",
      "user": {
        "id": 223868,
        "type": "Group",
        "login": "p_z",
        "name": "知曰",
        "description": "知曰",
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png",
        "large_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 13,
        "public_books_count": 1,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2018-12-12T07:39:16.000Z",
        "updated_at": "2019-08-27T06:23:10.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "",
    "body_draft": "",
    "body_html": null,
    "body_lake": "",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-01-31T10:15:29.000Z",
    "deleted_at": null,
    "created_at": "2019-01-31T10:15:29.000Z",
    "updated_at": "2019-05-31T06:29:48.000Z",
    "published_at": "2019-01-31T10:15:48.000Z",
    "first_published_at": "2019-01-31T10:15:48.000Z",
    "word_count": 0,
    "cover": null,
    "description": "",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1216184,
    "slug": "ny05pw",
    "title": "如何学日语",
    "book_id": 213751,
    "book": {
      "id": 213751,
      "type": "Book",
      "slug": "how_to_x",
      "name": "如何做 X",
      "user_id": 223868,
      "description": "如何去完成或学习 X",
      "creator_id": 223800,
      "public": 0,
      "items_count": 14,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-07-22T16:15:06.546Z",
      "updated_at": "2019-07-22T16:15:06.000Z",
      "created_at": "2019-01-31T09:48:04.000Z",
      "namespace": "p_z/how_to_x",
      "user": {
        "id": 223868,
        "type": "Group",
        "login": "p_z",
        "name": "知曰",
        "description": "知曰",
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png",
        "large_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 13,
        "public_books_count": 1,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2018-12-12T07:39:16.000Z",
        "updated_at": "2019-08-27T06:23:10.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "",
    "body_draft": "",
    "body_html": null,
    "body_lake": "",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-01-31T10:15:08.000Z",
    "deleted_at": null,
    "created_at": "2019-01-31T10:15:08.000Z",
    "updated_at": "2019-05-31T06:29:25.000Z",
    "published_at": "2019-01-31T10:15:21.000Z",
    "first_published_at": "2019-01-31T10:15:21.000Z",
    "word_count": 0,
    "cover": null,
    "description": "",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1216179,
    "slug": "bmvmfu",
    "title": "如何学英语",
    "book_id": 213751,
    "book": {
      "id": 213751,
      "type": "Book",
      "slug": "how_to_x",
      "name": "如何做 X",
      "user_id": 223868,
      "description": "如何去完成或学习 X",
      "creator_id": 223800,
      "public": 0,
      "items_count": 14,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-07-22T16:15:06.546Z",
      "updated_at": "2019-07-22T16:15:06.000Z",
      "created_at": "2019-01-31T09:48:04.000Z",
      "namespace": "p_z/how_to_x",
      "user": {
        "id": 223868,
        "type": "Group",
        "login": "p_z",
        "name": "知曰",
        "description": "知曰",
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png",
        "large_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 13,
        "public_books_count": 1,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2018-12-12T07:39:16.000Z",
        "updated_at": "2019-08-27T06:23:10.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "",
    "body_draft": "",
    "body_html": null,
    "body_lake": "",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-01-31T10:14:50.000Z",
    "deleted_at": null,
    "created_at": "2019-01-31T10:14:50.000Z",
    "updated_at": "2019-05-31T06:29:25.000Z",
    "published_at": "2019-01-31T10:15:03.000Z",
    "first_published_at": "2019-01-31T10:15:03.000Z",
    "word_count": 0,
    "cover": null,
    "description": "",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1216170,
    "slug": "gl3g6h",
    "title": "如何养好一只柴犬",
    "book_id": 213751,
    "book": {
      "id": 213751,
      "type": "Book",
      "slug": "how_to_x",
      "name": "如何做 X",
      "user_id": 223868,
      "description": "如何去完成或学习 X",
      "creator_id": 223800,
      "public": 0,
      "items_count": 14,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-07-22T16:15:06.546Z",
      "updated_at": "2019-07-22T16:15:06.000Z",
      "created_at": "2019-01-31T09:48:04.000Z",
      "namespace": "p_z/how_to_x",
      "user": {
        "id": 223868,
        "type": "Group",
        "login": "p_z",
        "name": "知曰",
        "description": "知曰",
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png",
        "large_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 13,
        "public_books_count": 1,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2018-12-12T07:39:16.000Z",
        "updated_at": "2019-08-27T06:23:10.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "",
    "body_draft": "",
    "body_html": null,
    "body_lake": "",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-01-31T10:13:36.000Z",
    "deleted_at": null,
    "created_at": "2019-01-31T10:13:36.000Z",
    "updated_at": "2019-05-31T06:29:48.000Z",
    "published_at": "2019-01-31T10:14:36.000Z",
    "first_published_at": "2019-01-31T10:14:21.000Z",
    "word_count": 0,
    "cover": null,
    "description": "",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1216165,
    "slug": "oykldp",
    "title": "如何养猫",
    "book_id": 213751,
    "book": {
      "id": 213751,
      "type": "Book",
      "slug": "how_to_x",
      "name": "如何做 X",
      "user_id": 223868,
      "description": "如何去完成或学习 X",
      "creator_id": 223800,
      "public": 0,
      "items_count": 14,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-07-22T16:15:06.546Z",
      "updated_at": "2019-07-22T16:15:06.000Z",
      "created_at": "2019-01-31T09:48:04.000Z",
      "namespace": "p_z/how_to_x",
      "user": {
        "id": 223868,
        "type": "Group",
        "login": "p_z",
        "name": "知曰",
        "description": "知曰",
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png",
        "large_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 13,
        "public_books_count": 1,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2018-12-12T07:39:16.000Z",
        "updated_at": "2019-08-27T06:23:10.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "",
    "body_draft": "",
    "body_html": null,
    "body_lake": "",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-01-31T10:13:08.000Z",
    "deleted_at": null,
    "created_at": "2019-01-31T10:13:08.000Z",
    "updated_at": "2019-05-31T06:29:25.000Z",
    "published_at": "2019-01-31T10:13:25.000Z",
    "first_published_at": "2019-01-31T10:13:25.000Z",
    "word_count": 0,
    "cover": null,
    "description": "",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1216161,
    "slug": "vm31y5",
    "title": "如何养狗",
    "book_id": 213751,
    "book": {
      "id": 213751,
      "type": "Book",
      "slug": "how_to_x",
      "name": "如何做 X",
      "user_id": 223868,
      "description": "如何去完成或学习 X",
      "creator_id": 223800,
      "public": 0,
      "items_count": 14,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-07-22T16:15:06.546Z",
      "updated_at": "2019-07-22T16:15:06.000Z",
      "created_at": "2019-01-31T09:48:04.000Z",
      "namespace": "p_z/how_to_x",
      "user": {
        "id": 223868,
        "type": "Group",
        "login": "p_z",
        "name": "知曰",
        "description": "知曰",
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png",
        "large_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 13,
        "public_books_count": 1,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2018-12-12T07:39:16.000Z",
        "updated_at": "2019-08-27T06:23:10.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "",
    "body_draft": "",
    "body_html": null,
    "body_lake": "",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-01-31T10:12:42.000Z",
    "deleted_at": null,
    "created_at": "2019-01-31T10:12:42.000Z",
    "updated_at": "2019-05-31T06:29:25.000Z",
    "published_at": "2019-01-31T10:13:02.000Z",
    "first_published_at": "2019-01-31T10:13:02.000Z",
    "word_count": 0,
    "cover": null,
    "description": "",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1216087,
    "slug": "nve8pc",
    "title": "如何科学减肥",
    "book_id": 213751,
    "book": {
      "id": 213751,
      "type": "Book",
      "slug": "how_to_x",
      "name": "如何做 X",
      "user_id": 223868,
      "description": "如何去完成或学习 X",
      "creator_id": 223800,
      "public": 0,
      "items_count": 14,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-07-22T16:15:06.546Z",
      "updated_at": "2019-07-22T16:15:06.000Z",
      "created_at": "2019-01-31T09:48:04.000Z",
      "namespace": "p_z/how_to_x",
      "user": {
        "id": 223868,
        "type": "Group",
        "login": "p_z",
        "name": "知曰",
        "description": "知曰",
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png",
        "large_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 13,
        "public_books_count": 1,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2018-12-12T07:39:16.000Z",
        "updated_at": "2019-08-27T06:23:10.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "\n<a name=\"9699a50e\"></a>\n### 关键词\n\n- 书单\n- app\n- 营养学\n- 低碳饮食\n- 生酮饮食\n- paper\n- 阿特金斯减肥法\n- 计划\n- 表格\n- 体脂称\n- 手环\n<a name=\"d41d8cd9\"></a>\n### \n<a name=\"b59c9e0f\"></a>\n### 概念\n\n- 基础代谢\n- 低碳水饮食\n- 燃脂心率\n- BMI 指数\n- 生酮饮食(keto)\n- HIIT\n  - Tabata\n> Tabata 是 HIIT 高强度间歇性的一种，它的训练方式和 HIIT 有些区别，但减脂原理以及优点和 HIIT 都是类似的。\n\n\n<a name=\"fef9d212\"></a>\n## 肥胖的危害\n![](https://cdn.nlark.com/yuque/0/2019/jpeg/223800/1549541591417-d6dd7785-cdbb-4f09-b3ae-58d4f5b1bf0c.jpeg#align=left&display=inline&height=386&originHeight=328&originWidth=550&size=0&width=648)\n<a name=\"e9d1af34\"></a>\n## 减肥方法\n<a name=\"44ebfb82\"></a>\n### 饮食\n<a name=\"445ddd1a\"></a>\n#### 生酮饮食\n\n- [治疗癫痫病的生酮饮食，你想用来减肥？](http://songshuhui.net/archives/101982)\n> 生酮饮食是限制碳水化合物、大量摄入脂肪的食谱，典型的生酮食谱中脂肪供能比高达70%-80%，蛋白质约为10%-20%，而碳水化合物只占5%-10%\n> 人体的生理活动需要热量，正常情况下由碳水化合物来提供。光是大脑活动所需要的热量，每天就需要120克葡萄糖。当人体处于饥饿或者碳水化合物缺乏的状态，就会消耗肝糖元以及暂时分解肌肉来供能。这样的状态持续三四天，糖元消失殆尽，血液中的胰岛素水平大大降低，肝脏就会开始把脂肪分解为酮体来供能。\n> 身体本来是按照葡萄糖供能来运行的，在生酮饮食下改用酮体来供能。就像一台汽油发动机，变成了用酒精做燃料。这种改变，会改变身体的整个代谢状态。\n\n**优点**：\n\n  - 短期的生酮饮食对于减轻体重以及改善某些生理指标有一定帮助\n    - 体重的降低\n    - 体脂率、胰岛素水平、血压、腰臀比等指标也有所改善 \n\n**缺点：**\n> 当血液中的酮体含量过高，人体会出于酮血症的状态。在这种状态下，肾会排出酮体和体液，从而导致人体失水，体重迅速减轻。或许，这就是有的人采用生酮饮食能迅速减重的原因。\n\n  - 其他健康的减肥方式相比，生酮饮食就没有什么优势\n  - 生酮饮食的营养组成相当不合理。\n> 许多维生素、矿物质以及膳食纤维等营养成分都伴随着碳水化合物而来。长期坚持生酮饮食，营养的失衡对健康会有什么样的影响，也还没有充分的研究\n\n  - 人体可能会出现许多不适，比如饥饿、疲劳、情绪低落、便秘、头痛等等\n  - 较长时间的生酮饮食会大大增加肾结石、骨质疏松和高尿酸的风险\n\n总结:\n> 从实验结果来看，短期的生酮饮食对于减轻体重以及改善某些生理指标有一定帮助。不过，如果跟其他健康的减肥方式相比，生酮饮食就没有什么优势。而生酮饮食早已明确的副作用，就已经不可忽视。此外，生酮饮食的营养组成相当不合理。许多维生素、矿物质以及膳食纤维等营养成分都伴随着碳水化合物而来。长期坚持生酮饮食，营养的失衡对健康会有什么样的影响，也还没有充分的研究。\n> 当然，如果作为一种医疗手段，生酮饮食还是值得研究和关注的。在某些疾病的治疗中，经过医生的评估，并且在医院的密切监护下进行生酮饮食，也是可以采取的方案。至于日常生活中用它来减肥，还是算了吧。\n\n简单来说**生酮饮食**最初就是作为一种医疗手段，例如糖尿病、癫痫，生酮饮食还被用于许多跟神经有关的疾病上，比如阿茨海默症、自闭症、脑癌、帕金森氏病等等，有一定的效果，不过综合权衡效果与证据强度，并没有达到临床推荐的层次。而且副作用明显，便秘和肾结石\n<a name=\"d41d8cd9\"></a>\n#### \n<a name=\"0d74ba8c\"></a>\n#### 阿特金斯减肥法\n<a name=\"6b17f352\"></a>\n#### 低碳水饮食\n<a name=\"37b6debe\"></a>\n### 运动\n<a name=\"8558e728\"></a>\n#### 长时间持续性有氧\n> 运动强度超过30分钟的中低强度有氧，如慢跑，游泳，长途骑行等。是一直以来没毛病的传统型有氧。\n\n不低于30分钟不高于70分钟为最佳。\n\n  - 慢跑\n  - 游泳\n  - 长途骑行\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/223800/1549541856051-0fd9ec25-c919-4b06-bd75-e991e3564695.png#align=left&display=inline&height=707&name=image.png&originHeight=508&originWidth=440&size=300058&width=612)<br />卡氏公式:<br />        燃脂心率 =（220-年龄-静态心率）x 30%-45%+静态心率\n\n<br /><a name=\"95a7e4d0\"></a>\n#### 间歇性有氧运动（HIIT）\n> HIIT，简单讲就是一种高强度与低强度交替间歇的训练方式。只要在运动中是强度高低交替的，都可以视作广义的HIIT，比如快慢交替跑，快慢交替骑车等等。\n\n优点：\n\n- 即运动后仍然能保持高热量、高脂肪的消耗效率。其训练后减脂效果可以持续72小时左右。并且其高强度的动作还可以起到保护肌肉维持代谢的作用\n\n缺点：\n\n- 强度高\n<a name=\"d41d8cd9\"></a>\n### \n<a name=\"0debf521\"></a>\n### 计划\n\n- 食谱\n- 运动\n  - 慢跑\n> 跑完步记得补充水份，牛奶比矿泉水更补水，还能补充蛋白质和电解质修复你的身体损耗。\n> 吃一根富含钾的香蕉也不错。\n\n<a name=\"1c7fa641\"></a>\n#### 注意事项：\n\n- 减肥也不能吃得低于自己的基础代谢\n<a name=\"5b208a57\"></a>\n## 参考:\n\n- 知乎\n  - [禁食「碳水化合物」正确吗？「阿特金斯减肥法」有效安全吗？ - 《科学世界》杂志的回答 - 知乎 ](https://www.zhihu.com/question/20234124/answer/352356794)\n  - [哥本哈根食谱真的有那么神奇吗？](https://www.zhihu.com/question/23586456/answer/151934876)\n  - [减肥谣言大混战|低碳水or低脂肪，谁在瞎说|生酮减肥](https://zhuanlan.zhihu.com/p/36154483)\n  - [脂肪是如何被消耗的？](https://zhuanlan.zhihu.com/p/36020258)\n  - [tabata 4分钟真的有效果吗？](https://www.zhihu.com/question/28248712)\n- 丁香园\n  - [(丁香园)生酮饮食：减重效果如何？又有什么风险？](http://endo.dxy.cn/article/560367)[备用链接](https://web.archive.org/web/20190207075150/http://endo.dxy.cn/article/560367) #生酮饮食\n- RubyChina\n  - [推荐一个简单有效的减肥方法：生酮饮食](https://ruby-china.org/topics/38029) [备用链接](https://web.archive.org/web/20190207074707/https://ruby-china.org/topics/38029)\n- Reddit\n  - [keto faq](https://www.reddit.com/r/keto/wiki/faq)\n  - [keto-calculator](https://calculo.io/keto-calculator)\n  - [Keto For Beginners](https://www.reddit.com/r/keto/wiki/keto_in_a_nutshell)\n  - [Keto Progress Tracker](https://docs.google.com/spreadsheets/d/1g-tl1PqIUaHsLdL2Au1KKGe7z5EQS0_xT7f_lMllIB4/edit#gid=5)\n- V2EX\n  - [一个女肥宅的减肥&健身心得，和大家分享~](https://www.v2ex.com/t/469642)\n- 科学松鼠会\n  - [治疗癫痫病的生酮饮食，你想用来减肥？](http://songshuhui.net/archives/101982)\n  - [低脂肪和低碳水，哪种食谱减肥效果好？](http://songshuhui.net/archives/100583)\n- 其它\n  - [A Guide to Ketosis](http://josepharcita.blogspot.com/2011/03/guide-to-ketosis.html)\n<a name=\"app\"></a>\n#### app\n\n- keep\n\n<a name=\"b6c5522e\"></a>\n#### 书单\nsource: [https://www.douban.com/doulist/111781954/](https://www.douban.com/doulist/111781954/)\n\n- 《我们为什么会发胖》\n\n[![image.png](https://cdn.nlark.com/yuque/0/2019/png/223800/1549531654316-1583207e-f17f-4b6c-af24-ebb7d5e1a4a9.png#align=left&display=inline&height=295&name=image.png&originHeight=602&originWidth=1480&size=247921&width=726)](https://book.douban.com/subject/26369484/)\n\n- 《运动饮食1:9》\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/223800/1549531774483-242f4e73-f064-4451-924d-40307caf186a.png#align=left&display=inline&height=308&name=image.png&originHeight=616&originWidth=1500&size=216699&width=750)\n\n- 《施瓦辛格健身全书》\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/223800/1549531883167-4ed718e6-8487-494d-b7ed-46a7809bbd9e.png#align=left&display=inline&height=267&name=image.png&originHeight=534&originWidth=1496&size=322007&width=748)\n\n- 《囚徒健身》\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/223800/1549532264981-490bb0e2-e58d-4f9e-b91b-445fc496b0a4.png#align=left&display=inline&height=307&name=image.png&originHeight=614&originWidth=1468&size=363357&width=734)\n\n- 《核心基础运动》\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/223800/1549532305042-6752e6dd-d89b-4727-992d-856408a3ca2d.png#align=left&display=inline&height=331&name=image.png&originHeight=662&originWidth=1514&size=312834&width=757)\n\n- 《德拉威尔拉伸训练图解》\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/223800/1549532339425-0c31d2a0-5da1-4e2a-81c5-1cb7a0312ac6.png#align=left&display=inline&height=304&name=image.png&originHeight=608&originWidth=1472&size=275937&width=736)<br />\n\n\n\n\n",
    "body_draft": "\n<a name=\"9699a50e\"></a>\n### 关键词\n\n- 书单\n- app\n- 营养学\n- 低碳饮食\n- 生酮饮食\n- paper\n- 阿特金斯减肥法\n- 计划\n- 表格\n- 体脂称\n- 手环\n<a name=\"d41d8cd9\"></a>\n### \n<a name=\"b59c9e0f\"></a>\n### 概念\n\n- 基础代谢\n- 低碳水饮食\n- 燃脂心率\n- BMI 指数\n- 生酮饮食(keto)\n- HIIT\n  - Tabata\n> Tabata 是 HIIT 高强度间歇性的一种，它的训练方式和 HIIT 有些区别，但减脂原理以及优点和 HIIT 都是类似的。\n\n\n<a name=\"fef9d212\"></a>\n## 肥胖的危害\n![](https://cdn.nlark.com/yuque/0/2019/jpeg/223800/1549541591417-d6dd7785-cdbb-4f09-b3ae-58d4f5b1bf0c.jpeg#align=left&display=inline&height=386&originHeight=328&originWidth=550&size=0&width=648)\n<a name=\"e9d1af34\"></a>\n## 减肥方法\n<a name=\"44ebfb82\"></a>\n### 饮食\n<a name=\"445ddd1a\"></a>\n#### 生酮饮食\n\n- [治疗癫痫病的生酮饮食，你想用来减肥？](http://songshuhui.net/archives/101982)\n> 生酮饮食是限制碳水化合物、大量摄入脂肪的食谱，典型的生酮食谱中脂肪供能比高达70%-80%，蛋白质约为10%-20%，而碳水化合物只占5%-10%\n> 人体的生理活动需要热量，正常情况下由碳水化合物来提供。光是大脑活动所需要的热量，每天就需要120克葡萄糖。当人体处于饥饿或者碳水化合物缺乏的状态，就会消耗肝糖元以及暂时分解肌肉来供能。这样的状态持续三四天，糖元消失殆尽，血液中的胰岛素水平大大降低，肝脏就会开始把脂肪分解为酮体来供能。\n> 身体本来是按照葡萄糖供能来运行的，在生酮饮食下改用酮体来供能。就像一台汽油发动机，变成了用酒精做燃料。这种改变，会改变身体的整个代谢状态。\n\n**优点**：\n\n  - 短期的生酮饮食对于减轻体重以及改善某些生理指标有一定帮助\n    - 体重的降低\n    - 体脂率、胰岛素水平、血压、腰臀比等指标也有所改善 \n\n**缺点：**\n> 当血液中的酮体含量过高，人体会出于酮血症的状态。在这种状态下，肾会排出酮体和体液，从而导致人体失水，体重迅速减轻。或许，这就是有的人采用生酮饮食能迅速减重的原因。\n\n  - 其他健康的减肥方式相比，生酮饮食就没有什么优势\n  - 生酮饮食的营养组成相当不合理。\n> 许多维生素、矿物质以及膳食纤维等营养成分都伴随着碳水化合物而来。长期坚持生酮饮食，营养的失衡对健康会有什么样的影响，也还没有充分的研究\n\n  - 人体可能会出现许多不适，比如饥饿、疲劳、情绪低落、便秘、头痛等等\n  - 较长时间的生酮饮食会大大增加肾结石、骨质疏松和高尿酸的风险\n\n总结:\n> 从实验结果来看，短期的生酮饮食对于减轻体重以及改善某些生理指标有一定帮助。不过，如果跟其他健康的减肥方式相比，生酮饮食就没有什么优势。而生酮饮食早已明确的副作用，就已经不可忽视。此外，生酮饮食的营养组成相当不合理。许多维生素、矿物质以及膳食纤维等营养成分都伴随着碳水化合物而来。长期坚持生酮饮食，营养的失衡对健康会有什么样的影响，也还没有充分的研究。\n> 当然，如果作为一种医疗手段，生酮饮食还是值得研究和关注的。在某些疾病的治疗中，经过医生的评估，并且在医院的密切监护下进行生酮饮食，也是可以采取的方案。至于日常生活中用它来减肥，还是算了吧。\n\n简单来说**生酮饮食**最初就是作为一种医疗手段，例如糖尿病、癫痫，生酮饮食还被用于许多跟神经有关的疾病上，比如阿茨海默症、自闭症、脑癌、帕金森氏病等等，有一定的效果，不过综合权衡效果与证据强度，并没有达到临床推荐的层次。而且副作用明显，便秘和肾结石\n<a name=\"d41d8cd9\"></a>\n#### \n<a name=\"0d74ba8c\"></a>\n#### 阿特金斯减肥法\n<a name=\"6b17f352\"></a>\n#### 低碳水饮食\n<a name=\"37b6debe\"></a>\n### 运动\n<a name=\"8558e728\"></a>\n#### 长时间持续性有氧\n> 运动强度超过30分钟的中低强度有氧，如慢跑，游泳，长途骑行等。是一直以来没毛病的传统型有氧。\n\n不低于30分钟不高于70分钟为最佳。\n\n  - 慢跑\n  - 游泳\n  - 长途骑行\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/223800/1549541856051-0fd9ec25-c919-4b06-bd75-e991e3564695.png#align=left&display=inline&height=707&name=image.png&originHeight=508&originWidth=440&size=300058&width=612)<br />卡氏公式:<br />        燃脂心率 =（220-年龄-静态心率）x 30%-45%+静态心率\n\n<br /><a name=\"95a7e4d0\"></a>\n#### 间歇性有氧运动（HIIT）\n> HIIT，简单讲就是一种高强度与低强度交替间歇的训练方式。只要在运动中是强度高低交替的，都可以视作广义的HIIT，比如快慢交替跑，快慢交替骑车等等。\n\n优点：\n\n- 即运动后仍然能保持高热量、高脂肪的消耗效率。其训练后减脂效果可以持续72小时左右。并且其高强度的动作还可以起到保护肌肉维持代谢的作用\n\n缺点：\n\n- 强度高\n<a name=\"d41d8cd9\"></a>\n### \n<a name=\"0debf521\"></a>\n### 计划\n\n- 食谱\n- 运动\n  - 慢跑\n> 跑完步记得补充水份，牛奶比矿泉水更补水，还能补充蛋白质和电解质修复你的身体损耗。\n> 吃一根富含钾的香蕉也不错。\n\n<a name=\"1c7fa641\"></a>\n#### 注意事项：\n\n- 减肥也不能吃得低于自己的基础代谢\n<a name=\"5b208a57\"></a>\n## 参考:\n\n- 知乎\n  - [禁食「碳水化合物」正确吗？「阿特金斯减肥法」有效安全吗？ - 《科学世界》杂志的回答 - 知乎 ](https://www.zhihu.com/question/20234124/answer/352356794)\n  - [哥本哈根食谱真的有那么神奇吗？](https://www.zhihu.com/question/23586456/answer/151934876)\n  - [减肥谣言大混战|低碳水or低脂肪，谁在瞎说|生酮减肥](https://zhuanlan.zhihu.com/p/36154483)\n  - [脂肪是如何被消耗的？](https://zhuanlan.zhihu.com/p/36020258)\n  - [tabata 4分钟真的有效果吗？](https://www.zhihu.com/question/28248712)\n- 丁香园\n  - [(丁香园)生酮饮食：减重效果如何？又有什么风险？](http://endo.dxy.cn/article/560367)[备用链接](https://web.archive.org/web/20190207075150/http://endo.dxy.cn/article/560367) #生酮饮食\n- RubyChina\n  - [推荐一个简单有效的减肥方法：生酮饮食](https://ruby-china.org/topics/38029) [备用链接](https://web.archive.org/web/20190207074707/https://ruby-china.org/topics/38029)\n- Reddit\n  - [keto faq](https://www.reddit.com/r/keto/wiki/faq)\n  - [keto-calculator](https://calculo.io/keto-calculator)\n  - [Keto For Beginners](https://www.reddit.com/r/keto/wiki/keto_in_a_nutshell)\n  - [Keto Progress Tracker](https://docs.google.com/spreadsheets/d/1g-tl1PqIUaHsLdL2Au1KKGe7z5EQS0_xT7f_lMllIB4/edit#gid=5)\n- V2EX\n  - [一个女肥宅的减肥&健身心得，和大家分享~](https://www.v2ex.com/t/469642)\n- 科学松鼠会\n  - [治疗癫痫病的生酮饮食，你想用来减肥？](http://songshuhui.net/archives/101982)\n  - [低脂肪和低碳水，哪种食谱减肥效果好？](http://songshuhui.net/archives/100583)\n- 其它\n  - [A Guide to Ketosis](http://josepharcita.blogspot.com/2011/03/guide-to-ketosis.html)\n<a name=\"app\"></a>\n#### app\n\n- keep\n\n<a name=\"b6c5522e\"></a>\n#### 书单\nsource: [https://www.douban.com/doulist/111781954/](https://www.douban.com/doulist/111781954/)\n\n- 《我们为什么会发胖》\n\n[![image.png](https://cdn.nlark.com/yuque/0/2019/png/223800/1549531654316-1583207e-f17f-4b6c-af24-ebb7d5e1a4a9.png#align=left&display=inline&height=295&name=image.png&originHeight=602&originWidth=1480&size=247921&width=726)](https://book.douban.com/subject/26369484/)\n\n- 《运动饮食1:9》\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/223800/1549531774483-242f4e73-f064-4451-924d-40307caf186a.png#align=left&display=inline&height=308&name=image.png&originHeight=616&originWidth=1500&size=216699&width=750)\n\n- 《施瓦辛格健身全书》\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/223800/1549531883167-4ed718e6-8487-494d-b7ed-46a7809bbd9e.png#align=left&display=inline&height=267&name=image.png&originHeight=534&originWidth=1496&size=322007&width=748)\n\n- 《囚徒健身》\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/223800/1549532264981-490bb0e2-e58d-4f9e-b91b-445fc496b0a4.png#align=left&display=inline&height=307&name=image.png&originHeight=614&originWidth=1468&size=363357&width=734)\n\n- 《核心基础运动》\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/223800/1549532305042-6752e6dd-d89b-4727-992d-856408a3ca2d.png#align=left&display=inline&height=331&name=image.png&originHeight=662&originWidth=1514&size=312834&width=757)\n\n- 《德拉威尔拉伸训练图解》\n\n![image.png](https://cdn.nlark.com/yuque/0/2019/png/223800/1549532339425-0c31d2a0-5da1-4e2a-81c5-1cb7a0312ac6.png#align=left&display=inline&height=304&name=image.png&originHeight=608&originWidth=1472&size=275937&width=736)<br />\n\n\n\n\n",
    "body_html": "<p><br /></p><h3 id=\"9699a50e\">关键词</h3><ul><li>书单</li><li>app</li><li>营养学</li><li>低碳饮食</li><li><span>生酮饮食</span></li><li><span>paper</span></li><li>阿特金斯减肥法</li><li>计划</li><li>表格</li><li>体脂称</li><li>手环</li></ul><h3 id=\"d41d8cd9\"><br /></h3><h3 id=\"b59c9e0f\">概念</h3><ul><li>基础代谢</li><li><span>低碳水饮食</span></li><li><span style=\"color: #000000;\">燃脂心率</span></li><li><span style=\"color: #000000;\">BMI 指数</span></li><li><span>生酮饮食(keto)</span></li><li>HIIT</li></ul><ul data-lake-indent=\"1\"><li>Tabata</li></ul><blockquote><p>Tabata 是 HIIT 高强度间歇性的一种，它的训练方式和 HIIT 有些区别，但减脂原理以及优点和 HIIT 都是类似的。</p></blockquote><p><br /></p><h2 id=\"fef9d212\">肥胖的危害</h2><p><img src=\"https://cdn.nlark.com/yuque/0/2019/jpeg/223800/1549541591417-d6dd7785-cdbb-4f09-b3ae-58d4f5b1bf0c.jpeg#align=left&amp;display=inline&amp;height=386&amp;originHeight=328&amp;originWidth=550&amp;size=0&amp;width=648\" style=\"max-width: 600px; width: 648px;\" /></p><h2 id=\"e9d1af34\">减肥方法</h2><h3 id=\"44ebfb82\">饮食</h3><h4 id=\"445ddd1a\"><span>生酮饮食</span></h4><ul><li><a href=\"http://songshuhui.net/archives/101982\" target=\"_blank\">治疗癫痫病的生酮饮食，你想用来减肥？</a></li></ul><blockquote><p>生酮饮食是限制碳水化合物、大量摄入脂肪的食谱，典型的生酮食谱中脂肪供能比高达70%-80%，蛋白质约为10%-20%，而碳水化合物只占5%-10%</p><p>人体的生理活动需要热量，正常情况下由碳水化合物来提供。光是大脑活动所需要的热量，每天就需要120克葡萄糖。当人体处于饥饿或者碳水化合物缺乏的状态，就会消耗肝糖元以及暂时分解肌肉来供能。这样的状态持续三四天，糖元消失殆尽，血液中的胰岛素水平大大降低，肝脏就会开始把脂肪分解为酮体来供能。</p><p>身体本来是按照葡萄糖供能来运行的，在生酮饮食下改用酮体来供能。就像一台汽油发动机，变成了用酒精做燃料。这种改变，会改变身体的整个代谢状态。</p></blockquote><p><strong>优点</strong>：</p><ul data-lake-indent=\"1\"><li>短期的生酮饮食对于减轻体重以及改善某些生理指标有一定帮助</li></ul><ul data-lake-indent=\"2\"><li>体重的降低</li><li><span>体脂率、胰岛素水平、血压、腰臀比等指标也有所改善 </span></li></ul><p><strong>缺点：</strong></p><blockquote><p>当血液中的酮体含量过高，人体会出于酮血症的状态。在这种状态下，肾会排出酮体和体液，从而导致人体失水，体重迅速减轻。或许，这就是有的人采用生酮饮食能迅速减重的原因。</p></blockquote><ul data-lake-indent=\"1\"><li>其他健康的减肥方式相比，生酮饮食就没有什么优势</li><li>生酮饮食的营养组成相当不合理。</li></ul><blockquote><p>许多维生素、矿物质以及膳食纤维等营养成分都伴随着碳水化合物而来。长期坚持生酮饮食，营养的失衡对健康会有什么样的影响，也还没有充分的研究</p></blockquote><ul data-lake-indent=\"1\"><li>人体可能会出现许多不适，比如饥饿、疲劳、情绪低落、便秘、头痛等等</li><li>较长时间的生酮饮食会大大增加肾结石、骨质疏松和高尿酸的风险</li></ul><p>总结:</p><blockquote><p>从实验结果来看，短期的生酮饮食对于减轻体重以及改善某些生理指标有一定帮助。不过，如果跟其他健康的减肥方式相比，生酮饮食就没有什么优势。而生酮饮食早已明确的副作用，就已经不可忽视。此外，生酮饮食的营养组成相当不合理。许多维生素、矿物质以及膳食纤维等营养成分都伴随着碳水化合物而来。长期坚持生酮饮食，营养的失衡对健康会有什么样的影响，也还没有充分的研究。</p><p>当然，如果作为一种医疗手段，生酮饮食还是值得研究和关注的。在某些疾病的治疗中，经过医生的评估，并且在医院的密切监护下进行生酮饮食，也是可以采取的方案。至于日常生活中用它来减肥，还是算了吧。</p></blockquote><p>简单来说<strong>生酮饮食</strong>最初就是作为一种医疗手段，例如糖尿病、癫痫，生酮饮食还被用于许多跟神经有关的疾病上，比如阿茨海默症、自闭症、脑癌、帕金森氏病等等，有一定的效果，不过综合权衡效果与证据强度，并没有达到临床推荐的层次。而且副作用明显，便秘和肾结石</p><h4 id=\"d41d8cd9\"><br /></h4><h4 id=\"0d74ba8c\"><span>阿特金斯减肥法</span></h4><h4 id=\"6b17f352\"><span>低碳水饮食</span></h4><h3 id=\"37b6debe\"><span>运动</span></h3><h4 id=\"8558e728\">长时间持续性有氧</h4><blockquote><p>运动强度超过30分钟的中低强度有氧，如慢跑，游泳，长途骑行等。是一直以来没毛病的传统型有氧。</p></blockquote><p><span style=\"color: #3F3F3F;\">不低于30分钟不高于70分钟为最佳。</span></p><ul data-lake-indent=\"1\"><li>慢跑</li><li>游泳</li><li>长途骑行</li></ul><p><img alt=\"image.png\" title=\"image.png\" src=\"https://cdn.nlark.com/yuque/0/2019/png/223800/1549541856051-0fd9ec25-c919-4b06-bd75-e991e3564695.png#align=left&amp;display=inline&amp;height=707&amp;name=image.png&amp;originHeight=508&amp;originWidth=440&amp;size=300058&amp;width=612\" style=\"max-width: 600px; width: 612px;\" /></p><p><span class=\"lake-fontsize-11\" style=\"color: #3F3F3F;\">卡氏公式:</span></p><p><span class=\"lake-fontsize-11\" style=\"color: #3F3F3F;\"><span>        </span><span style=\"color: #000000;\">燃脂心率 =</span>（220-年龄-静态心率）x 30%-45%+静态心率</span></p><ul><br /></ul><h4 id=\"95a7e4d0\"><span style=\"color: #000000;\">间歇性有氧运动（HIIT）</span></h4><blockquote><p>HIIT，简单讲就是一种高强度与低强度交替间歇的训练方式。只要在运动中是强度高低交替的，都可以视作广义的HIIT，比如快慢交替跑，快慢交替骑车等等。</p></blockquote><p>优点：</p><ul><li>即运动后<span style=\"color: #F5222D;\">仍然能保持高热量、高脂肪的消耗效率</span>。其训练后减脂效果可以<span style=\"color: #F5222D;\">持续72小时</span>左右。并且其高强度的动作还可以起到<span style=\"color: #F5222D;\">保护肌肉维持代谢</span>的作用</li></ul><p><span class=\"lake-fontsize-11\" style=\"color: #3F3F3F;\">缺点：</span></p><ul><li>强度高</li></ul><h3 id=\"d41d8cd9\"><br /></h3><h3 id=\"0debf521\">计划</h3><ul><li>食谱</li><li>运动</li></ul><ul data-lake-indent=\"1\"><li>慢跑</li></ul><blockquote><p><span style=\"color: #F5222D;\">跑完步记得补充水份，牛奶比矿泉水更补水，还能补充蛋白质和电解质修复你的身体损耗。</span></p><p><span style=\"color: #F5222D;\">吃一根富含钾的香蕉也不错。</span></p></blockquote><h4 id=\"1c7fa641\">注意事项：</h4><ul><li>减肥也不能吃得低于自己的基础代谢</li></ul><h2 id=\"5b208a57\">参考:</h2><ul><li>知乎</li></ul><ul data-lake-indent=\"1\"><li><a href=\"https://www.zhihu.com/question/20234124/answer/352356794\" target=\"_blank\">禁食「碳水化合物」正确吗？「阿特金斯减肥法」有效安全吗？ - 《科学世界》杂志的回答 - 知乎 </a></li><li><a href=\"https://www.zhihu.com/question/23586456/answer/151934876\" target=\"_blank\">哥本哈根食谱真的有那么神奇吗？</a></li><li><a href=\"https://zhuanlan.zhihu.com/p/36154483\" target=\"_blank\">减肥谣言大混战|低碳水or低脂肪，谁在瞎说|生酮减肥</a></li><li><a href=\"https://zhuanlan.zhihu.com/p/36020258\" target=\"_blank\">脂肪是如何被消耗的？</a></li><li><a href=\"https://www.zhihu.com/question/28248712\" target=\"_blank\">tabata 4分钟真的有效果吗？</a></li></ul><ul><li>丁香园</li></ul><ul data-lake-indent=\"1\"><li><a href=\"http://endo.dxy.cn/article/560367\" target=\"_blank\">(丁香园)生酮饮食：减重效果如何？又有什么风险？</a><a href=\"https://web.archive.org/web/20190207075150/http://endo.dxy.cn/article/560367\" target=\"_blank\">备用链接</a> #生酮饮食</li></ul><ul><li>RubyChina</li></ul><ul data-lake-indent=\"1\"><li><span><a href=\"https://ruby-china.org/topics/38029\" target=\"_blank\">推荐一个简单有效的减肥方法：生酮饮食</a> </span><a href=\"https://web.archive.org/web/20190207074707/https://ruby-china.org/topics/38029\" target=\"_blank\"><span>备用链接</span></a></li></ul><ul><li><span>Reddit</span></li></ul><ul data-lake-indent=\"1\"><li><a href=\"https://www.reddit.com/r/keto/wiki/faq\" target=\"_blank\">keto faq</a></li><li><a href=\"https://calculo.io/keto-calculator\" target=\"_blank\">keto-calculator</a></li><li><a href=\"https://www.reddit.com/r/keto/wiki/keto_in_a_nutshell\" target=\"_blank\">Keto For Beginners</a></li><li><a href=\"https://docs.google.com/spreadsheets/d/1g-tl1PqIUaHsLdL2Au1KKGe7z5EQS0_xT7f_lMllIB4/edit#gid=5\" target=\"_blank\">Keto Progress Tracker</a></li></ul><ul><li><span>V2EX</span></li></ul><ul data-lake-indent=\"1\"><li><a href=\"https://www.v2ex.com/t/469642\" target=\"_blank\">一个女肥宅的减肥&amp;健身心得，和大家分享~</a></li></ul><ul><li>科学松鼠会</li></ul><ul data-lake-indent=\"1\"><li><a href=\"http://songshuhui.net/archives/101982\" target=\"_blank\">治疗癫痫病的生酮饮食，你想用来减肥？</a></li><li><a href=\"http://songshuhui.net/archives/100583\" target=\"_blank\">低脂肪和低碳水，哪种食谱减肥效果好？</a></li></ul><ul><li>其它</li></ul><ul data-lake-indent=\"1\"><li><a href=\"http://josepharcita.blogspot.com/2011/03/guide-to-ketosis.html\" target=\"_blank\">A Guide to Ketosis</a></li></ul><h4 id=\"app\">app</h4><ul><li>keep</li></ul><p><br /></p><h4 id=\"b6c5522e\">书单</h4><p>source: <a href=\"https://www.douban.com/doulist/111781954/\" target=\"_blank\">https://www.douban.com/doulist/111781954/</a></p><p><br /></p><ul><li>《我们为什么会发胖》</li></ul><p><a href=\"https://book.douban.com/subject/26369484/\" ref=\"noopener noreferrer\"><img alt=\"image.png\" title=\"image.png\" src=\"https://cdn.nlark.com/yuque/0/2019/png/223800/1549531654316-1583207e-f17f-4b6c-af24-ebb7d5e1a4a9.png#align=left&amp;display=inline&amp;height=295&amp;name=image.png&amp;originHeight=602&amp;originWidth=1480&amp;size=247921&amp;width=726\" style=\"max-width: 600px; width: 726px;\" /></a></p><p><br /></p><ul><li>《运动饮食1:9》</li></ul><p><img alt=\"image.png\" title=\"image.png\" src=\"https://cdn.nlark.com/yuque/0/2019/png/223800/1549531774483-242f4e73-f064-4451-924d-40307caf186a.png#align=left&amp;display=inline&amp;height=308&amp;name=image.png&amp;originHeight=616&amp;originWidth=1500&amp;size=216699&amp;width=750\" style=\"max-width: 600px; width: 750px;\" /></p><ul><li><span style=\"color: #333333;\">《施瓦辛格健身全书》</span></li></ul><p><span style=\"color: #333333;\"><img alt=\"image.png\" title=\"image.png\" src=\"https://cdn.nlark.com/yuque/0/2019/png/223800/1549531883167-4ed718e6-8487-494d-b7ed-46a7809bbd9e.png#align=left&amp;display=inline&amp;height=267&amp;name=image.png&amp;originHeight=534&amp;originWidth=1496&amp;size=322007&amp;width=748\" style=\"max-width: 600px; width: 748px;\" /></span></p><ul><li><span style=\"color: #333333;\">《囚徒健身》</span></li></ul><p><span style=\"color: #333333;\"><img alt=\"image.png\" title=\"image.png\" src=\"https://cdn.nlark.com/yuque/0/2019/png/223800/1549532264981-490bb0e2-e58d-4f9e-b91b-445fc496b0a4.png#align=left&amp;display=inline&amp;height=307&amp;name=image.png&amp;originHeight=614&amp;originWidth=1468&amp;size=363357&amp;width=734\" style=\"max-width: 600px; width: 734px;\" /></span></p><ul><li>《<span>核心基础运动</span>》</li></ul><p><img alt=\"image.png\" title=\"image.png\" src=\"https://cdn.nlark.com/yuque/0/2019/png/223800/1549532305042-6752e6dd-d89b-4727-992d-856408a3ca2d.png#align=left&amp;display=inline&amp;height=331&amp;name=image.png&amp;originHeight=662&amp;originWidth=1514&amp;size=312834&amp;width=757\" style=\"max-width: 600px; width: 757px;\" /></p><ul><li>《<span>德拉威尔拉伸训练图解</span>》</li></ul><p><img alt=\"image.png\" title=\"image.png\" src=\"https://cdn.nlark.com/yuque/0/2019/png/223800/1549532339425-0c31d2a0-5da1-4e2a-81c5-1cb7a0312ac6.png#align=left&amp;display=inline&amp;height=304&amp;name=image.png&amp;originHeight=608&amp;originWidth=1472&amp;size=275937&amp;width=736\" style=\"max-width: 600px; width: 736px;\" /></p><p style=\"text-indent: 2em;\"><br /></p><p><br /></p><p><br /></p><p><br /></p>",
    "body_lake": "<!doctype lake><p><br /></p><h3 id=\"9699a50e\">关键词</h3><ul><li>书单</li><li>app</li><li>营养学</li><li>低碳饮食</li><li><span>生酮饮食</span></li><li><span>paper</span></li><li>阿特金斯减肥法</li><li>计划</li><li>表格</li><li>体脂称</li><li>手环<cursor /></li></ul><h3 id=\"d41d8cd9\"><br /></h3><h3 id=\"b59c9e0f\">概念</h3><ul><li>基础代谢</li><li><span>低碳水饮食</span></li><li><span style=\"color: #000000;\">燃脂心率</span></li><li><span style=\"color: #000000;\">BMI 指数</span></li><li><span>生酮饮食(keto)</span></li><li>HIIT</li></ul><ul data-lake-indent=\"1\"><li>Tabata</li></ul><blockquote><p>Tabata 是 HIIT 高强度间歇性的一种，它的训练方式和 HIIT 有些区别，但减脂原理以及优点和 HIIT 都是类似的。</p></blockquote><p><br /></p><h2 id=\"fef9d212\">肥胖的危害</h2><p><card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22https%3A%2F%2Fcdn.nlark.com%2Fyuque%2F0%2F2019%2Fjpeg%2F223800%2F1549541591417-d6dd7785-cdbb-4f09-b3ae-58d4f5b1bf0c.jpeg%22%2C%22originWidth%22%3A550%2C%22originHeight%22%3A328%2C%22size%22%3A0%2C%22display%22%3A%22inline%22%2C%22align%22%3A%22left%22%2C%22linkTarget%22%3A%22_blank%22%2C%22width%22%3A648%2C%22height%22%3A386%7D\"></card></p><h2 id=\"e9d1af34\">减肥方法</h2><h3 id=\"44ebfb82\">饮食</h3><h4 id=\"445ddd1a\"><span>生酮饮食</span></h4><ul><li><a href=\"http://songshuhui.net/archives/101982\" target=\"_blank\">治疗癫痫病的生酮饮食，你想用来减肥？</a></li></ul><blockquote><p>生酮饮食是限制碳水化合物、大量摄入脂肪的食谱，典型的生酮食谱中脂肪供能比高达70%-80%，蛋白质约为10%-20%，而碳水化合物只占5%-10%</p><p>人体的生理活动需要热量，正常情况下由碳水化合物来提供。光是大脑活动所需要的热量，每天就需要120克葡萄糖。当人体处于饥饿或者碳水化合物缺乏的状态，就会消耗肝糖元以及暂时分解肌肉来供能。这样的状态持续三四天，糖元消失殆尽，血液中的胰岛素水平大大降低，肝脏就会开始把脂肪分解为酮体来供能。</p><p>身体本来是按照葡萄糖供能来运行的，在生酮饮食下改用酮体来供能。就像一台汽油发动机，变成了用酒精做燃料。这种改变，会改变身体的整个代谢状态。</p></blockquote><p><strong>优点</strong>：</p><ul data-lake-indent=\"1\"><li>短期的生酮饮食对于减轻体重以及改善某些生理指标有一定帮助</li></ul><ul data-lake-indent=\"2\"><li>体重的降低</li><li><span>体脂率、胰岛素水平、血压、腰臀比等指标也有所改善 </span></li></ul><p><strong>缺点：</strong></p><blockquote><p>当血液中的酮体含量过高，人体会出于酮血症的状态。在这种状态下，肾会排出酮体和体液，从而导致人体失水，体重迅速减轻。或许，这就是有的人采用生酮饮食能迅速减重的原因。</p></blockquote><ul data-lake-indent=\"1\"><li>其他健康的减肥方式相比，生酮饮食就没有什么优势</li><li>生酮饮食的营养组成相当不合理。</li></ul><blockquote><p>许多维生素、矿物质以及膳食纤维等营养成分都伴随着碳水化合物而来。长期坚持生酮饮食，营养的失衡对健康会有什么样的影响，也还没有充分的研究</p></blockquote><ul data-lake-indent=\"1\"><li>人体可能会出现许多不适，比如饥饿、疲劳、情绪低落、便秘、头痛等等</li><li>较长时间的生酮饮食会大大增加肾结石、骨质疏松和高尿酸的风险</li></ul><p>总结:</p><blockquote><p>从实验结果来看，短期的生酮饮食对于减轻体重以及改善某些生理指标有一定帮助。不过，如果跟其他健康的减肥方式相比，生酮饮食就没有什么优势。而生酮饮食早已明确的副作用，就已经不可忽视。此外，生酮饮食的营养组成相当不合理。许多维生素、矿物质以及膳食纤维等营养成分都伴随着碳水化合物而来。长期坚持生酮饮食，营养的失衡对健康会有什么样的影响，也还没有充分的研究。</p><p>当然，如果作为一种医疗手段，生酮饮食还是值得研究和关注的。在某些疾病的治疗中，经过医生的评估，并且在医院的密切监护下进行生酮饮食，也是可以采取的方案。至于日常生活中用它来减肥，还是算了吧。</p></blockquote><p>简单来说<strong>生酮饮食</strong>最初就是作为一种医疗手段，例如糖尿病、癫痫，生酮饮食还被用于许多跟神经有关的疾病上，比如阿茨海默症、自闭症、脑癌、帕金森氏病等等，有一定的效果，不过综合权衡效果与证据强度，并没有达到临床推荐的层次。而且副作用明显，便秘和肾结石</p><h4 id=\"d41d8cd9\"><br /></h4><h4 id=\"0d74ba8c\"><span>阿特金斯减肥法</span></h4><h4 id=\"6b17f352\"><span>低碳水饮食</span></h4><h3 id=\"37b6debe\"><span>运动</span></h3><h4 id=\"8558e728\">长时间持续性有氧</h4><blockquote><p>运动强度超过30分钟的中低强度有氧，如慢跑，游泳，长途骑行等。是一直以来没毛病的传统型有氧。</p></blockquote><p><span style=\"color: #3F3F3F;\">不低于30分钟不高于70分钟为最佳。</span></p><ul data-lake-indent=\"1\"><li>慢跑</li><li>游泳</li><li>长途骑行</li></ul><p><card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22https%3A%2F%2Fcdn.nlark.com%2Fyuque%2F0%2F2019%2Fpng%2F223800%2F1549541856051-0fd9ec25-c919-4b06-bd75-e991e3564695.png%22%2C%22originWidth%22%3A440%2C%22originHeight%22%3A508%2C%22name%22%3A%22image.png%22%2C%22size%22%3A300058%2C%22display%22%3A%22inline%22%2C%22align%22%3A%22left%22%2C%22linkTarget%22%3A%22_blank%22%2C%22width%22%3A612%2C%22height%22%3A707%7D\"></card></p><p><span class=\"lake-fontsize-11\" style=\"color: #3F3F3F;\">卡氏公式:</span></p><p><span class=\"lake-fontsize-11\" style=\"color: #3F3F3F;\"><span>        </span><span style=\"color: #000000;\">燃脂心率 =</span>（220-年龄-静态心率）x 30%-45%+静态心率</span></p><ul><br /></ul><h4 id=\"95a7e4d0\"><span style=\"color: #000000;\">间歇性有氧运动（HIIT）</span></h4><blockquote><p>HIIT，简单讲就是一种高强度与低强度交替间歇的训练方式。只要在运动中是强度高低交替的，都可以视作广义的HIIT，比如快慢交替跑，快慢交替骑车等等。</p></blockquote><p>优点：</p><ul><li>即运动后<span style=\"color: #F5222D;\">仍然能保持高热量、高脂肪的消耗效率</span>。其训练后减脂效果可以<span style=\"color: #F5222D;\">持续72小时</span>左右。并且其高强度的动作还可以起到<span style=\"color: #F5222D;\">保护肌肉维持代谢</span>的作用</li></ul><p><span class=\"lake-fontsize-11\" style=\"color: #3F3F3F;\">缺点：</span></p><ul><li>强度高</li></ul><h3 id=\"d41d8cd9\"><br /></h3><h3 id=\"0debf521\">计划</h3><ul><li>食谱</li><li>运动</li></ul><ul data-lake-indent=\"1\"><li>慢跑</li></ul><blockquote><p><span style=\"color: #F5222D;\">跑完步记得补充水份，牛奶比矿泉水更补水，还能补充蛋白质和电解质修复你的身体损耗。</span></p><p><span style=\"color: #F5222D;\">吃一根富含钾的香蕉也不错。</span></p></blockquote><h4 id=\"1c7fa641\">注意事项：</h4><ul><li>减肥也不能吃得低于自己的基础代谢</li></ul><h2 id=\"5b208a57\">参考:</h2><ul><li>知乎</li></ul><ul data-lake-indent=\"1\"><li><a href=\"https://www.zhihu.com/question/20234124/answer/352356794\" target=\"_blank\">禁食「碳水化合物」正确吗？「阿特金斯减肥法」有效安全吗？ - 《科学世界》杂志的回答 - 知乎 </a></li><li><a href=\"https://www.zhihu.com/question/23586456/answer/151934876\" target=\"_blank\">哥本哈根食谱真的有那么神奇吗？</a></li><li><a href=\"https://zhuanlan.zhihu.com/p/36154483\" target=\"_blank\">减肥谣言大混战|低碳水or低脂肪，谁在瞎说|生酮减肥</a></li><li><a href=\"https://zhuanlan.zhihu.com/p/36020258\" target=\"_blank\">脂肪是如何被消耗的？</a></li><li><a href=\"https://www.zhihu.com/question/28248712\" target=\"_blank\">tabata 4分钟真的有效果吗？</a></li></ul><ul><li>丁香园</li></ul><ul data-lake-indent=\"1\"><li><a href=\"http://endo.dxy.cn/article/560367\" target=\"_blank\">(丁香园)生酮饮食：减重效果如何？又有什么风险？</a><a href=\"https://web.archive.org/web/20190207075150/http://endo.dxy.cn/article/560367\" target=\"_blank\">备用链接</a> #生酮饮食</li></ul><ul><li>RubyChina</li></ul><ul data-lake-indent=\"1\"><li><span><a href=\"https://ruby-china.org/topics/38029\" target=\"_blank\">推荐一个简单有效的减肥方法：生酮饮食</a> </span><a href=\"https://web.archive.org/web/20190207074707/https://ruby-china.org/topics/38029\" target=\"_blank\"><span>备用链接</span></a></li></ul><ul><li><span>Reddit</span></li></ul><ul data-lake-indent=\"1\"><li><a href=\"https://www.reddit.com/r/keto/wiki/faq\" target=\"_blank\">keto faq</a></li><li><a href=\"https://calculo.io/keto-calculator\" target=\"_blank\">keto-calculator</a></li><li><a href=\"https://www.reddit.com/r/keto/wiki/keto_in_a_nutshell\" target=\"_blank\">Keto For Beginners</a></li><li><a href=\"https://docs.google.com/spreadsheets/d/1g-tl1PqIUaHsLdL2Au1KKGe7z5EQS0_xT7f_lMllIB4/edit#gid=5\" target=\"_blank\">Keto Progress Tracker</a></li></ul><ul><li><span>V2EX</span></li></ul><ul data-lake-indent=\"1\"><li><a href=\"https://www.v2ex.com/t/469642\" target=\"_blank\">一个女肥宅的减肥&amp;健身心得，和大家分享~</a></li></ul><ul><li>科学松鼠会</li></ul><ul data-lake-indent=\"1\"><li><a href=\"http://songshuhui.net/archives/101982\" target=\"_blank\">治疗癫痫病的生酮饮食，你想用来减肥？</a></li><li><a href=\"http://songshuhui.net/archives/100583\" target=\"_blank\">低脂肪和低碳水，哪种食谱减肥效果好？</a></li></ul><ul><li>其它</li></ul><ul data-lake-indent=\"1\"><li><a href=\"http://josepharcita.blogspot.com/2011/03/guide-to-ketosis.html\" target=\"_blank\">A Guide to Ketosis</a></li></ul><h4 id=\"app\">app</h4><ul><li>keep</li></ul><p><br /></p><h4 id=\"b6c5522e\">书单</h4><p>source: <a href=\"https://www.douban.com/doulist/111781954/\" target=\"_blank\">https://www.douban.com/doulist/111781954/</a></p><p><br /></p><ul><li>《我们为什么会发胖》</li></ul><p><card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22https%3A%2F%2Fcdn.nlark.com%2Fyuque%2F0%2F2019%2Fpng%2F223800%2F1549531654316-1583207e-f17f-4b6c-af24-ebb7d5e1a4a9.png%22%2C%22originWidth%22%3A1480%2C%22originHeight%22%3A602%2C%22name%22%3A%22image.png%22%2C%22size%22%3A247921%2C%22display%22%3A%22inline%22%2C%22align%22%3A%22left%22%2C%22link%22%3A%22https%3A%2F%2Fbook.douban.com%2Fsubject%2F26369484%2F%22%2C%22linkTarget%22%3A%22%22%2C%22width%22%3A726%2C%22height%22%3A295%7D\"></card></p><p><br /></p><ul><li>《运动饮食1:9》</li></ul><p><card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22https%3A%2F%2Fcdn.nlark.com%2Fyuque%2F0%2F2019%2Fpng%2F223800%2F1549531774483-242f4e73-f064-4451-924d-40307caf186a.png%22%2C%22originWidth%22%3A1500%2C%22originHeight%22%3A616%2C%22name%22%3A%22image.png%22%2C%22size%22%3A216699%2C%22display%22%3A%22inline%22%2C%22align%22%3A%22left%22%2C%22linkTarget%22%3A%22_blank%22%2C%22width%22%3A750%2C%22height%22%3A308%7D\"></card></p><ul><li><span style=\"color: #333333;\">《施瓦辛格健身全书》</span></li></ul><p><span style=\"color: #333333;\"><card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22https%3A%2F%2Fcdn.nlark.com%2Fyuque%2F0%2F2019%2Fpng%2F223800%2F1549531883167-4ed718e6-8487-494d-b7ed-46a7809bbd9e.png%22%2C%22originWidth%22%3A1496%2C%22originHeight%22%3A534%2C%22name%22%3A%22image.png%22%2C%22size%22%3A322007%2C%22display%22%3A%22inline%22%2C%22align%22%3A%22left%22%2C%22linkTarget%22%3A%22_blank%22%2C%22width%22%3A748%2C%22height%22%3A267%7D\"></card></span></p><ul><li><span style=\"color: #333333;\">《囚徒健身》</span></li></ul><p><span style=\"color: #333333;\"><card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22https%3A%2F%2Fcdn.nlark.com%2Fyuque%2F0%2F2019%2Fpng%2F223800%2F1549532264981-490bb0e2-e58d-4f9e-b91b-445fc496b0a4.png%22%2C%22originWidth%22%3A1468%2C%22originHeight%22%3A614%2C%22name%22%3A%22image.png%22%2C%22size%22%3A363357%2C%22display%22%3A%22inline%22%2C%22align%22%3A%22left%22%2C%22linkTarget%22%3A%22_blank%22%2C%22width%22%3A734%2C%22height%22%3A307%7D\"></card></span></p><ul><li>《<span>核心基础运动</span>》</li></ul><p><card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22https%3A%2F%2Fcdn.nlark.com%2Fyuque%2F0%2F2019%2Fpng%2F223800%2F1549532305042-6752e6dd-d89b-4727-992d-856408a3ca2d.png%22%2C%22originWidth%22%3A1514%2C%22originHeight%22%3A662%2C%22name%22%3A%22image.png%22%2C%22size%22%3A312834%2C%22display%22%3A%22inline%22%2C%22align%22%3A%22left%22%2C%22linkTarget%22%3A%22_blank%22%2C%22width%22%3A757%2C%22height%22%3A331%7D\"></card></p><ul><li>《<span>德拉威尔拉伸训练图解</span>》</li></ul><p><card type=\"inline\" name=\"image\" value=\"data:%7B%22src%22%3A%22https%3A%2F%2Fcdn.nlark.com%2Fyuque%2F0%2F2019%2Fpng%2F223800%2F1549532339425-0c31d2a0-5da1-4e2a-81c5-1cb7a0312ac6.png%22%2C%22originWidth%22%3A1472%2C%22originHeight%22%3A608%2C%22name%22%3A%22image.png%22%2C%22size%22%3A275937%2C%22display%22%3A%22inline%22%2C%22align%22%3A%22left%22%2C%22linkTarget%22%3A%22_blank%22%2C%22width%22%3A736%2C%22height%22%3A304%7D\"></card></p><p style=\"text-indent: 2em;\"><br /></p><p><br /></p><p><br /></p><p><br /></p>",
    "public": 1,
    "status": 1,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-02-07T15:09:12.000Z",
    "deleted_at": null,
    "created_at": "2019-01-31T09:50:22.000Z",
    "updated_at": "2019-05-31T06:29:48.000Z",
    "published_at": "2019-02-07T15:09:12.000Z",
    "first_published_at": "2019-01-31T09:50:36.000Z",
    "word_count": 1615,
    "cover": null,
    "description": "关键词书单app营养学低碳饮食生酮饮食paper阿特金斯减肥法计划表格体脂称手环概念基础代谢低碳水饮食燃脂心率BMI 指数生酮饮食(keto)HIITTabataTabata 是 HIIT 高强度间歇性的一种，它的训练方式和 HIIT 有些区别，但减脂原理以及优点和 HIIT 都是类似的。肥胖...",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  },
  {
    "id": 1216077,
    "slug": "qiiqg0",
    "title": "无标题",
    "book_id": 213751,
    "book": {
      "id": 213751,
      "type": "Book",
      "slug": "how_to_x",
      "name": "如何做 X",
      "user_id": 223868,
      "description": "如何去完成或学习 X",
      "creator_id": 223800,
      "public": 0,
      "items_count": 14,
      "likes_count": 0,
      "watches_count": 1,
      "content_updated_at": "2019-07-22T16:15:06.546Z",
      "updated_at": "2019-07-22T16:15:06.000Z",
      "created_at": "2019-01-31T09:48:04.000Z",
      "namespace": "p_z/how_to_x",
      "user": {
        "id": 223868,
        "type": "Group",
        "login": "p_z",
        "name": "知曰",
        "description": "知曰",
        "avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png",
        "large_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_320,h_320",
        "medium_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_160,h_160",
        "small_avatar_url": "https://gw.alipayobjects.com/zos/rmsportal/SZXCSCJTuhRSmAggBlVp.png?x-oss-process=image/resize,m_fill,w_80,h_80",
        "books_count": 13,
        "public_books_count": 1,
        "followers_count": 0,
        "following_count": 0,
        "created_at": "2018-12-12T07:39:16.000Z",
        "updated_at": "2019-08-27T06:23:10.000Z",
        "_serializer": "v2.user"
      },
      "_serializer": "v2.book"
    },
    "user_id": 223800,
    "creator": {
      "id": 223800,
      "type": "User",
      "login": "zhiyue",
      "name": "zhiyue",
      "description": null,
      "avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png",
      "large_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_320,h_320",
      "medium_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_160,h_160",
      "small_avatar_url": "https://cdn.nlark.com/yuque/0/2019/png/223800/1548930031642-avatar/504ea169-554a-425b-b690-6b2d66b1b9c3.png?x-oss-process=image/resize,m_fill,w_80,h_80",
      "books_count": 8,
      "public_books_count": 1,
      "followers_count": 4,
      "following_count": 1,
      "created_at": "2018-12-12T06:39:44.000Z",
      "updated_at": "2019-08-27T06:25:28.000Z",
      "_serializer": "v2.user"
    },
    "format": "lake",
    "body": "",
    "body_draft": "",
    "body_html": null,
    "body_lake": "",
    "public": 1,
    "status": 0,
    "likes_count": 0,
    "comments_count": 0,
    "content_updated_at": "2019-01-31T09:48:10.000Z",
    "deleted_at": null,
    "created_at": "2019-01-31T09:48:10.000Z",
    "updated_at": "2019-11-02T16:39:40.000Z",
    "published_at": null,
    "first_published_at": null,
    "word_count": 0,
    "cover": null,
    "description": "",
    "custom_description": null,
    "_serializer": "v2.doc_detail"
  }
]